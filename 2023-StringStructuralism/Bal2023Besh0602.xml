<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="balisage-1-5.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="balisage-1-5.rng" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<?xml-stylesheet type="text/xsl" href="balisage-proceedings-html.xsl"?>
<article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink"
    version="5.0-subset Balisage-1.5">

    <title>Markup and migratory workflows in the context of AI and big data analytics</title>
    <subtitle>Reflections on the data modeling groundwork of the digital humanities</subtitle>
    <info>
        <abstract>

            <!--WRITE A SIMPLE ABSTRACT NOW. -->




            <para>
                <!--(to reference: 
                    
                    
                * Kordjamshidi P, Roth D, Kersting K. <link xlink:href="Kordjamshidi P, Roth D, Kersting K. Declarative Learning-Based Programming as an Interface to AI Systems. Front Artif Intell. 2022;5:755361. Published 2022 Mar 14. doi:10.3389/frai.2022.755361">Declarative Learning-Based Programming as an Interface to AI Systems. 
                Frontiers in Artifical Intelligence</link>  5:755361, 2022 Mar 14. doi:10.3389/frai.2022.755361
                https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8967162/#fn0001
                    
                * Mordechai Levy-Eichel and Daniel Scheinerman, "Digital humanists need to learn how to count: A prominent recent book in the field suffers serious methodological pitfalls." The Chronicle of Higher Education 17 May 2022. https://www.chronicle.com/article/digital-humanists-need-to-learn-how-to-count 
                
                * essays from The Shape of Data in Digital Humanities, ed. Julia Flanders and Fotis Jannidis. London: Routledge, 2018. 
                      * (note: Intro, contribution on the TEI by Lou Burnard, conclusion by Sperburg-McQueen). 
                
                * Michael Sperberg McQueen, "What does descriptive markup contribute to digital humanities?". Digital Humanities Concepts 2015 Conference presentation (slides + Geoffrey Rockwell's notes). https://philosophi.ca/pmwiki.php/Main/DigitalHumanitiesConcepts2015 
               
                
                * Ted Underwood, The Stone and the shell blog posts:  "Seven ways humanists are using computers to understand text" 4 June 2015:
                https://tedunderwood.com/2015/06/04/seven-ways-humanists-are-using-computers-to-understand-text/ and "Emerging conversations between literary history and sociology." 02 December 2015: https://tedunderwood.com/2015/12/02/emerging-conversations-between-literary-history-and-sociology/
                
                * Gregory J. Palermo, "Transforming Text: Four Valences of a Digital Humanities Informed Writing Analytics" Journal of Writing Analytics 
                    Vol. 1 (2017). DOI: 10.37514/JWA-J.2017.1.1.11. https://wac.colostate.edu/docs/jwa/vol1/palermo.pdf
     
                
              
           -->
            </para>

        </abstract>
        <author>
            <personname>
                <firstname>Elisa</firstname>
                <othername>E.</othername>
                <surname>Beshero-Bondar</surname>
            </personname>
            <personblurb>
                <para>Elisa Beshero-Bondar explores and teaches document data modeling with the XML
                    family of languages. She serves on the TEI Technical Council and is the founder
                    and organizer of the <link xlink:href="https://digitalmitford.org"
                        xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">Digital
                        Mitford project</link> and <link
                        xlink:href="https://digitalmitford.github.io/DigMitCS/" xlink:type="simple"
                        xlink:show="new" xlink:actuate="onRequest">its usually annual coding
                        school</link>. She experiments with visualizing data from complex document
                    structures like epic poems and with computer-assisted collation of differently
                    encoded editions of <link xlink:href="https://frankensteinvariorum.github.io/"
                        xlink:type="simple" xlink:show="new" xlink:actuate="onRequest"><emphasis
                            role="ital">Frankenstein</emphasis></link>. Her ongoing adventures with
                    markup technologies are documented on <link xlink:href="https://newtfire.org"
                        xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">her
                        development site at newtfire.org</link>. </para>
            </personblurb>
            <affiliation>
                <jobtitle>Chair</jobtitle>
                <orgname>TEI Technical Council</orgname>
            </affiliation>
            <affiliation>
                <jobtitle>Professor of Digital Humanities</jobtitle>
                <jobtitle>Program Chair of Digital Media, Arts, and Technology</jobtitle>
                <orgname>Penn State Erie, The Behrend College</orgname>
            </affiliation>
            <email>eeb4@psu.edu</email>
        </author>
        <keywordset role="author">
            <keyword>machine-assisted collation</keyword>
            <keyword>Python</keyword>
            <keyword>XSLT</keyword>

        </keywordset>
    </info>
    <section>
        <title>Introduction: Text tokenization and declarative methods in digital humanities</title>
        <para>Many scholars in the digital humanities work on natural language processing projects
            that involve us in tokenizing texts and applying software to study how they cluster and
            co-occur. Studies of term/token frequency-inverse document frequency (TF-IDF) are the
            basis of experiments like topic modeling, an approximate statistical effort to survey
                <quote>topics</quote> based on clustering of tokens. The practice of tokenizing
            texts is also fundamental to stylometry, to seek evidence of what patterns and
            clusterings make a voice distinctive. Among digital humanists who have spoken at the
            ADHO conference from 2015 onward, my own work on digital scholarly editions involves me
            much more than usual with declarative markup through XML and TEI.<footnote>
                <para>At least in 2017, topics connected to digital scholarly editions (and
                    connected to it, declarative markup) seems to have been on the decline. See
                    Scott Weingart, <quote>What’s Under the Big Tent?: A Study of ADHO Conference
                        Abstracts</quote>, Digital Studies/le Champ Numérique, 7(1), 6. DOI: <link
                        xlink:href="http://doi.org/10.16995/dscn.284"
                        >http://doi.org/10.16995/dscn.284</link>. See also the questions raised
                    about the ADHO conference and its representation of the practice of
                        <quote>digital humanities</quote> in Laura Estill, Jennifer Giuliano, Élika
                    Ortega, Melissa Terras, Deb Verhoeven, and Glen Layne-Worthy, <quote>The circus
                        we deserve? A front row look at the organization of the annual academic
                        conference for the Digital Humanities</quote> DHQ: Digital Humanities
                    Quarterly 16:4 (2022). <link
                        xlink:href="A front row look at the organization of the annual academic conference for the Digital Humanities"
                        >http://www.digitalhumanities.org/dhq/vol/16/4/000643/000643.html</link>
                </para>
            </footnote> This apparent marginality in my field means I have a slightly unusual and
            persistently useful <quote>toolkit</quote> I have been using for a decade, and that I am
            also a resource for my colleagues when they need to learn these technologies. My work
            with declarative methods also allows me to enter the world of natural language
            processing and explore documents as my colleagues do where we share common areas of
            interest. These days I regularly move data from my marked-up documents into the realm of
            natural language processing to identify and analyze patterns. Such work tends to cycle
            from marked-up XML documents to strings for tokenization and processing, and then back
            into markup to frame the outputs for sharing and visualizing the data in SVG, XML,
            XHTML5.</para>
        <para>The cycle from declarative markup, to string-processing algorthims, and back to
            declarative markup for outputs is a fundamental aspect of my research and teaching. But
            for many in my field, only the string processing portion of this is relevant, as they
            are not regularly involved as I am with designing custom interfaces. When you work with
            digital scholarly editions, you think of interfaces and representation, and you also
            tend to work closely with lots of textual data drawn from single works or small
            collections, instead of at a distance from thousands or millions of documents treated as
                <quote>unstructured</quote> streams of tokenized data. I began my career in the
            United States in the 1990s in a literary and cultural field called
                <quote>English</quote>, and I know that many of my digital humanities colleagues
            invested in natural language processing share that background with me, and share much of
            my own migration experience into a institutional zones delineated <quote>digital
                humanities</quote> in our strange institutional adventures with computers. But I
            know that I think of texts quite differently than many of my digital humanist
            colleagues, simply because in the document modeling and research I do with digital
            scholarly editions, I am trying to do things with texts and declare things about texts
            that seem to be out of scope in their work (at least for now). Some of my analytical
            colleagues do express that declarative markup seems unnecessary in a time of big text
            data analytics, when declarations about the documents seem to encumber or inhibit
            projects at scale.<footnote>
                <para>Evidence of how my colleagues practicing digital humanities perceive
                    declarative markup in the time of AI can be seen in the author's January 2023
                    conversation with Ted Underwood on Mastodon:
                    https://sigmoid.social/@TedUnderwood/109730986869388754. The informal
                    conversation was sparked by a declaration that ChatGPT’s capacity to take text
                    input with instructions and output it marked in TEI also meant that eventually
                    there will be no more need for markup at all. In some ways this paper responds
                    to the challenge of that conversation, by an awareness that more needs to be
                    declared now about what we do with declarative methods and semantics.</para>
            </footnote> In this paper, I want to address the question of what declarative markup can
            do for us who engage in textual scholarship in the digital humanities.</para>
        <para>Because I am steeped in scholarly editing and a declarative markup
                <quote>specialization</quote> in the digital humanities, my efforts to test the chat
            interfaces of large language models reflect my distinct research interests in comparing
            and collating texts. I have learned something that highlights the authority and efficacy
            of declarative methods in text analysis, and I hope this is worth sharing with
            declarative markup specialists and their adjacent text-scholarly friends in the digital
            humanities. In this paper I will discuss a form of token-based text analysis that foils
            large language models consistently, and I will show how declarative markup, interacting
            with imperative programming, simply and profoundly makes that analysis possible to
            accomplish. This is a paper intended to demonstrate the importance of declarative
            authority in our text-analytic systems and to join a call for a more declarative
            approach to what is currently an unintelligent system for modeling language. </para>

    </section>

    <section>
        <title>Can AI help with my document collation?</title>
        <para>I have been working on a project over the past few years that has challenged me to
            explore, test, and refine a machine-assisted method for comparing versions of a text.
            The project involves comparing five versions of the novel
                <emphasis>Frankenstein</emphasis>, and the basis for comparing these versions
            includes the markup from editions that were coded differently. I have shared papers
            about these adventures over the past few Balisage meetings, including the fun of
            flattening and raising markup and the challenge of comparing strings that include
            representations of the markup in the editions.<footnote>
                <para>See among others, Elisa Beshero-Bondar, <quote>Adventures in Correcting XML
                        Collation Problems with Python and XSLT</quote>, Proceedings of Balisage:
                    The Markup Conference 2022. Balisage Series on Markup Technologies, vol. 27
                    (2022). <link
                        xlink:href="https://doi.org/10.4242/BalisageVol27.Beshero-Bondar01"
                        >https://doi.org/10.4242/BalisageVol27.Beshero-Bondar01</link>.</para>
            </footnote> Even when machine-assisted, document collation is tiring, tedious work. It
            is one thing to prepare an algorithm for comparison and apply it to good, adaptable
            software for the purpose, but it is quite another have to correct the output. That is
            where the real challenge begins: the intellectual challenge, mental discipline, or
                <quote>self-psych-out</quote> of <quote>machine-assisted</quote> collation: When do
            you give up trying to refine the software algorithm, and when to you
                <quote>crack</quote> and resort to hand-correcting problematic outputs? Sometimes
            giving up really slows down a project, and it is really possible to refine the method,
            but it requires patience and tinkering with the machinery, and the patience to continue
            testing. Would it not be wonderful for artificial intelligence to assist and accelerate
            this painstaking effort, if there could be a reliable way to train it to process text
            like an editor of a digital scholarly edition?</para>
        <para>The sensational public launch of ChatGPT on November 30, 2022 has sparked excitment,
            confusion, concern and a new surge of publications across academia and the public sector.<footnote>
                <para>This article documents a significant body of publications aided by, applying,
                    or investigating ChatGPT published between December 2022 and February 2023, just
                    the beginning of a scholarly surge of interest across disciplines in AI:
                    Zamfiroiu, Alin, Denisa Vasile, and Daniel Savu, <quote>ChatGPT – A Systematic
                        Review of Published Research Papers.</quote>
                    <emphasis>Informatica Economica</emphasis>, vol. 27, no. 1, 2023, pp. 5-16.
                        <link
                        xlink:href="http://revistaie.ase.ro/content/105/01%20-%20zamfiroiu,%20vasile,%20savu.pdf"
                        >http://revistaie.ase.ro/content/105/01%20-%20zamfiroiu,%20vasile,%20savu.pdf</link>.
                    Accessed 2023-07-22.</para>
            </footnote> ChatGPT has also motivated much fun, informal tinkering with prompts among
            my academic circles. We would ask for introductions of ourselves and our colleagues
            suitable for use in conferences and laugh at how ludricously wrong they are. (In one
            invented bio I am both a medievalist and a published poet, neither of which is true, but
            I could speculate that somehow the words associated with me in ChatGPT’s training had
            been in proximity with medievalist friends and people far more creative than me). Of
            course we also prompted it to invent supposedly serious bibliographies to see its
            made-up citations and fake URLs, too. At universities, teaching faculty worry about our
            students abusing generative AI to compose their papers, and possibilities for new
            approaches to the writing process. Academics who write computer programming code quickly
            discovered a supremely helpful aspect of ChatGPT for debugging code or quickly
            introducing how to access a software library on the fly. Once we have seen such
            benefits, we tend to recognize that our students should also cultivate skills to prompt
            AI—responsibly—for coding assistance. ChatGPT has saved time for me and my most
            dedicated students, time that we might otherwise have spent combing through
            documentation and Stack Overflow posts. Even when ChatGPT was wrong and its suggested
            code plainly did not work, it was leading us rapidly to the ad-hoc fixes we needed to
            make, and particularly with some knowledge coming in we could work with it in a dialogue
            and improve our understanding. </para>

        <para>Encouraged by such time-saving help, we have been eagerly experimenting all year with
            something that seems to promise the ultimate <emphasis>declarative</emphasis>
            possiblity: to directly ask a machine to deliver an output, without directing how it
            generates that output. The developers at OpenAI fondly aspire for their chat model to
            become: <quote>a very eager junior programmer</quote> to <quote>make completely new
                workflows effortless and efficient</quote>.<footnote>
                <para><quote><link
                            xlink:href="https://openai.com/blog/chatgpt-plugins#code-interpreter"
                            >ChatGPT plugins: Code interpreter</link></quote>, Chat GPT Blog.
                    2023.</para>
            </footnote> I wondered how well the grand new AI models might perform on the very task
            that has taken me and my colleagues and students years to refine: the machine-assisted
            collation of multiple versions of a work in the form of manuscripts and printed
            documents. The processes that underlie this involve aligning chunks of text, and a
            token-by-token processing of streams of text pulled from marked-up documents. The large
            language models supporting generative AI are themselves based on word embeddings and
            tokenized processing text streams. could the <quote>word arithmetic</quote> we associate
            with text-generative AI be applied to comparison algorithms? Would it <quote>just
                know</quote> how to optimize the most reasonable alignments and outputs? </para>
        <para>At various moments between January and July 2023, I began testing a hypothesis that a
            machine trained on tokenized strings and word embeddings should excel at the task of
            comparing strings, even tokenizing and normalizing them. My informal approach to
            conversational prompt engineering discussed in the following sections could likely be
            improved, but I do have specific requirements for an optimal collation in mind that I
            have been attempting to declare and discuss with text-generative chat interfaces, and
            the exercise has been instructive. Over the past several months in my prompt experiments
            to engage ChatGPT and Anthropic’s Claude in various permutations of this task, they not
            only been wanting, but remarkably and consistently so. The ways in which generative AI
            has bungled my series of string-comparison challenges may tell us something interesting
            about the limits of current large language models to correctly observe the differences
            between strings, and to express those differences in structured forms. The errors are
            illuminating in a way that demonstrates something seriously lacking in the
            text-generative system in 2023, and that is a fully declarative method of working with
            input and generating output.</para>


        <section>
            <title>What happens when we ask a large language model to compare strings?</title>
            <para>To begin to estimate whether AI could assist my collation work, I needed to work
                within the limits of ChatGPT’s input window. But just as I could ask it to proofread
                a paragraph or two for errors, surely I could provide some input strings and ask it
                to compare them, and show me how they differ.</para>


            <para><!-- Did you ask it to "diff" the strings?  YES--></para>

            <para>Experimenting with text-generative AI models in the previous months has
                illuminated a remarkable problem in evaluating text by the tokens that seems to be
                generated by two different understandings of <quote>text</quote>. Prepare three or
                four versions of a reasonably short text to for the chat interface to compare. Ask
                the chat to show you how they compare and where they differe, and see some
                remarkably strange results. Not only were the results almost always inaccurate, but
                on repeated prompts and requests for corrections, the AI could not be said to
                improve significantly. Even where there was some improvement, there were usually new
                inaccuracies introduced to the model's capacity to review the task at hand. </para>
            
            
            
             
          
        </section>
        <section>
            <title>From stochastic parrot to reasoning intelligence?</title>
            
            <para>As a human (read: limited, inconsistent) reader of texts I am in awe that a mathematically trained language model, a so-called "artificial intelligence" which I expect to be more consistent and adept at pattern recognition than , consistently struggles with what seems to be a simple comparison of strings. Is
                it a pre-programmed shortness of memory when asked to compare strings? I would
                venture that ChatGPT's current inability to analyze comparisons of strings has
                something to do with its token-by-token generative stream. ChatGPT can correctly
                tell me what Levenshtein (or edit-distance) distance is. <!-- DEFINE IT. --> The AI
                can also separate two different versions of a text in different boxes. But it cannot
                calculate the edit-distance and it cannot seem to pinpoint variations. In this
                specific task, the AI supplies the illusion of structure with some persistent (and
                to me still baffling) blindness. If we could identify the AI's blind-spot, I think
                it is failing to <quote>see</quote> what constitutes a reasonable, meaningful basis
                for comparison of text streams.</para>
            <para>In a conference presentation in 2015, Michael Sperberg-McQueen declares on slide
                8, <quote>Declarative semantics make it possible to reason about representations;
                    imperative semantics impede.</quote><footnote>
                        <para>https://blackmesatech.com/2015/10/KIaCiDH/#(8)</para>
                    </footnote> Today dialogue with generative language-based AI gives us the
                opportunity to declare and inquire with reason, but the stochastic outputs we
                receive sometimes seem to reflect an impedance, something blocking the path of
                reasoned representation. We can make a study of how far and how frequently and in
                what ways an AI gets something seriously wrong when it delivers us its reasonable
                and authoritative-sounding answers whose meaningful content is nevertheless outside
                the bounds of reason. We understand that prompt generation is based on statistical
                predictions of what might be the best-fit, reasonable next tokens of text to supply
                in sequence.<footnote>
                    <para>For unsophisticated novices like me, these articles have been particularly
                        helpful for gaining a basic appreciation of key concepts in text generative
                        AI: Haomiao Huang, <link
                            xlink:href="https://arstechnica.com/gadgets/2023/01/the-generative-ai-revolution-has-begun-how-did-we-get-here/"
                            ><quote>The generative AI revolution has begun—how did we get
                                here?</quote></link> Ars Technica 30 January 2023; Jay Alammar,
                        <link xlink:href="https://jalammar.github.io/illustrated-word2vec/"
                            ><quote>The Illustrated Word2Vec</quote></link> blog post, 27 March
                        2019. </para>
                    
                </footnote> We also understand the large-language models (LLMs) demonstrate bias
                because they amplify even the veiled language of racism and sexism that often goes
                nearly unheard or unmarked in everyday discourse of Wikipedia and Reddit and social media.<footnote>
                    <para>This Google Collab Notebook tutorial offers an accessible introduction to
                        gender and social class bias engrained in large language models: Shlomi Hod,
                        <quote>Tutorial // Exploring Gender Bias in Word Embedding</quote>
                        2018—. <link
                            xlink:href="https://colab.research.google.com/github/ResponsiblyAI/word-embedding/blob/main/tutorial-bias-word-embedding.ipynb"
                            >https://colab.research.google.com/github/ResponsiblyAI/word-embedding/blob/main/tutorial-bias-word-embedding.ipynb</link>.
                        This article details pervasive problema of gender bias in ChatGPT’s
                        translations from English to Farsi, Malay, Tagalog, Thai, and Turkish:
                        Sourojit Ghosh and Aylin Caliskan, <quote>ChatGPT Perpetuates Gender Bias in
                            Machine Translation and Ignores Non-Gendered Pronouns: Findings across
                            Bengali and Five other Low-Resource Languages</quote> Upcoming
                        Publication in AAAI/ACM Conference on AI, Ethics, and Society, 2023.</para>
                </footnote> Text-generative AI speaks with a language of authority and confidence
                and amplifies normative values in its predictions of the best fit content completion
                for a prompt. </para>
            <para>Nothing in our modeling of texts escapes bias, but our capacity to assert and test
                reasonable statements is a particular strength of declarative markup. In his 2015
                presentation, Sperberg-McQueen points out that hierarchical models are not neutral.
                The way we organize document hierarchies and decide on markup representations, and
                create schema rules to validate our models does not represent reflect absolute
                <quote>ground truth</quote>, but rather attempts to describe and define based on
                what choose to prioritize, whether that is the section headings of a legislative
                memo or the page-by-page printing of a comic book. The models we create for
                documents and the metadata we care about reflect the paradigms and priorities of the
                humans who create them. Document historians of the future may come back to our XML
                markup and find us benighted, but they could also research in our models the rules
                of our publishing houses, the attitudes and expectations that prevailed in
                understanding how to study language and archive our cultural heritage. The point is,
                what we express in declarative semantics is fully visible, tractable, and usually
                documented. It is explicitly and deliberately marked, while the biases amplified by
                large language models in our stochastic AI systems are revealed only by analyzing the
                outputs or attempting to source the now-secret training data.</para>
            

            
            <para> That seminal article from 1990 <quote>What is Text, Really?</quote> is striking
                in the year 2023 for how current it remains as a critique of prevailing technology
                systems for handling text.<footnote>
                    <para>Steven J. DeRose, David G. Durand, Elli Mylonas, Allen H. Renear,
                        <quote>What is Text, Really?</quote> 1990.</para>
                </footnote> Their proposition, that text really is an Ordered Hierarchy of Content
                Objects, comes explicitly as a response (among other things) to concepts of text as
                a stream of content objects, the gram particles and formmating instructions without
                reference to structural context. In the year 2023 when we ask questions to large
                language models we are given to understand that text is generated in response to the
                <quote>context window</quote> that model uses for perceiving the range of nearby
                tokens and their proximity to teh current token a frame of reference. Is it the case
                in 2023 that context in the large language model is being determined by frames of
                reference in a stream of text? When semantics is coded and decoded in vector space
                by position and co-occurrence, this generates the appearance of meaningful output,
                which may not be true but is nevertheless frequently deemed useful. This is the
                argument of the famous <quote>Stochastic Parrots</quote> article: that large language models distort, exploit, and waste resources in an effort only to produce unreliable and biased approximations. <footnote>
                    <para> For helpful introductions to how large language models work to generate text based on predictive algorithms, see On how meaning is predicted in large language models, see Jay Alammar,
                        <link xlink:href="http://jalammar.github.io/illustrated-transformer/"
                            ><quote>The Illustrated Transformer</quote></link> blog post. 27
                        June 2018; Molly Ruby <link
                            xlink:href="https://towardsdatascience.com/how-chatgpt-works-the-models-behind-the-bot-1ce5fca96286"
                            ><quote>How ChatGPT Works: The Model Behind The Bot</quote></link>,
                        in Towards Data Science. Medium. 30 January 2023. </para>
                </footnote> I </para>
            
            
          
            
            <para>
                <!-- What could make it better? 
           Mulitple articles suggest LLMs are proceeding in too linear/sequential a way
           Vector databases would allow for  graph structures, associations of metadata with data:
           https://www.pinecone.io/learn/vector-database/
           
           Tree of Thoughts: Deliberate Problem Solving with Large Language Models: https://arxiv.org/pdf/2305.10601.pdf
           This includes te complaint about left-to-right token-by-token processing, and need for more dimenensions: decision tree
           
           Length generalization problems: This piece seems to address why LLMs fall short and fail to fully solve problems: Can LLMs extrapolate from short examples to solve longer problems?  https://openreview.net/pdf?id=zSkYVeX7bC4 
       
            
            -->
            </para>   


            <para>What might it mean for a text-generative <quote>AI</quote> system to to operate in
                a fully declarative way? </para>
        </section>
    </section>
    <section>
        <title>How meaningful is markup, anyway?</title>

        <para>When the text-generative AI models composed the markup shared in the previous section,
            their declarative semantics were unclear and often inconsistent, particularly when the
            tags don't match the content. In my experiments, the logic of the generated markup
            betrays inconsistencies. Perhaps its purpose became diluted by other imperatives of the
            generative language algorithm. We could describe such output as expressing a middle
            state, a string bearing the forms of markup but with dubious declarative semantics. </para>
        <para>The way declarative logic is incorporated in a text-processing system matters. How
            deliberate can we be in applying it and generating the output we ask for? In its current
            form, I am finding AI to be limited in its capacities to handle declarative tasks.
            Handled differently, declarative logic can be processed in imperative programs without
            loss of their significance in the output. Transforming text into other formats shows us
            what is fluid and transferrable in markup. We map its structures into forms that
            machines need to read, and when we do that they become moveable bins or containers of
            information. The process has been vital to our collation project, where a deliberate
            declared logic for controlling the basis for comparison has been key to consistent
            processing. </para>


        <section>
            <title>Markup as declarative intervention in an imperative process</title>
            <para>The process of refining the collation process for the Frankenstein Variorum
                involved a serious challenge to stop the collateX software from its default
                mechanism, always to align the smallest particles of the same text. Adapting the
                pair-wise comparison model of Needleman Wunsch among others, the software definitely
                tends to align the smallest irreducible units of text (tokens) that it reads as
                    <quote>the same</quote>, like <quote>an</quote> and <quote>the</quote>, even in
                passages that are not meant to be associated across the texts.<footnote>
                    <para/>
                </footnote> Some of the versions of <citation>Frankenstein</citation> contain long
                inserted blocks, multi-paragraph inserted passages, and gaps in the manuscript that
                make alignment tricky. In the last year, my student Yuying Jin and I established a
                reliable method for bracketing these off in the last year that we call our
                    <quote>longToken</quote> strategy. Here we lengthen the size of the smallest
                particle of comparable text to the size of whatever we can express inside an XML
                element <code>&lt;longToken&gt;.....&lt;/longToken&gt;</code>. We instructed our
                Python script to isolate all tokens by newline characters, and set the entire length
                of longToken (which could be as small as a single character and as large as two
                paragraphs of text, including flattened markup) all in one irreducible line. By
                controlling the tokenization algorithm, we were able to control the mechanism of the
                collation software, prevent it from making spurious alignments on small words in a
                passage that we would effectively bracket away from micro-comparisons.</para>
            <para>Our Python script is a place of negotiation between paradigms of structured markup
                and so-called unstructured text. We use the <link
                    xlink:href="https://docs.python.org/3/library/xml.dom.pulldom.html">XML Pulldom
                    library</link> to process what markup from the source documents we want to
                include in the string comparison process. That is, we mask away some elements, like
                the page <code>&lt;surface&gt;</code> and <code>&lt;zone&gt;</code> elements that
                indicate page surfaces and locations on the pages from the Shelley-Godwin Archive
                encoding, because we have decided that page position is not relevant to comparison
                of the semantic text structure. But we want to preserve the element nodes that mark
                paragraphs, and chapter structures, and we want to preserve the information about
                deletion marks in the manuscript and from the Thomas copy. The word
                    <quote>mask</quote> seems appropriate here: it's something like applying tape to
                pieces of the file that we select. We continue to work with the markup, though, in
                its meaningful form. In the Python script, we define variables containing lists of
                element names that we will either mask away from the collation, or that we will
                include: <programlisting>
            ignore = ['sourceDoc', 'xml', 'comment', 'include', 'addSpan', 'handShift', 'damage', 
                'unclear', 'restore', 'surface', 'zone', 'retrace']
            blockEmpty = ['p', 'div', 'milestone', 'lg', 'l', 'cit', 'quote', 'bibl']
            inlineEmpty = ['mod', 'pb', 'sga-add', 'delSpan', 'anchor', 'lb', 'gap', 
                 'hi', 'w', 'ab']
            inlineContent = ['del-INNER', 'add-INNER', 'metamark', 'shi']
            inlineVariationEvent = ['head', 'del', 'mdel', 'add', 'note', 'longToken']
                </programlisting> The <code>ignore</code> variable contains
                everything we are screening away from the stream of text comparison. The other
                variables represent elements types we will see in the input. This input contains
                some recognizable elements from the TEI, but <code>&lt;p&gt;</code>,
                    <code>&lt;lg&gt;</code>, and <code>&lt;l&gt;</code> are defined in the
                    <code>blockEmpty</code> list, along with <code>&lt;milestone&gt;</code>, which
                is the only element that those knowledgeable of the TEI would recognize as
                legitimately empty.</para>
            <para>What have we done to the TEI? Perhaps a sacrilege, but we are meddling with TEI
                XML files as after all text files bearing meaningful markup, and we have converted
                their element nodes into a format that allows us to compare texts based on their
                original structures by removing the structures to process the comparison.</para>
        </section>
        <section>
            <title>Transferring and preserving declared semantics</title>
            <para>In preparing our editions for collation (as discussed in previous Balisage
                papers), we have <quote>flattened</quote> the original TEI structural elements, and
                abstracted them away from their original document models. We do this on purpose to
                represent the element tags as Trojan-style markers and to be able to work them into
                our a new XML file that stores a standoff critical apparatus in TEI. That file
                represents the results of our collation pipeline, and it stores a flattened
                representation of the tags from the source editions. The standoff critical apparatus
                serves, also, as a basis for creating new edition files that store the collation
                data, highlighting passages that vary with the other editions.</para>
            <para>In this process, detailed elsewhere, the semantics of the declarative markup from
                the source files are preserved even while that markup has undergone a complicated
                series of transformations. First it is transferred into strings or a stream of text
                in order to be collated, and then that stream of text is mapped back again into new
                XML structures to represent the meaningful data in the critical apparatus about how
                the texts compare to one another.</para>
            <para>Moving in between text-processing paradigms illuminates a transfer of semantics
                into format. The logic of declarative markup is preserved in the Python function
                running the pull parser via the XML Pulldom library. This function delivers us a way
                to transfer the logic of the markup element nodes into the formatting used to
                prepare the tokens and normalized tokens to be delivered to the collateX software.
                <programlisting>
                    def extract(input_xml):
    """Process entire input XML document, firing on events"""
    # Start pulling; it continues automatically
    doc = pulldom.parse(input_xml)
    output = ''
    for event, node in doc:
        if event == pulldom.START_ELEMENT and node.localName in ignore:
            continue
        # copy comments intact
        # if event == pulldom.COMMENT:
        #     doc.expandNode(node)
        #     output += node.toxml()
        # ebb: The following handles our longToken and longToken-style elements:
        # complete element nodes surrounded by newline characters to make a long complete token:
        if event == pulldom.START_ELEMENT and node.localName in inlineVariationEvent:
            doc.expandNode(node)
            output += '\n' + node.toxml() + '\n'
        # stops the problem of forming tokens that fuse element tags to words.
        elif event == pulldom.START_ELEMENT and node.localName in blockEmpty:
            output += '\n' + node.toxml() + '\n'
        # ebb: empty inline elements that do not take surrounding white spaces:
        elif event == pulldom.START_ELEMENT and node.localName in inlineEmpty:
            output += node.toxml()
        # non-empty inline elements: mdel, shi, metamark
        elif event == pulldom.START_ELEMENT and node.localName in inlineContent:
            output += '\n' + regexEmptyTag.sub('>', node.toxml())
            # output += '\n' + node.toxml()
        elif event == pulldom.END_ELEMENT and node.localName in inlineContent:
            output += '&lt;/' + node.localName + '&gt;' + '\n'
        # elif event == pulldom.START_ELEMENT and node.localName in blockElement:
        #    output += '\n&lt;' + node.localName + '&gt;\n'
        # elif event == pulldom.END_ELEMENT and node.localName in blockElement:
        #    output += '\n&lt;/' + node.localName + '>'
        elif event == pulldom.CHARACTERS:
            # output += fixToken(normalizeSpace(node.data))
            output += normalizeSpace(node.data)
        else:System ID: /Users/eeb4/Documents/GitHub/fv/collationWorkspace/collationChunks/C08/output/Collation_C08-complete.xml
Description: 
XPath location: /cx:apparatus[1]/app[54]
Start location: 667:2
End location: 699:8

            continue
    return output</programlisting> The <quote>partial DOM tree</quote> constructed
                by XML PullDom serializes something resonant with the semantics of explicit markup,
                allowing us in our project to hold the logic and even the structure of markup as a
                stream of text to be tokenized, chopped into the smallest fragments of meaningful
                variation. Thanks to the advantage of declarative markup, the scholarly editor gets
                to declare what that smallest fragment can be. A full element node marking an
                    <code>inlineVariationEvent</code> surrounded by <code>\n</code> newline
                characters becomes an irreducible token in , and this includes the
                    <code>&lt;longToken&gt;</code>, <code>&lt;add&gt;</code>, and
                    <code>&lt;del&gt;</code> elements that in our project mark irreducible units of
                comparison. We want an entire added or deleted passage to be lined up complete as
                one action in the text. It must be compared to a full comparable unit marked in the
                other documents, fully undeleted. That is a decision of our scholarly edition work
                to handle collation events, and it means that a deletion event followed by an
                insertion event in the Thomas text (where the author crossed out a passage and
                indicated another to add) effectively drives the collation software to generate a
                specially shaped entry in our critical apparatus. We have programmed our work to
                prepare this output: <programlisting>
               &lt;app&gt;
		&lt;rdgGrp
			n="['&lt;del&gt;to his statement, which was delivered&lt;/del&gt;', 'to him with interest for he spoke']"&gt;
			&lt;rdg wit="fThomas"&gt;&lt;del rend="strikethrough"&gt;to his statement, which was
				delivered&lt;/del&gt; &lt;add&gt;to him with interest for he spoke&lt;/add&gt;&lt;/rdg&gt;
		&lt;/rdgGrp&gt;
		&lt;rdgGrp n="['to his statement, which was delivered']"&gt;
			&lt;rdg wit="f1818"&gt;&lt;longToken&gt;to his statement, which was
				delivered&lt;/longToken&gt;&lt;/rdg&gt;
			&lt;rdg wit="f1823"&gt;&lt;longToken&gt;to his statement, which was
				delivered&lt;/longToken&gt;&lt;/rdg&gt;
			&lt;rdg wit="f1831"&gt;&lt;longToken&gt;to his statement, which was
				delivered&lt;/longToken&gt;&lt;/rdg&gt;
		&lt;/rdgGrp&gt;
	&lt;/app&gt;</programlisting> This output from collateX is formatted according to
                the TEI XML critical apparatus to express the logic of elements storing variation
                information across five source edition files. A moment of meaningful variation is
                stored in an <code>&lt;app&gt;</code> element, and each of uts
                    <code>&lt;rdg&gt;</code> descendants stores a single token representing the text
                of one witness, here a phrase that we purposefully blocked off to be an irreducible
                unit of comparison using the <code>&lt;longToken&gt;</code> element. You can see the
                trace of the longToken elements in the <code>&lt;rdg&gt;</code> text nodes, while
                the <code>@n</code> attribute on the <code>&lt;rdgGrp</code> elements serves to
                express how the collation software normalizes each token to show on what basis the
                    <code>&lt;rdg&gt;</code> elements inside are understood to agree: the trace of
                the longToken element is removed there because it is not itself part of the string
                we ask the collation software to compare. </para>


            <para>In the example, the collation software follows our normalizing algorithm to
                determine that three of the witnesses share one form, and the Thomas edition holds
                the same passage crossed out together with its complete replacement. Here,
                declarative markup provides a precise way to delineate information on what
                constitutes an indivisible token to the software. With the demarcation of a
                    <code>&lt;longToken&gt;</code> I can bracket off passages of text and force the
                software to deal with them on my terms. This gives us control of a process of
                pair-wise comparisons by allowing us to alter the usual definition of the smallest
                unit of meaningful variation. Declarative markup thus permits us to express our
                theory of textual variation in the logic of the programming pipeline. Certainly we
                did something unorthodox with the machinery of comparing texts and we invented our
                own markup outside the TEI to declare what a token could be, and I want to call this
                a deliberate, <emphasis>declarative intervention</emphasis> in the imperative
                algorithms. </para>


            <para>This presupposes that the imperative tools can read the declarations, and
                accommodate the markup. For this capacity in our project, we flatten the element
                nodes into strings and identify those as regular expression patterns for processing.
                In our project we raise them again into elements with an XSLT pipeline, here fully
                relying on declarative methods to communicate our desired output. But in the crucial
                stage of collation, when texts must be handled as sequential strings and imperative
                processes are requird for calculations of alignment and comparison, the handling of
                markup as patterns in imperative programs offers a modicum of authority and control
                of the output.</para>
        </section>


    </section>
    <section>
        <title>Conclusion</title>
        <para><!-- Sum up the findings --> ChatGPT promised a kind of declarative affordance and
            declares to us its results, but its declarations are neither consistent nor reasonable.
            Perhaps a more adaptable algorithm for AI would allow for declarative mechanisms to
            control the logic of its operations. </para>

        <para>In a moment of eager excitement, confusion, and fear about the potential disruptive
            influences of generative language models, markup technologies provide reliable precision
            and control. They allow us to intervene and guide computational processes within
            declarative bounds of reason. Declarative methods can provide a foundation for a digital
            humanities lab like mine to counterbalance the anxiety-ridden speculative work of
            statistically-based <quote>distant reading</quote>, to extend what digital resources we
            can create, and to ground the authority of our research. When the calculations and
            training capacities of a large language model are subject to rapid change with the next
            month's update, and when developers of generative language models conceal their sources
            for commercial reasons and do not share their transformer architectures openly, we would
            do well to inspect our tools and research methods for brittle dependencies. Declarative
            markup proves itself a precision instrument to guide computational processing and may
            help to address the ephemerality of unstable technology stacks.</para>
    </section>

</article>
