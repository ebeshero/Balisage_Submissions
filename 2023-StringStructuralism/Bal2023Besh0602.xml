<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="balisage-1-5.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="balisage-1-5.rng" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<?xml-stylesheet type="text/xsl" href="balisage-proceedings-html.xsl"?>
<article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink"
    version="5.0-subset Balisage-1.5">

    <title>Markup and migratory workflows in the context of AI and big data analytics</title>
    <subtitle>Reflections on the data modeling groundwork of the digital humanities</subtitle>
    <info>
        <abstract>

            <para>Can large language models, working with tokenized text, effectively compare strings and accurately model the comparison in structured forms like alignment tables and the TEI critical apparatus? The answer is no, or not very well, but that answer helps to illuminate a remarkable strength and versatility of declarative markup, when deliberately introduced to imperative programs. We can see how declarative methods control the imperative machinery of a complex collation process in the Frankenstein Variorum project. The key question or provocation is whether <quote>artificial intelligence</quote> in our time can be improved by returning to its declarative origins, to make room for the authority of domain experts to control an otherwise unwieldy stochastic process that poses as a voice of reason.</para>

        </abstract>
        <author>
            <personname>
                <firstname>Elisa</firstname>
                <othername>E.</othername>
                <surname>Beshero-Bondar</surname>
            </personname>
            <personblurb>
                <para>Elisa Beshero-Bondar explores and teaches document data modeling with the XML
                    family of languages. She serves on the TEI Technical Council and is the founder
                    and organizer of the <link xlink:href="https://digitalmitford.org"
                        xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">Digital
                        Mitford project</link> and <link
                        xlink:href="https://digitalmitford.github.io/DigMitCS/" xlink:type="simple"
                        xlink:show="new" xlink:actuate="onRequest">its usually annual coding
                        school</link>. She experiments with visualizing data from complex document
                    structures like epic poems and with computer-assisted collation of differently
                    encoded editions of <link xlink:href="https://frankensteinvariorum.github.io/"
                        xlink:type="simple" xlink:show="new" xlink:actuate="onRequest"><emphasis
                            role="ital">Frankenstein</emphasis></link>. Her ongoing adventures with
                    markup technologies are documented on <link xlink:href="https://newtfire.org"
                        xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">her
                        development site at newtfire.org</link>. </para>
            </personblurb>
            <affiliation>
                <jobtitle>Chair</jobtitle>
                <orgname>TEI Technical Council</orgname>
            </affiliation>
            <affiliation>
                <jobtitle>Professor of Digital Humanities</jobtitle>
                <jobtitle>Program Chair of Digital Media, Arts, and Technology</jobtitle>
                <orgname>Penn State Erie, The Behrend College</orgname>
            </affiliation>
            <email>eeb4@psu.edu</email>
        </author>
        <keywordset role="author">
            <keyword>artificial intelligence</keyword>
            <keyword>AI</keyword>
            <keyword>large language model</keyword>
            <keyword>LLM</keyword>
            <keyword>declarative markup</keyword>
            <keyword>declarative methods</keyword>
            <keyword>imperative methods</keyword>
            <keyword>TEI</keyword>
            <keyword>Text Encoding Initiative</keyword>
            <keyword>tokenization</keyword>
            <keyword>normalization</keyword>
            <keyword>machine-assisted collation</keyword>
            <keyword>Python</keyword>
            <keyword>XSLT</keyword>
        </keywordset>
    </info>
    <section>
        <title>Introduction: Text tokenization and declarative methods in digital humanities</title>
        <para>Many scholars in the digital humanities work on natural language processing projects
            that involve tokenizing texts and applying software to study how they cluster and
            co-occur. Studies of term/token frequency-inverse document frequency (TF-IDF) are the
            basis of experiments like topic modeling, an approximate statistical effort to survey
                <quote>topics</quote> based on clustering of tokens. The practice of tokenizing
            texts is also fundamental to stylometry, to seek evidence of what patterns and
            clusterings make a voice distinctive. Among digital humanists who have spoken at the
            ADHO conference from 2015 onward, my own work on digital scholarly editions involves me
            much more than usual with declarative markup through XML and TEI.<footnote>
                <para>At least in 2017, topics connected to digital scholarly editions (and
                    connected to it, declarative markup) seems to have been on the decline. See
                    Scott Weingart, <quote>What’s Under the Big Tent?: A Study of ADHO Conference
                        Abstracts</quote>, Digital Studies/le Champ Numérique, 7(1), 6. DOI: <link
                        xlink:href="http://doi.org/10.16995/dscn.284"
                        >http://doi.org/10.16995/dscn.284</link>. See also the questions raised
                    about the ADHO conference and its representation of the practice of
                        <quote>digital humanities</quote> in Laura Estill, Jennifer Giuliano, Élika
                    Ortega, Melissa Terras, Deb Verhoeven, and Glen Layne-Worthy, <quote>The circus
                        we deserve? A front row look at the organization of the annual academic
                        conference for the Digital Humanities</quote> DHQ: Digital Humanities
                    Quarterly 16:4 (2022). <link
                        xlink:href="A front row look at the organization of the annual academic conference for the Digital Humanities"
                        >http://www.digitalhumanities.org/dhq/vol/16/4/000643/000643.html</link>
                </para>
            </footnote> This apparent marginality in my field means I have a slightly unusual and
            persistently useful <quote>toolkit</quote> I have been using for a decade, and that I am
            also a resource for my colleagues when they need to learn these technologies. My work
            with declarative methods also allows me to enter the world of natural language
            processing and explore documents as my colleagues do where we share common areas of
            interest. These days I regularly move data from my marked-up documents into the realm of
            natural language processing to identify and analyze patterns. Such work tends to cycle
            from marked-up XML documents to strings for tokenization and processing, and then back
            into markup to frame the outputs for sharing and visualizing the data in SVG, XML,
            XHTML5.</para>
        <para>The cycle from declarative markup, to string-processing algorthims, and back to output
            declarative markup is a fundamental aspect of my research and teaching. But for many in
            my field, only the string processing portion of this is relevant, as they are not
            regularly involved as I am with designing custom interfaces. When you work with digital
            scholarly editions, you think of interfaces and representation, and you also tend to
            work closely with lots of textual data drawn from single works or small collections,
            instead of at a distance from thousands or millions of documents treated as
                <quote>unstructured</quote> streams of tokenized data. I began my career in the
            United States in the 1990s in a literary and cultural field called
                <quote>English</quote>, and I know that many of my digital humanities colleagues
            invested in natural language processing share that background with me, and share much of
            my own migration experience into zones delineated <quote>digital
                humanities</quote> in our strange institutional adventures with computers. But I
            think of texts quite differently than many of my digital humanist colleagues do, simply
            because in my document modeling and research with digital scholarly editions, I am
            processing texts in ways that seem to be out of scope in their work (at least for now).
            Some of my analytical colleagues opine that declarative markup seems unnecessary in a
            time of big text data analytics, particularly when the making of declarations about the
            document form and content seems to encumber or inhibit projects at scale. The
            classifications and categorizations made by AI should be able to do the work of markup
            or render it obsolete.<footnote>
                <para>Evidence of how my colleagues practicing digital humanities perceive
                    declarative markup in the time of AI can be seen in the author's January 2023
                    conversation with Ted Underwood on Mastodon:
                    <link xlink:href="https://sigmoid.social/@TedUnderwood/109730986869388754">https://sigmoid.social/@TedUnderwood/109730986869388754</link>. The informal
                    conversation was sparked by a declaration that ChatGPT’s capacity to take text
                    input with instructions and output it marked in TEI also meant that eventually
                    there will be no more need for markup at all. In some ways this paper responds
                    to the challenge of that conversation.</para>
            </footnote> In this paper, I want to address the question of what declarative markup can
            do for us who engage in textual scholarship in the digital humanities. More needs to be
            declared just now about what we do with declarative methods and semantics and how they
            might assist the efforts of AI in our time.</para>
        <para>Because I am steeped in scholarly editing and a declarative markup
                <quote>specialization</quote> in the digital humanities, my efforts to test the chat
            interfaces of large language models reflect my distinct research interests in comparing
            and collating texts. Over the course of this year, I have realized something about the
            authority and efficacy of declarative methods in text analysis, and I hope this
            realization is worth sharing with declarative markup specialists and their adjacent
            text-scholarly friends in the digital humanities. In this paper I will discuss a form of
            token-based text analysis that consistently foils large language models, and I will show
            how declarative markup, interacting with imperative programming, simply and profoundly
            makes that analysis possible to accomplish. This is a paper intended to demonstrate the
            importance of declarative authority in our text-analytic systems and to join a call for
            a more declarative approach to what is currently an unintelligent (so-called
                <quote>AI</quote>) system for modeling language.</para>

    </section>

    <section>
        <title>Can AI help with my document collation?</title>
        <para>I have been working on a project over the past few years that has challenged me to
            explore, test, and refine a machine-assisted method for comparing versions of a text.
            The project involves comparing five versions of the novel
                <emphasis>Frankenstein</emphasis>, and the basis for comparing these versions
            includes the markup from editions that were coded differently. I have shared papers
            about these adventures over the past few Balisage meetings, including the fun of
            flattening and raising markup and the challenge of comparing strings that include
            representations of the markup in the editions.<footnote>
                <para>See among others, Elisa Beshero-Bondar, <quote>Adventures in Correcting XML
                        Collation Problems with Python and XSLT</quote>, Proceedings of Balisage:
                    The Markup Conference 2022. Balisage Series on Markup Technologies, vol. 27
                    (2022). <link
                        xlink:href="https://doi.org/10.4242/BalisageVol27.Beshero-Bondar01"
                        >https://doi.org/10.4242/BalisageVol27.Beshero-Bondar01</link>.</para>
            </footnote> Even when machine-assisted, document collation is tiring, tedious work. It
            is one thing to prepare an algorithm for comparison and apply it to good, adaptable
            software for the purpose, but it is quite another have to correct the output. That is
            where the real challenge begins, the intellectual challenge, mental discipline, or
                <quote>self-psych-out</quote> of <quote>machine-assisted</quote> collation: When do
            you give up trying to refine the software algorithm, and when do you
                <quote>crack</quote> and resort to hand-correcting problematic outputs? Sometimes
            giving up really slows down a project, when it is still possible to refine the method. Not giving up on the process requires patience and tinkering with the machinery, and the patience to continue
            testing. Would it not be wonderful for artificial intelligence to assist and accelerate
            this painstaking effort, if there could be a reliable way to train it to process text
            like an editor of a digital scholarly edition?</para>
        <para>The sensational public launch of ChatGPT on November 30, 2022 has sparked excitment,
            confusion, concern and a new surge of publications across academia and the public sector.<footnote>
                <para>This article documents a significant body of publications aided by, applying,
                    or investigating ChatGPT published between December 2022 and February 2023, just
                    the beginning of a scholarly surge of interest across disciplines in AI:
                    Zamfiroiu, Alin, Denisa Vasile, and Daniel Savu, <quote>ChatGPT – A Systematic
                        Review of Published Research Papers.</quote>
                    <emphasis>Informatica Economica</emphasis>, vol. 27, no. 1, 2023, pp. 5-16.
                        <link
                        xlink:href="http://revistaie.ase.ro/content/105/01%20-%20zamfiroiu,%20vasile,%20savu.pdf"
                        >http://revistaie.ase.ro/content/105/01%20-%20zamfiroiu,%20vasile,%20savu.pdf</link>.
                    Accessed 2023-07-22.</para>
            </footnote> ChatGPT has also given us much fun with prompt experiments among
            my academic circles. We would ask for introductions of ourselves and our colleagues
            suitable for use in conferences and laugh at how ludricously wrong they are. (In one
            invented bio I am both a medievalist and a published poet, neither of which is true, but
            I could speculate that somehow the words associated with me in ChatGPT’s training had
            been in proximity with medievalist friends and people far more creative than me). Of
            course we also prompted it to invent supposedly serious bibliographies to see its
            made-up citations and fake URLs, too. At universities, teaching faculty worry about our
            students abusing generative AI to compose their papers, and possibilities for new
            approaches to the writing process. Academics who write computer programs quickly
            discovered a supremely helpful aspect of ChatGPT for debugging code or quickly
            introducing how to access a software library on the fly. Once we have seen such
            benefits, we tend to recognize that our students should also cultivate skills to prompt
            AI—responsibly—for coding assistance. ChatGPT has saved time for me and my most
            dedicated students, time that we might otherwise have spent combing through
            documentation and Stack Overflow posts. Even when ChatGPT was wrong and its suggested
            code plainly did not work, it was leading us rapidly to the ad-hoc fixes we needed to
            make, and particularly with some knowledge coming in we could work with it in a dialogue
            and improve our understanding. </para>

        <para>Encouraged by such time-saving coding assistance, my colleagues, students, and I have
            been eagerly experimenting all year with something that seems to promise the ultimate
                <emphasis>declarative</emphasis> possiblity: to directly ask a machine to deliver an
            output, without directing how it generates that output. The developers at OpenAI fondly
            aspire for their chat model to become: <quote>a very eager junior programmer</quote> to
                <quote>make completely new workflows effortless and efficient</quote>.<footnote>
                <para><quote><link
                            xlink:href="https://openai.com/blog/chatgpt-plugins#code-interpreter"
                            >ChatGPT plugins: Code interpreter</link></quote>, Chat GPT Blog.
                    2023.</para>
            </footnote> I wondered how well the grand new AI models might perform on the very task
            that has taken me and my colleagues and students years to refine: the machine-assisted
            collation of multiple versions of a work in the form of manuscripts and printed
            documents. The processes that underlie this involve aligning chunks of text, and a
            token-by-token processing of streams of text pulled from marked-up documents. The large
            language models supporting generative AI are themselves based on word embeddings and
            tokenized processing text streams. could the <quote>word arithmetic</quote> we associate
            with text-generative AI be applied to comparison algorithms? Would it <quote>just
                know</quote> how to optimize the most reasonable alignments and outputs? </para>
        <para>At various moments between January and July 2023, I began testing a hypothesis that a
            machine trained on tokenized strings and word embeddings should excel at the task of
            token-by-token comparison of strings. My informal approach to conversational prompt
            engineering discussed in the following sections could likely be improved, but I do have
            specific requirements for an optimal collation in mind that I have been attempting to
            declare and discuss with text-generative chat interfaces, and the exercise has been
            instructive. Over the past several months in my prompt experiments to engage ChatGPT and
            Anthropic’s Claude in various permutations of this task, they have not only been wanting, but
            remarkably and consistently so. The ways in which generative AI has bungled my series of
            string-comparison challenges may tell us something interesting about the limits of
            current large language models to correctly observe the differences between strings, and
            to express those differences in structured forms. The errors are illuminating in a way
            that demonstrates something seriously lacking in the text-generative system in 2023, and
            that is a fully declarative method of working with input and generating output.</para>


        <section>
            <title>What happens when we ask a large language model to compare strings?</title>
            <para>To begin to estimate whether AI could assist my collation work, I needed to work
                within the limits of ChatGPT’s input window. But just as I could ask it to proofread
                a paragraph or two for errors, surely I could provide some input strings and ask it
                to compare them, and show me how they differ. In no case did I ever receive
                reliable, accurate results, but the kinds of errors I saw were interesting to try to
                diagnose the basis of error. Here I share a representative sampling of the
                experiments.<footnote><para>I accessed ChatGPT from January through July 2023 from <link xlink:href="https://chat.openai.com/">https://chat.openai.com/</link></para></footnote></para>

            <para>In some of my experiments, I simply requested that ChatGPT present me a table
                showing me how two versions of a text align. In this prompt, I indicated that two
                editions share a version, and a manuscript presents a different version. I was
                curious to see how the AI would handle two versions shared by three documents. <blockquote>
                    <title>Elisa:</title>
                    <para>Can you prepare a data structure to show where these texts are the same
                        and where they differ?</para>

                    <para>Manuscript: It was on a dreary night of November that I beheld the frame
                        on which my man compleated. And with an anxiety that almost amounted to
                        agony I collected instruments of life around me that I might infuse a spark
                        of being into the lifeless thing that lay at my feet.</para>

                    <para>1818 edition and 1831 edition: It was on a dreary night of November, that
                        I beheld the accomplishment of my toils. With an anxiety that almost
                        amounted to agony, I collected the instruments of life around me, that I
                        might infuse a spark of being into the lifeless thing that lay at my
                        feet.</para>
                </blockquote>
                <blockquote>
                    <title>ChatGPT:</title>
                    <para>To compare the texts and visualize the similarities and differences, you
                        can use a data structure such as a table or a side-by-side comparison.
                        Here's an example of how you can represent the texts:</para>
                    <programlisting>
+---------------------+---------------------------+-------------------------+
|       Manuscript     |      1818 edition         |     1831 edition        |
+---------------------+---------------------------+-------------------------+
| It was on a dreary  | It was on a dreary        | It was on a dreary      |
| night of November   | night of November         | night of November       |
| that I beheld the   | that I beheld the         | that I beheld the       |
| frame on which my   | accomplishment of my      | accomplishment of my    |
| man compleated.     | toils.                    | toils.                  |
| And with an anxiety | With an anxiety that      | With an anxiety that    |
| that almost amounted| almost amounted to agony, | almost amounted to agony|
| to agony I collected| I collected the           | I collected the         |
| instruments of life | instruments of life       | instruments of life     |
| around me that I    | around me,                | around me,              |
| might infuse a spark| that I might infuse a     | that I might infuse a   |
| of being into the   | spark of being into the   | spark of being into the |
| lifeless thing that | lifeless thing that lay   | lifeless thing that lay |
| lay at my feet.     | at my feet.               | at my feet.             |
+---------------------+---------------------------+-------------------------+

                    </programlisting>
                    <para>In this representation, each row corresponds to a line of text, and the
                        columns represent the different versions: Manuscript, 1818 edition, and 1831
                        edition. The matching text is aligned vertically, allowing you to see where
                        the texts are the same and where they differ.</para>

                    <para> By comparing the texts using this structure, you can easily identify the
                        variations between the Manuscript, 1818 edition, and 1831 edition.</para>

                </blockquote> Here I was pleased to see that ChatGPT understood that I wanted to
                represent three editions, although I was surprised that it did nothing besides block
                the text into a single row. I asked for ChatGPT to refine the table. <blockquote>
                    <title>Elisa:</title>
                    <para>Let's try to refine this. Where the texts are identical, just show one
                        block of text on the screen. Then when the texts are different, use the
                        table to put the differences side by side.</para>
                </blockquote>
                <blockquote>
                    <title>ChatGPT:</title>
                    <para>Sure! Let's refine the representation to show the identical text blocks
                        once and use a table to display the differing portions side by side. Here's
                        an updated representation:</para>
                    <programlisting>
                    Identical <emphasis role="under">text</emphasis>:
-------------------------
It was <emphasis role="under">on</emphasis> a dreary night <emphasis role="under">of</emphasis> November

<emphasis role="under">Text</emphasis> differences:
+---------------------+---------------------------+-------------------------+
|       Manuscript     |      1818 edition         |     1831 edition        |
+---------------------+---------------------------+-------------------------+
| that I beheld the   | that I beheld the         | that I beheld the       |
| accomplishment <emphasis role="under">of</emphasis> my| accomplishment <emphasis role="under">of</emphasis> my      | accomplishment <emphasis role="under">of</emphasis> my    |
| toils.              | toils.                    | toils.                  |
| <emphasis role="under">With</emphasis> an anxiety that| <emphasis role="under">With</emphasis> an anxiety that      | <emphasis role="under">With</emphasis> an anxiety that    |
| almost amounted <emphasis role="under">to</emphasis>  | almost amounted <emphasis role="under">to</emphasis> agony, | almost amounted <emphasis role="under">to</emphasis> agony|
| agony I collected   | I collected the           | I collected the         |
| instruments <emphasis role="under">of</emphasis> life | instruments <emphasis role="under">of</emphasis> life       | instruments <emphasis role="under">of</emphasis> life     |
| around <emphasis role="under">me</emphasis>, that I   | around <emphasis role="under">me</emphasis>,                | around <emphasis role="under">me</emphasis>,              |
| might infuse a spark| that I might infuse a     | that I might infuse a   |
| <emphasis role="under">of</emphasis> being <emphasis role="under">into</emphasis> the   | spark <emphasis role="under">of</emphasis> being <emphasis role="under">into</emphasis> the   | spark <emphasis role="under">of</emphasis> being <emphasis role="under">into</emphasis> the |
| lifeless thing that | lifeless thing that lay   | lifeless thing that lay |
| lay at my feet.     | at my feet.               | at my feet.             |
+---------------------+---------------------------+-------------------------+
  
                </programlisting>

                    <para>In this refined representation, the identical text block "It was on a
                        dreary night of November" is displayed once at the top, indicating that this
                        portion is the same in all versions. The table below then shows the
                        differing text portions side by side, highlighting the variations between
                        the Manuscript, 1818 edition, and 1831 edition.</para>

                </blockquote> Here I am applying underlined emphasis to show what ChatGPT delivered
                in blue color-coded CSS to highlight what it calls <quote>variations</quote> between
                the editions. A few strange things have happened. First the language model does
                correctly indicate that the first portion of the string is identical. But it misses
                the difference that there is a comma in the 1818 and 1831 versions, and simply does
                not represent the comma, so we have dropped a small token of text. Next in the
                table, we completely miss the variant passage from the manuscript: <quote>the frame
                    on which my man compleated. And</quote>. Instead ChatGPT represents the
                manuscript text as the same block that it provides for the other two. Is it
                forgetting the differences? Yet is seems to understand that some indication of
                differences is expected, and it highlights words of between two and four characters
                long that are identical in the gthree passages it blocked. This is distressingly
                inaccurate, but enough to raise questions of how it can be determining what to
                highlight.</para>
            <para>I tried again with this experiment. I understood that ChatGPT’s memory might well
                be too short to handle the text processing completely, but I wondered whether it
                could improve its response, much as we can prod it to help us debug our code, and
                whether it might help to remind it of the source texts again. <blockquote>
                    <title>Elisa:</title>
                    <para>Your approach is what I had in mind, good. But you've forgotten where the
                        source texts are different. Can you redo this, taking another look at the
                        source texts?</para>

                    <para>Manuscript: It was on a dreary night of November that I beheld the frame
                        on which my man compleated. And with an anxiety that almost amounted to
                        agony I collected instruments of life around me that I might infuse a spark
                        of being into the lifeless thing that lay at my feet.</para>

                    <para>1818 edition and 1831 edition: It was on a dreary night of November, that
                        I beheld the accomplishment of my toils. With an anxiety that almost
                        amounted to agony, I collected the instruments of life around me, that I
                        might infuse a spark of being into the lifeless thing that lay at my
                        feet.</para>
                </blockquote>
                <blockquote>
                    <title>ChatGPT:</title>
                    <para>Apologies for the oversight. Let's revise the representation to include
                        the differing portions as well. Here's the updated version:</para>
                    <programlisting>
                      Text differences:
+---------------------+---------------------------+-------------------------+
|       Manuscript     |      1818 edition         |     1831 edition        |
+---------------------+---------------------------+-------------------------+
| It was <emphasis role="under">on</emphasis> a dreary  | It was <emphasis role="under">on</emphasis> a dreary        | It was <emphasis role="under">on</emphasis> a dreary      |
| night <emphasis role="under">of</emphasis> November   | night <emphasis role="under">of</emphasis> November         | night <emphasis role="under">of</emphasis> November       |
| that I beheld the   | that I beheld the         | that I beheld the       |
| frame <emphasis role="under">on</emphasis> which my   | accomplishment <emphasis role="under">of</emphasis> my      | accomplishment <emphasis role="under">of</emphasis> my    |
| man compleated.     | toils.                    | toils.                  |
| <emphasis>And</emphasis> <emphasis role="under">with</emphasis> an anxiety | <emphasis role="under">With</emphasis> an anxiety that      | <emphasis role="under">With</emphasis> an anxiety that    |
| that almost amounted| almost amounted <emphasis role="under">to</emphasis> agony, | almost amounted <emphasis role="under">to</emphasis> agony|
| <emphasis role="under">to</emphasis> agony I collected| I collected the           | I collected the         |
| instruments <emphasis role="under">of</emphasis> life | instruments <emphasis role="under">of</emphasis> life       | instruments <emphasis role="under">of</emphasis> life     |
| around <emphasis role="under">me</emphasis> that I    | around <emphasis role="under">me</emphasis>,                | around <emphasis role="under">me</emphasis>,              |
| might infuse a spark| that I might infuse a     | that I might infuse a   |
| <emphasis role="under">of</emphasis> being <emphasis role="under">into</emphasis> the   | spark <emphasis role="under">of</emphasis> being <emphasis role="under">into</emphasis> the   | spark <emphasis role="under">of</emphasis> being <emphasis role="under">into</emphasis> the |
| lifeless thing that | lifeless thing that lay   | lifeless thing that lay |
| lay at my feet.     | at my feet.               | at my feet.             |
+---------------------+---------------------------+-------------------------+
                      
                  </programlisting>

                    <para>In this refined representation, we have the text differences table with
                        the Manuscript, 1818 edition, and 1831 edition side by side. The portions
                        that are the same in all versions are omitted for brevity, and only the
                        differing sections are displayed.</para>

                </blockquote> With this response, I am baffled and simply stop the prompt experiment
                sequence. ChatGPT seems unaware of what it is, and is not doing. There is a single
                accentuated highlight (in yellow against the blue) of the capitalized word
                    <quote>And</quote> from the manuscript, but it has otherwise simply highlighted
                short words across all the witnesses. What most surprised me was ChatGPT's assertion
                that it <quote>omitted</quote> all the passages that were the same. It omitted
                nothing. And it seemed to have no understanding of the concept of
                differentiation.</para>

            <para>I tried similar experiments this summer, wondering if differentiation of strings
                might have improved after the news that ChatGPT had expanded its context window for
                processing input. After June 21, developers are able to prompt ChatGPT with
                8000-word prompts, and it will be able ot store longer passages in memory. My
                prompts were not so long, but I suspect there is something challenging to the memory
                processing about my requests to compare strings, and I was curious whether I might
                see improvements. So I tried some similar experiments. Among my experiments were
                efforts to ask ChatGPT to provide responses not in an alignment table but TEI
                critical apparatus markup.<footnote>
                    <para>Timothy Mugayi, <link
                            xlink:href="https://levelup.gitconnected.com/chatgpt-16k-context-window-a-step-closer-to-100k-c770f0658996"
                                ><quote>ChatGPT 16K Context Window A Step Closer to 100k: A look at
                                larger context windows and what it means for your
                                applications</quote></link> Medium: Level Up Coding. 21 June
                        2023.</para>
                </footnote></para>

            <para>Here is a more recent experiment, requesting output in TEI critical apparatus
                markup (with apologies to Samuel Taylor Coleridge for my flagrant abuse of
                    <quote>The Rime of the Ancient Mariner</quote>). <blockquote>
                    <title>Elisa:</title>
                    <para>Given these four text inputs, can you collate them and generate a TEI
                        critical apparatus? <orderedlist>
                            <listitem>
                                <para>It was an ancient Marinere eftsoons there went he.</para>
                            </listitem>
                            <listitem>
                                <para>He was an old mariner, erstwhile he went there.</para>
                            </listitem>
                            <listitem>
                                <para>It was an old Marinere, eftsoons there went he.</para>
                            </listitem>
                            <listitem>
                                <para>He was an ancient Marinere, eftsoons he went there.</para>
                            </listitem>
                        </orderedlist>
                    </para>
                </blockquote>
                <blockquote>
                    <title>ChatGPT:</title>
                    <para>Certainly! A critical apparatus in Text Encoding Initiative (TEI) format
                        typically consists of variant readings with corresponding witnesses. In this
                        case, the four text inputs are slightly different from each other, and we
                        can create a simple critical apparatus for them. I will assume that each
                        text is a separate witness (W1, W2, W3, and W4) in the critical
                        apparatus.</para>

                    <para>Here's the TEI critical apparatus:</para>
                    <programlisting>
&lt;app&gt;
  &lt;lem&gt;
    It was an ancient Marinere eftsoons there went he.
  &lt;/lem&gt;
  &lt;rdg wit="#W2"&gt;
    He was an old mariner, erstwhile he went there.
  &lt;/rdg&gt;
  &lt;rdg wit="#W3"&gt;
    It was an old Marinere, eftsoons there went he.
  &lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;
    He was an ancient Marinere, eftsoons he went there.
  &lt;/rdg&gt;
&lt;/app&gt;   
              </programlisting>
                    <para> In this representation: <itemizedlist>
                            <listitem>
                                <para><code>&lt;lem&gt;</code> stands for the lemma (the base
                                    text).</para>
                            </listitem>
                            <listitem>
                                <para><code>&lt;rdg&gt;</code> stands for a variant reading.</para>
                            </listitem>
                            <listitem>
                                <para><code>wit="#W1"</code> represents the witness identifier for
                                    each variant reading.</para>
                            </listitem>
                        </itemizedlist>
                    </para>
                    <para>Now, the critical apparatus shows that the lemma (base text) is "It was an
                        ancient Marinere eftsoons there went he," and three variants (W2, W3, and
                        W4) are provided with their corresponding readings. </para>

                </blockquote> What is presented here as a distinct advantage over my other
                experiments of being, quite simply correct. Indeed, none of these four sentences is
                the same, and from ChatGPT this is a fair representation of TEI critical apparatus
                encoding, representing a single moment of variation in the <code>&lt;app&gt;</code>
                element, and showing each of the four versions inside. Its explanation is clear. I
                am not sure how it arrived at a concept of the lemma except that it seems to be
                defaulting to the first as being somehow preferred for the base text. But this
                markup is too simple and not especially useful if I am wanting to highlight
                precisely where the texts align and where they differ. So I continued the
                conversation. <blockquote>
                    <title>Elisa:</title>
                    <para>Can you improve this by using the <code>&lt;app&gt;</code> elements only
                        where there are forks or deltas in the text?</para>
                </blockquote>
                <blockquote>
                    <title>ChatGPT:</title>
                    <para>Certainly! In a critical apparatus, we can use the
                            <code>&lt;app&gt;</code> element only where there are forks or deltas
                        (variants) in the text. This will help in presenting a more concise
                        representation of the textual differences. Here's the improved TEI critical
                        apparatus:</para>
                    <programlisting>
&lt;app&gt;
  &lt;lem&gt;
    It was an ancient Marinere eftsoons there went he.
  &lt;/lem&gt;
  &lt;rdg wit="#W2"&gt;
    He was an old mariner, erstwhile he went there.
  &lt;/rdg&gt;
  &lt;rdg wit="#W3"&gt;
    It was an old Marinere, eftsoons there went he.
  &lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;
    He was an ancient Marinere, eftsoons he went there.
  &lt;/rdg&gt;
&lt;/app&gt;    
                    </programlisting>
                    <para>In this representation, the <code>&lt;app&gt;</code> element encloses the
                        entire set of variant readings (rdg elements) because there are textual
                        differences among the witnesses at this point. Since the lemma (base text)
                        remains the same in all cases, we don’t need separate
                            <code>&lt;app&gt;</code> elements for each witness.</para>

                </blockquote> This was amusing. ChatGPT does not change its code: it is identical.
                It explains to me that, of course, the witnesses each differ from one another. This
                is a justification or rationalization of its response. </para>
            <para>If I want it to approach the problem differently perhaps I need a better prompt.
                So I try again. In the prompt below, I attempted to show ChatGPT what kind of output
                I wanted to see, and gave it a start that I requested it to continue. (I
                inadvertently left the second app element unclosed, though this omission does not
                seem to have affected the reply.) <blockquote>
                    <title>Elisa:</title>
                    <para>That is not what I meant. I'd like you to apply the critical apparatus
                        using inline parallel segmentation. This means you should show just one line
                        of text where all witnesses are the same, and then use the
                            <code>&lt;app&gt;</code> element in the specific moments where the text
                        differs. Here is how you could begin: <programlisting> 
                   &lt;app&gt;
                       &lt;rdg wit="#W1 #W3"&gt;It&lt;/lem&gt;
                           &lt;rdg wit="#W2 #W4"&gt;He&lt;/rdg&gt;
                   &lt;/app&gt;
                   was an
                   &lt;app&gt;
                       &lt;rdg wit="#W1 #W4"&gt;ancient&lt;/rdg&gt;
                       &lt;rdg wit="#W2 #W3&gt;old&lt;/rdg&gt;
   
                  </programlisting>
                    </para>

                    <para>Can you continue based on this start?</para>

                </blockquote>
                <blockquote>
                    <title>ChatGPT:</title>
                    <para>Apologies for the misunderstanding. I understand now that you want to
                        represent the critical apparatus using inline parallel segmentation. Here's
                        the continuation based on the start you provided:</para>
                    <programlisting>                        
&lt;app&gt;
  &lt;rdg wit="#W1 #W3"&gt;It&lt;/rdg&gt;
  &lt;rdg wit="#W2 #W4"&gt;He&lt;/rdg&gt;
&lt;/app&gt;
was an
&lt;app&gt;
  &lt;rdg wit="#W1 #W4"&gt;ancient&lt;/rdg&gt;
  &lt;rdg wit="#W2 #W3"&gt;old&lt;/rdg&gt;
&lt;/app&gt;
Marinere
&lt;app&gt;
  &lt;rdg wit="#W1 #W3 #W4"&gt;eftsoons there&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;erstwhile&lt;/rdg&gt;
&lt;/app&gt;
went he.
    
                    </programlisting>
                    <para>In this representation, the critical apparatus is represented using the
                            <code>&lt;app&gt;</code> element, and within each
                            <code>&lt;app&gt;</code> element, we use the <code>&lt;rdg&gt;</code>
                        elements to indicate the variant readings for different witnesses (W1, W2,
                        W3, and W4).</para>
                    <para>I hope this format better meets your requirements for inline parallel
                        segmentation. Let me know if you need any further adjustments!</para>

                </blockquote> At first glance this appeared to be what I wanted, but on review of
                the strings I had asked ChatGPT to collate, we need to recognize some significant
                errors. <orderedlist>
                    <listitem>
                        <para>It was an ancient Marinere eftsoons there went he.</para>
                    </listitem>
                    <listitem>
                        <para>He was an old mariner, erstwhile he went there.</para>
                    </listitem>
                    <listitem>
                        <para>It was an old Marinere, eftsoons there went he.</para>
                    </listitem>
                    <listitem>
                        <para>He was an ancient Marinere, eftsoons he went there.</para>
                    </listitem>
                </orderedlist> ChatGPT's critical apparatus markup declares that all of the texts
                share the capitalized and distinct spelling <quote>Marinere</quote>, missing the
                difference of witness 2 which has <quote>mariner</quote>. It also misses the
                presence or absence of the comma (omitting it entirely in the critical apparatus).
                Finally, there is the issue with representing transposition. Versions 2 and 4 show
                    <quote>he went there</quote> while Versions 1 and 3 have <quote>there went
                    he</quote>. ChatGPT almost completely these differences in its representation of
                the end of the passages. Its apparatus correctly represents Text 2 as the only
                variant holding <quote>erstwhile</quote>, but it incorrectly identifies Text 4 as
                showing <quote>eftsoons there</quote> along with Texts 1 and 3. It should have
                stopped the alignment at <quote>eftsoons</quote>, and created a new
                    <code>&lt;app&gt;</code> to hold the variations of <quote>there went he</quote>
                vs. <quote>he went there</quote>. It was doing pretty well, but clearly this was
                only an approximation and precise accuracy is not to be expected.</para>
            <para>Still I wondered if I had given ChatGPT something too short and intricate with too
                many small variations. What if I added a bit to the four strings that would give it
                something that should be easy to align, a long stretch of identical tokens? Could it
                show improvement, continuing on? <blockquote>
                    <title>Elisa:</title>
                    <para> You're on the right track, but you're dropping some of the text in your
                        comparison. Let's try again with a longer set of texts to see if that helps. <orderedlist>
                            <listitem>
                                <para>It was an ancient Marinere eftsoons there went he. He wanted
                                    to talk to the AI about collation and TEI.</para>
                            </listitem>
                            <listitem>
                                <para>He was an old mariner, erstwhile he went there. He wanted to
                                    talk about TEI to the AI that day.</para>
                            </listitem>
                            <listitem>
                                <para>It was an old Marinere, eftsoons there went he. He wanted to
                                    talk to the AI about TEI.</para>
                            </listitem>
                            <listitem>
                                <para>He was an ancient Marinere, eftsoons he went there. He wanted
                                    to talk about TEI and AI.</para>
                            </listitem>
                        </orderedlist>
                    </para>

                </blockquote>
                <blockquote>
                    <title>ChatGPT:</title>
                    <para>Apologies for the oversight. Let's try again with the longer set of texts,
                        using the inline parallel segmentation for the TEI critical
                        apparatus:</para>

                    <programlisting>
&lt;app&gt;
  &lt;rdg wit="#W1 #W3"&gt;It was an ancient Marinere eftsoons there went he.&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;He was an old mariner, erstwhile he went there.&lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;He was an ancient Marinere, eftsoons he went there.&lt;/rdg&gt;
&lt;/app&gt;
&lt;app&gt;
  &lt;rdg wit="#W1"&gt;He wanted to talk to the AI about collation and TEI.&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;He wanted to talk about TEI to the AI that day.&lt;/rdg&gt;
  &lt;rdg wit="#W3"&gt;He wanted to talk to the AI about TEI.&lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;He wanted to talk about TEI and AI.&lt;/rdg&gt;
&lt;/app&gt;
                    </programlisting>
                    <para> In this representation:</para>

                    <para>The first <code>&lt;app&gt;</code> element contains the variant readings
                        for the first sentence: <quote>It was an ancient Marinere eftsoons there
                            went he.</quote> (W1, W2, W3, and W4). The second
                            <code>&lt;app&gt;</code> element contains the variant readings for the
                        second sentence: "He wanted to talk to the AI about collation and TEI."
                        (W1), "He wanted to talk about TEI to the AI that day." (W2), "He wanted to
                        talk to the AI about TEI." (W3), and "He wanted to talk about TEI and AI."
                        (W4).</para>
                    <para>This format shows the differences between the witnesses inline for each
                        sentence. Let me know if this meets your requirements, or if you need any
                        further adjustments!</para>
                </blockquote> Somehow in the series of prompts and responses, something I expect
                ChatGPT to have <quote>learned</quote> seems to be forgotten. ChatGPT is returning
                to its original preference for blocking long portions of text in the
                    <code>&lt;rdg&gt;</code> elements. It is nevertheless indicating, incorrectly,
                that Texts 1 and 3 agree completely, when Text 3 contains a comma after
                    <quote>Marinere</quote>. Is the experiment worth continuing? Reader, I did
                continue, but saw similar patterns of error with dropping punctuation or variant
                tokens, and with ignoring sameness in long blocks it marked variant. The last
                response provided by ChatGPT to this series provides a good summary representation
                of each of these problems: <blockquote>
                    <title>ChatGPT:</title>

                    <programlisting>
&lt;app&gt;
  &lt;rdg wit="#W1 #W3"&gt;It was an&lt;/rdg&gt;
  &lt;rdg wit="#W2 #W4"&gt;He was an&lt;/rdg&gt;
&lt;/app&gt;
&lt;app&gt;
  &lt;rdg wit="#W1"&gt;ancient&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;old&lt;/rdg&gt;
  &lt;rdg wit="#W3 #W4"&gt;old&lt;/rdg&gt;
&lt;/app&gt;
Marinere eftsoons there went he. He wanted to talk to the AI about collation and TEI.
&lt;app&gt;
  &lt;rdg wit="#W1"&gt;He wanted to talk to the AI about collation and TEI.&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;He wanted to talk about TEI to the AI that day.&lt;/rdg&gt;
  &lt;rdg wit="#W3"&gt;He wanted to talk to the AI about TEI.&lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;He wanted to talk about TEI and AI.&lt;/rdg&gt;
&lt;/app&gt;   
         </programlisting>
                    <para>Now, the revised encoding correctly shows the common phrase "He wanted to
                        talk to the AI about collation and TEI." in the second text, which is
                        present across all four witnesses (W1, W2, W3, and W4).</para>

                </blockquote> ChatGPT replaces one kind of problem for a new kind of error. There
                are omissions and failures to recognize precisely what is common and what is not.
                And now text that it claims to be the same across all versions is <emphasis
                    role="ital">also</emphasis> represented as variant. This is a terrible
                misrepresentation, but the kinds of errors make me wonder how the language model is
                attempting to process my requests. Why is it creating these errors? </para>


            <para>I had learned that sometimes if you prompt the chatbot to pretend that it is an
                expert in an area that this would help improve its response, and in some of my
                experiments this year I attempted this sort of <quote>let’s pretend</quote> game to
                ask ChatGPT to pretend they are an expert in the TEI and preparing a digital
                scholarly edition, but at least for the tasks I was requesting they did not help to
                improve the responses. They are predictably unreliable, and never once did I see a
                response without errors. I also tried simplifying the task and asking it directly
                only to <quote>diff</quote> some strings, but this made no difference and I have yet
                to see an accurate response to a prompt requesting a comparison of two or more
                strings.</para>
            <para>Finally, I attempted an experiment with Anthropic’s Claude AI, which purports to
                having a larger memory capacity and context window for prompt processing that
                ChatGPT.<footnote><para>I accessed Claude in July 2023 at <link xlink:href="https://claude.ai">https://claude.ai</link></para></footnote> The results were slightly better out of the box. In this case I returned to
                comparing two versions of the passage from <emphasis>Frankenstein</emphasis>: <blockquote>
                    <title>Elisa:</title>
                    <para>You are preparing a critical edition in TEI using critical apparatus
                        markup. Can you prepare a sample of code for comparing two editions based on
                        the following three versions of the same passage?</para>
                    <para>Manuscript: It was on a dreary night of November that I beheld the frame
                        on which my man compleated. And with an anxiety that almost amounted to
                        agony I collected instruments of life around me that I might infuse a spark
                        of being into the lifeless thing that lay at my feet.</para>
                    <para>1818 edition and 1831 edition: It was on a dreary night of November, that
                        I beheld the accomplishment of my toils. With an anxiety that almost
                        amounted to agony, I collected the instruments of life around me, that I
                        might infuse a spark of being into the lifeless thing that lay at my
                        feet.</para>
                </blockquote>
                <blockquote>
                    <title>Claude.ai:</title>
                    <para>Here is a sample TEI encoding of the critical apparatus comparing those
                        three versions of the passage:</para>
                    <programlisting>
&lt;p&gt;It was on a dreary night of November, that I beheld the 
&lt;app&gt;
  &lt;rdg wit="#MS"&gt;frame on which my man compleated&lt;/rdg&gt;
  &lt;rdg wit="#1818 #1831"&gt;accomplishment of my toils&lt;/rdg&gt;. 
&lt;/app&gt;
With an anxiety that almost amounted to agony, I collected the instruments of 
life around me, that I might infuse a spark of being into the lifeless thing that 
lay at my feet.&lt;/p&gt;     
                    </programlisting>

                </blockquote> This is <emphasis role="ital">almost</emphasis> correct, and indeed, I
                was surprised to find that Claude was unifying the text streams around the parallel
                portions. It was missing the differences in punctuation, however, and even when I
                prompted Claude to correct for omissions they might have made, Claude failed to
                identify the problems. </para>

            <para>Experimenting with text-generative language models in the previous months has
                illuminated some interesting problems in comparing text strings in language models
                that work with tokenized string inputs. Comparisons are fuzzy, overly broad, or
                outright drop tokens and usually misrepresent the source texts in some way. Not only
                were the results almost always inaccurate, but on repeated prompts and requests for
                corrections, neither ChatGPT nor Claude could not be said to improve significantly.
                Why are the models so problematic at a task that involves identifying sameness and
                difference in sequences of tokenized text? I can only speculate since I lack access
                or expertise to comprehend the working systems <quote>under the hood</quote> of the
                language models, but I speculate that the problems stem from a fundamentally
                different way of <quote>reading</quote> tokens. That is, the method of reading input
                and studying word embeddings in the langauge model is based on a more complicated
                statistical process than the simple edit-distance calculation I requested. Perhaps
                the AI can <quote>read</quote> in no other way than by the (statistical)
                books.</para>
        </section>
        <section>
            <title>From stochastic parrot to reasoning intelligence?</title>

            <para>As a human (read: limited, inconsistent) reader of texts I am in awe that a
                mathematically trained language model, a so-called <quote>artificial
                    intelligence</quote> which I expect to be more consistent and adept at pattern
                recognition than I am, consistently struggles with what seems to be a simple
                comparison of strings. Is it a shortness of Long-Term Short-Term Memory (LTSTM) that
                causes the models to lose track of the details in the process of calculating a
                response? Perhaps ChatGPT’s current inability to analyze comparisons of strings has
                something to do with its token-by-token generative stream. ChatGPT can correctly
                tell me what Levenshtein (or edit-distance) distance is: <blockquote>
                    <title>ChatGPT:</title>
                    <para>The Levenshtein distance is a measure of the minimum number of
                        single-character edits (insertions, deletions, or substitutions) required to
                        change one string into another.</para>
                </blockquote> The AI can also separate two different versions of a text in different
                boxes. But it cannot accurately calculate the edit-distance and it cannot seem to
                pinpoint variations. In the task of preparing an alignment table or a TEI critical
                apparatus, the AI supplies the illusion of structure with some persistent blind
                spots. Perhaps it is failing to <quote>see</quote> what constitutes a reasonable,
                meaningful basis for comparison of text streams. Perhaps this is due to a confusion
                between its paradigm of understanding tokens based on
                    <emphasis>relatedness</emphasis> as opposed to their exact sameness or
                difference. In other words, I suspect that something about semantics is getting in
                the way, not literally the meaning of the text, but rather the programming to
                associate tokens with each other based on their co-occurence, the vectorized word
                embeddings that helps the AI predict the next token to generate. The very capacities
                that permit ChatGPT and Claude to converse in a reasonable voice interfere with
                their capacities to calculate or prepare an accurate programming script. We have
                been learning these past several months simply to expect, and live with, AI being
                fast but fuzzy, to expect error, and certainly not to ask it do to our math homework.<footnote>
                    <para>Simon Frieder, Luca Pinchetti, Alexis Chevalier, Ryan-Rhys Griffiths,
                        Tommaso Salvatori, Thomas Lukasiewicz, Philipp Christian Petersen, Julius
                        Berner, <quote>Mathematical Capabilities of ChatGPT</quote> Arxiv: Computer
                        Science &gt; Machine Learning, 2023. <link
                            xlink:href="https://doi.org/10.48550/arXiv.2301.13867"
                            >https://doi.org/10.48550/arXiv.2301.13867</link></para>
                </footnote></para>
            <para>Perhaps we should not expect anything better. Today dialogue with generative
                language-based AI gives us the opportunity to declare and inquire with the voice of
                reason, but the stochastic outputs we receive sometimes contradict themselves and
                frequently miscalculatge and misrepresent. We understand that prompt generation is
                based on statistical predictions of what might be the best-fit, reasonable next
                tokens of text to supply in sequence, and that this makes them not intelligent at
                all but rather stochastic machines.<footnote>
                    <para>For unsophisticated novices like me, these articles have been particularly
                        helpful for gaining a basic appreciation of key concepts in text generative
                        AI: Haomiao Huang, <link
                            xlink:href="https://arstechnica.com/gadgets/2023/01/the-generative-ai-revolution-has-begun-how-did-we-get-here/"
                                ><quote>The generative AI revolution has begun—how did we get
                                here?</quote></link> Ars Technica 30 January 2023; Jay Alammar,
                            <link xlink:href="https://jalammar.github.io/illustrated-word2vec/"
                                ><quote>The Illustrated Word2Vec</quote></link> blog post, 27 March
                        2019. </para>

                </footnote> Further, we understand these stochastic machines can do damage, because
                they amplify even the veiled language of racism and sexism that often goes nearly
                unheard or unmarked in everyday discourse of Wikipedia and Reddit and social media.<footnote>
                    <para>This Google Collab Notebook tutorial offers an accessible introduction to
                        gender and social class bias engrained in large language models: Shlomi Hod,
                            <quote>Tutorial // Exploring Gender Bias in Word Embedding</quote>
                        2018—. <link
                            xlink:href="https://colab.research.google.com/github/ResponsiblyAI/word-embedding/blob/main/tutorial-bias-word-embedding.ipynb"
                            >https://colab.research.google.com/github/ResponsiblyAI/word-embedding/blob/main/tutorial-bias-word-embedding.ipynb</link>.
                        This article details pervasive problema of gender bias in ChatGPT’s
                        translations from English to Farsi, Malay, Tagalog, Thai, and Turkish:
                        Sourojit Ghosh and Aylin Caliskan, <quote>ChatGPT Perpetuates Gender Bias in
                            Machine Translation and Ignores Non-Gendered Pronouns: Findings across
                            Bengali and Five other Low-Resource Languages</quote> Upcoming
                        Publication in AAAI/ACM Conference on AI, Ethics, and Society, 2023.</para>
                </footnote> In the year 2023, text-generative AI speaks with a language of authority
                and confidence that amplifies normative values in its unstable predictions of the
                best fit content completion for a prompt. We know these limitations, and their
                consequences are dire.</para>

            <para>Reasoned authority is what we expect of optimal interactions with computers, and
                this is a foundational value of our declarative markup community. In slides from a
                2015 digital humanities conference presentation, Michael Sperberg-McQueen claims,
                    <quote>Declarative semantics make it possible to reason about representations;
                    imperative semantics impede.</quote><footnote>
                    <para>Michael Sperberg-McQueen, <link
                            xlink:href="https://blackmesatech.com/2015/10/KIaCiDH/"><quote>What does
                                descriptive markup contribute to digital humanities?</quote></link>,
                        Key Ideas and Concepts of Digital Humanities conference, Technische
                        Universitat Darmstadt, 26-28 October, 2015. <link
                            xlink:href="https://blackmesatech.com/2015/10/KIaCiDH/#(8)">Slide
                            8</link>.</para>
                </footnote> Nothing in our modeling of texts escapes bias, but our capacity to
                assert and test reasonable statements is a particular strength of declarative markup
                and the tooling our community has developed for it. In that 2015 presentation,
                Sperberg-McQueen also points out that hierarchical models are not neutral. The way
                we organize document hierarchies and decide on markup representations, and create
                schema rules to validate our models does not represent reflect absolute
                    <quote>ground truth</quote>, but rather attempts to describe and define based on
                what choose to prioritize, whether that is the section headings of a legislative
                memo or the page-by-page printing of a comic book. The models we create for
                documents and the metadata we care about reflect the paradigms and priorities of the
                humans who create them. Document historians of the future may come back to our XML
                markup and find us benighted, but they could also research in our models the rules
                of our publishing houses, the attitudes and expectations that prevailed in
                understanding how to study language and archive our cultural heritage. The point is,
                what we express in declarative semantics is fully visible, tractable, and usually
                documented. Our ways of thinking about texts, however flawed, are explicitly and
                deliberately marked. By stark contrast, the biases amplified by large language
                models in our stochastic systems are revealed only by analyzing the outputs or
                attempting to source the now-secret training data.</para>
            <para>That seminal article from 1990 <quote>What is Text, Really?</quote> is striking in
                the year 2023 for how current it remains as a critique of prevailing machine systems
                for handling text.<footnote>
                    <para>Steven J. DeRose, David G. Durand, Elli Mylonas, Allen H. Renear,
                        <quote>What is Text, Really?</quote> Journal of Computing in Higher Education. 1. 3-26. 1990. <link xlink:href="https://doi.org/10.1007/BF02941632">https://doi.org/10.1007/BF02941632</link></para>
                </footnote> Their proposition, that text really is an Ordered Hierarchy of Content
                Objects, came explicitly as a response (among other things) to concepts of text as a
                stream of content objects, the gram particles and formmating instructions without
                reference to structural context. In the year 2023 when we ask questions to large
                language models we are given to understand that text is generated in response to a
                limited <quote>context window</quote> that the language model uses for perceiving
                the range of nearby tokens and their proximity to the current token a frame of
                reference. Is it then the case in 2023 that context in the large language model is
                being determined by frames of reference in a stream of text? When an approximation
                of semantics is coded and decoded in vector space by position and token
                co-occurrence, this generates the appearance of meaningful output, which cannot be
                said to represent truth but might sometimes approximate it. This is the argument of
                the famous <quote>Stochastic Parrots</quote> article: that large language models
                distort, exploit, and waste resources in an effort only to produce unreliable and
                biased approximations. <footnote>
                    <para> Emily Bender, Timnit Gebru et. al. <quote>On the Dangers of Stochastic
                            Parrots: Can Language Models Be Too Big?</quote> Proceedings of the 2021
                        ACM Conference on Fairness, Accountability, and Transparency, March 2021,
                        pp. 610–623. <link xlink:href="https://doi.org/10.1145/3442188.3445922"
                            >https://doi.org/10.1145/3442188.3445922</link>. For helpful
                        introductions to how large language models work to generate text based on
                        predictive algorithms, see On how meaning is predicted in large language
                        models, see Jay Alammar, <link
                            xlink:href="http://jalammar.github.io/illustrated-transformer/"
                                ><quote>The Illustrated Transformer</quote></link> blog post. 27
                        June 2018; Molly Ruby <link
                            xlink:href="https://towardsdatascience.com/how-chatgpt-works-the-models-behind-the-bot-1ce5fca96286"
                                ><quote>How ChatGPT Works: The Model Behind The Bot</quote></link>,
                        in Towards Data Science. Medium. 30 January 2023. </para>
                </footnote>
            </para>
            <para>Should we expect better of so-called <quote>artificial intelligence</quote> in our
                time, to attempt something more than formulaic approximations of reasoned responses?
                Mulitple researchers suggest that large language models could attempt a wider range
                of learning methods, to associate metadata wtih data, or to attempt solving complex
                problems using hierarchical decision trees.<footnote>
                    <para>Here is a sampling of recent articles on how to improve problem solving
                        capacities in large language models: Cem Anil, Yuhuai Wu et. al.,
                            <quote>Exploring Length Generalization in Large Language Models</quote>
                        36th Conference on Neural Information Processing Systems. 2022. <link
                            xlink:href="https://openreview.net/pdf?id=zSkYVeX7bC4"
                            >https://openreview.net/pdf?id=zSkYVeX7bC4</link>; Shunyu Yao, Dian Yu,
                        Jeffrey Zhao et. al., <quote>Tree of Thoughts: Deliberate Problem Solving
                            with Large Language Models</quote>, Arxiv: Computer Science &gt;
                        Computation and Language, May 2023 preprint <link
                            xlink:href="https://arxiv.org/pdf/2305.10601.pdf"
                            >https://arxiv.org/pdf/2305.10601.pdf</link>; Roie Schwaber-Cohen,
                            <quote>Vector Databases</quote>, Pinecone <link
                            xlink:href="https://www.pinecone.io/learn/vector-database/"
                            >https://www.pinecone.io/learn/vector-database/</link> n.d. </para>
                </footnote> A group of researchers writing from the NIH, discussing the application
                of AI in medical diagnostics, explicitly calls for declarative methods to improve
                the learning algorithms. Because they historicize artificial intelligence to show
                how declarative methods once were central in Lisp and Prolog, they provide a helpful
                differentiation between AI then and now: <blockquote>
                    <para>The main goal of AI has been to develop programs that make intelligent
                        decisions and solve real-world problems, possibly dealing with “messy" real
                        world input that could make it difficult to handle using “conventional"
                        programming. The earlier AI problem solvers were expert systems that
                        attempted to model the way experts reason and make decisions using a set of
                        logical rules. Programming languages like Lisp and Prolog were designed to
                        make programming such systems easy even for non-expert users. The idea was
                        to represent the domain knowledge using a set of logical rules, and use the
                        rules in a logical reasoning process hidden from the programmers.</para>
                    <para>From the traditional AI perspective, this is a declarative programming
                        paradigm where we program for the what and not the how. The expert programs
                        could go beyond an independent set of rules and turn to logical programs
                        with a Turing-complete expressivity, supporting logical inference, for
                        example, by unification and resolution. However, real-world problems are
                        complex and often involve many interdependent components . . .It has become
                        evident that formalizing complex problem solving using programming a finite
                        set of deterministic logic-based rules is not possible, nor is it possible
                        to write a conventional structured program, even with a Turing-complete
                        language, for supporting intelligent decision-making based on naturally
                        occurring data.</para>
                </blockquote>The virtues of declarative methods are here expressed in familiar
                terms: domain experts can communicate needed information and apply programming to
                validate according to logical constraints. The authors point out how insufficient
                these machine learning techniques are, and call for augmenting them with what they
                call Systems AI using declarative methods. <blockquote>
                    <para>We emphasize the need to use some fundamental declarative ideas such as
                        first-order query languages, knowledge representation and reasoning
                        techniques, programming languages for multi agent systems, database
                        management systems (DBMS), and deductive databases (DDB). We need to place
                        these ideas within and around ML formalisms including classical ML tools,
                        deep learning libraries and automatic differentiation tools, and integrate
                        them with innovative programming languages and software development
                        techniques, as a way to address complex real-world problems that require
                        both learning and reasoning models.<footnote>
                            <para>Kordjamshidi P, Roth D, Kersting K., <quote>Declarative Learning-Based
                                Programming as an Interface to AI Systems</quote>, Frontiers in
                                Artifical Intelligence 5:755361, 2022 Mar 14. doi:10.3389/frai.2022.755361.
                                <link xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8967162/"
                                    >https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8967162/</link>
                            </para>
                        </footnote></para>
                </blockquote>
                 I have quoted at length to emphasize a point that should not be
                forgotten about the origins of artificial intelligence work in declarative methods,
                and the capacity of declarative methods to alter the grounds of what a machine
                intelligence can reference. The language models with which we interact in 2023
                cannot change paradigms for how they evaluate language. If they are to develop to
                become precision instruments that do no harm, declarative methods may be the way
                forward. </para>


        </section>
    </section>
    <section>
        <title>How meaningful is markup, anyway?</title>

        <para>When the text-generative AI models composed the markup shared in the previous section,
            their declarative semantics were unclear and often inconsistently applied.Perhaps its
            purpose became diluted by other imperatives of the generative language algorithm. We
            could describe such output as expressing a middle state, a string bearing the forms of
            markup but with dubious or disreputable declarative semantics. The way declarative logic
            is incorporated in a text-processing system matters. How deliberate can we be in
            applying it and generating the output we ask for? In their current form, large language
            models are limited in their capacities to handle complex tasks.</para>
        <para> When handled deliberately, declarative logic can be processed in imperative programs
            without loss of their significance in the output. Transforming text into other formats
            shows us what is fluid and transferrable in markup. We map its structures into forms
            that machines need to read, and when we do that they become moveable bins or containers
            of information. The process has been vital to our collation project for the Frankenstein
            Variorum, where a deliberate declared logic for controlling the basis for comparison has
            been key to consistent processing.</para>
        <section>
            <title>Markup as declarative intervention in an imperative process</title>
            <para>The process of refining the collation process for the Frankenstein Variorum
                involved a serious challenge to stop the collateX software from its default
                mechanism, always to align the smallest particles of the same text. CollateX
                definitely tends to align the smallest irreducible units of text (tokens) that it
                reads as <quote>the same</quote>, like <quote>a</quote>, <quote>an</quote>, and
                    <quote>the</quote>, even in passages that are not meant to be associated across
                the texts.<footnote>
                    <para> See the CollateX documentation, section 3.1 Alignment Algorithms in <link
                            xlink:href="https://collatex.net/doc/">https://collatex.net/doc/</link>.
                        The Needleman-Wunsch algorithm appears to be a starting point that CollateX
                        has adapted and improved to the Dekker algorithm, but the author's
                        experience applying the default alignment algorithm is consistent with this
                        pronounced statement from Needleman and Wunsch when they introduced their
                        comparison algorithm for bioinformatics in 1970: <quote>Comparisons are made
                            from the smallest unit of significance.</quote> This means that the
                        software consistently defaults to aligning the smallest units of agreement
                        at the token level, even when the context of the passage of text surrounding
                        them (say the unit paragraph or section) is completely different. Saul B.
                        Needleman and Christian D. Wunsch, <quote>A general method applicable to the
                            search for similarities in the amino acid sequence of two
                            proteins</quote> Journal of Molecular Biology 48:3 (28 March 1970) pp.
                        443-453. <link xlink:href="https://doi.org/10.1016/0022-2836(70)90057-4"
                            >https://doi.org/10.1016/0022-2836(70)90057-4</link>.</para>
                </footnote> One solution is to normalize the text stream in pre-processing prior to
                collation, to exclude such articles or short punctuation, but this did not accord
                with our methods of comparing the texts: the small words do matter to us when they
                mark variations. Other solutions involve post-processing or editing the output
                collation units by hand, which in our case was a brittle solution, prone to
                introducing new errors. Some of the versions of <citation>Frankenstein</citation>
                contain long inserted blocks, multi-paragraph inserted passages, and gaps in the
                manuscript that make it tricky to prepare aligned units (or <quote>chunks</quote>
                representing parallel passages across the five versions).</para>
            <para>Over the last year, my student Yuying Jin and I established a reliable method for
                bracketing off long divergent passages, a method that we call our
                    <quote>longToken</quote> strategy. Here we lengthen the size of the smallest
                particle of comparable text to the size of whatever we can express inside an XML
                element <code>&lt;longToken&gt;.....&lt;/longToken&gt;</code>. We instructed our
                Python script to isolate all tokens by newline characters, and set the entire length
                of longToken (which could be as small as a single character and as large as two
                paragraphs of text, including flattened markup) all in one irreducible line. By
                controlling the tokenization algorithm, we were able to control the mechanism of the
                collation software, prevent it from making spurious alignments on small words in a
                passage that we would effectively bracket away from micro-comparisons.</para>
            <para>Our Python script is a place of negotiation between paradigms of structured markup
                and so-called unstructured text. We use the <link
                    xlink:href="https://docs.python.org/3/library/xml.dom.pulldom.html">XML Pulldom
                    library</link> to process what markup from the source documents we want to
                include in the string comparison process. That is, we mask away some elements, like
                the page <code>&lt;surface&gt;</code> and <code>&lt;zone&gt;</code> elements that
                indicate page surfaces and locations on the pages from the Shelley-Godwin Archive
                encoding, because we have decided that page position is not relevant to comparison
                of the semantic text structure. But we want to preserve the element nodes that mark
                paragraphs, and chapter structures, and we want to preserve the information about
                deletion marks in the manuscript and from the Thomas copy. The word
                    <quote>mask</quote> seems appropriate here: it is something like applying tape
                to pieces of the file that we select. We continue to work with the markup, though,
                in its meaningful form. In the Python script, we define variables containing lists
                of element names that we will either mask away from the collation, or that we will
                include: <programlisting>
ignore = ['sourceDoc', 'xml', 'comment', 'include', 'addSpan', 'handShift', 'damage', 
                'unclear', 'restore', 'surface', 'zone', 'retrace']
blockEmpty = ['p', 'div', 'milestone', 'lg', 'l', 'cit', 'quote', 'bibl']
inlineEmpty = ['mod', 'pb', 'sga-add', 'delSpan', 'anchor', 'lb', 'gap', 
                 'hi', 'w', 'ab']
inlineContent = ['del-INNER', 'add-INNER', 'metamark', 'shi']
inlineVariationEvent = ['head', 'del', 'mdel', 'add', 'note', 'longToken']
                </programlisting> The <code>ignore</code> variable contains
                everything we are screening away from the stream of text comparison. The other
                variables represent elements types we will see in the input. This input contains
                some recognizable elements from the TEI, but <code>&lt;p&gt;</code>,
                    <code>&lt;lg&gt;</code>, and <code>&lt;l&gt;</code> are defined in the
                    <code>blockEmpty</code> list, along with <code>&lt;milestone&gt;</code>, which
                is the only element that those knowledgeable of the TEI would recognize as
                legitimately empty.</para>
            <para>What have we done to the TEI? Perhaps a sacrilege, but we are meddling with TEI
                XML files as, after all, text files that hold meaningful declarative markup, and we
                have converted their element nodes into a format that allows us to compare texts
                based on their original structures by removing the structures to process the
                comparison.</para>
        </section>
        <section>
            <title>There and back again: Transferring declared semantics</title>
            <para>In preparing our editions for collation (as discussed in previous Balisage
                papers), we have <quote>flattened</quote> the original TEI structural elements, and
                abstracted them away from their original document models. We do this on purpose to
                represent the element tags as Trojan-style markers and to be able to work them into
                our a new XML file that stores a standoff critical apparatus in TEI. That file
                represents the results of our collation pipeline, and it stores a flattened
                representation of the tags from the source editions. The standoff critical apparatus
                serves, also, as a basis for creating new edition files that store the collation
                data, highlighting passages that vary with the other editions.</para>
            <para>In this process, the semantics of the declarative markup from the source files are
                preserved even while that markup has undergone a complicated series of
                transformations. First it is transferred into strings or a stream of text in order
                to be collated. Then that stream of text is mapped back again into new XML
                structures to represent the meaningful data in the critical apparatus about how the
                texts compare to one another.</para>
            <para>Moving in between text-processing paradigms illuminates a transfer of semantics
                into format. The logic of declarative markup is preserved in the Python function
                running the pull parser via the XML Pulldom library. This function delivers us a way
                to transfer the logic of the markup element nodes into the formatting used to
                prepare the tokens and normalized tokens to be delivered to the collateX software.
                <programlisting>
    def extract(input_xml):
    """Process entire input XML document, firing on events"""
    doc = pulldom.parse(input_xml)
    output = ''
    for event, node in doc:
        if event == pulldom.START_ELEMENT and node.localName in ignore:
            continue
        # copy comments intact
        # if event == pulldom.COMMENT:
        #     doc.expandNode(node)
        #     output += node.toxml()
        # ebb: The following handles our longToken and longToken-style elements:
        # complete element nodes surrounded by newline characters to make a long complete token:
        if event == pulldom.START_ELEMENT and node.localName in inlineVariationEvent:
            doc.expandNode(node)
            output += '\n' + node.toxml() + '\n'
        # stops the problem of forming tokens that fuse element tags to words.
        elif event == pulldom.START_ELEMENT and node.localName in blockEmpty:
            output += '\n' + node.toxml() + '\n'
        # ebb: empty inline elements that do not take surrounding white spaces:
        elif event == pulldom.START_ELEMENT and node.localName in inlineEmpty:
            output += node.toxml()
        # non-empty inline elements: mdel, shi, metamark
        elif event == pulldom.START_ELEMENT and node.localName in inlineContent:
            output += '\n' + regexEmptyTag.sub('>', node.toxml())
            # output += '\n' + node.toxml()
        elif event == pulldom.END_ELEMENT and node.localName in inlineContent:
            output += '&lt;/' + node.localName + '&gt;' + '\n'
        # elif event == pulldom.START_ELEMENT and node.localName in blockElement:
        #    output += '\n&lt;' + node.localName + '&gt;\n'
        # elif event == pulldom.END_ELEMENT and node.localName in blockElement:
        #    output += '\n&lt;/' + node.localName + '>'
        elif event == pulldom.CHARACTERS:
            # output += fixToken(normalizeSpace(node.data))
            output += normalizeSpace(node.data)
        else:
            continue
    return output</programlisting> The <quote>partial DOM tree</quote> constructed
                by XML PullDom serializes something resonant with the semantics of explicit markup,
                allowing us in our project to hold the logic and even the structure of markup as a
                stream of text to be tokenized, chopped into the smallest fragments of meaningful
                variation. Thanks to the advantage of declarative markup, the scholarly editor gets
                to declare what that smallest fragment can be. A full element node marking an
                    <code>inlineVariationEvent</code> surrounded by <code>\n</code> newline
                characters becomes an irreducible token in , and this includes the
                    <code>&lt;longToken&gt;</code>, <code>&lt;add&gt;</code>, and
                    <code>&lt;del&gt;</code> elements that in our project mark irreducible units of
                comparison. We want an entire added or deleted passage to be lined up complete as
                one action in the text. It must be compared to a full comparable unit marked in the
                other documents, fully undeleted. That is a decision of our scholarly edition work
                to handle collation events, and it means that a deletion event followed by an
                insertion event in the Thomas text (where the author crossed out a passage and
                indicated another to add) effectively drives the collation software to generate a
                specially shaped entry in our critical apparatus. We have programmed our work to
                prepare this output: <programlisting>
               &lt;app&gt;
		&lt;rdgGrp
			n="['&lt;del&gt;to his statement, which was delivered&lt;/del&gt;', 
			'to him with interest for he spoke']"&gt;
			&lt;rdg wit="fThomas"&gt;&lt;del rend="strikethrough"&gt;to his statement, 
			which was delivered&lt;/del&gt; &lt;add&gt;to him with interest
			for he spoke&lt;/add&gt;&lt;/rdg&gt;
		&lt;/rdgGrp&gt;
		&lt;rdgGrp n="['to his statement, which was delivered']"&gt;
			&lt;rdg wit="f1818"&gt;&lt;longToken&gt;to his statement, which was
				delivered&lt;/longToken&gt;&lt;/rdg&gt;
			&lt;rdg wit="f1823"&gt;&lt;longToken&gt;to his statement, which was
				delivered&lt;/longToken&gt;&lt;/rdg&gt;
			&lt;rdg wit="f1831"&gt;&lt;longToken&gt;to his statement, which was
				delivered&lt;/longToken&gt;&lt;/rdg&gt;
		&lt;/rdgGrp&gt;
	&lt;/app&gt;</programlisting> This output from collateX is formatted according to
                the TEI XML critical apparatus to express the logic of elements storing variation
                information across five source edition files. A moment of meaningful variation is
                stored in an <code>&lt;app&gt;</code> element, and each of uts
                    <code>&lt;rdg&gt;</code> descendants stores a single token representing the text
                of one witness, here a phrase that we purposefully blocked off to be an irreducible
                unit of comparison using the <code>&lt;longToken&gt;</code> element. You can see the
                trace of the longToken elements in the <code>&lt;rdg&gt;</code> text nodes, while
                the <code>@n</code> attribute on the <code>&lt;rdgGrp</code> elements serves to
                express how the collation software normalizes each token to show on what basis the
                    <code>&lt;rdg&gt;</code> elements inside are understood to agree: the trace of
                the longToken element is removed there because it is not itself part of the string
                we ask the collation software to compare. </para>


            <para>In the example, the collation software follows our normalizing algorithm to
                determine that three of the witnesses share one form, and the Thomas edition holds
                the same passage crossed out together with its complete replacement. Here,
                declarative markup provides a precise way to delineate information on what
                constitutes an indivisible token to the software. With the demarcation of a
                    <code>&lt;longToken&gt;</code> I can bracket off passages of text and force the
                software to deal with them on my terms. This gives us control of a process of
                pair-wise comparisons by allowing us to alter the usual definition of the smallest
                unit of meaningful variation. Declarative markup thus permits us to express our
                theory of textual variation in the logic of the programming pipeline. Certainly we
                did something unorthodox with the machinery of comparing texts and we invented our
                own markup outside the TEI to declare what a token could be, and I want to call this
                a deliberate, <emphasis>declarative intervention</emphasis> in the imperative
                algorithms. </para>


            <para>This presupposes that the imperative tools can read the declarations, and
                accommodate the markup. For this capacity in our project, we flatten the element
                nodes into strings and identify those as regular expression patterns for processing.
                In our project we raise them again into elements with an XSLT pipeline, here fully
                relying on declarative methods to communicate our desired output. But in the crucial
                stage of collation, when texts must be handled as sequential strings and imperative
                processes are requird for calculations of alignment and comparison, the handling of
                markup as patterns in imperative programs offers a modicum of authority and control
                of the output.</para>
        </section>


    </section>
    <section>
        <title>Conclusion</title>
        <para>In this paper we looked first at the ways in which large language models fail
            repeatedly in the task of comparing and differentiating strings. We considered this a
            curious failing in a system that works with tokenized units of language, and also a sign
            of a limited basis for making reasonable statements. Perhaps this could be improved with
            implementing declarative methods. ChatGPT promised a kind of declarative affordance and
            declares to us its results, but its declarations are neither consistent nor reasonable.
            Perhaps a more adaptable algorithm for AI would allow for declarative mechanisms to
            control the logic of its operations. </para>
        <para>We then turned to consider how declarative methods can be implemented in imperative
            programming. When scholars should have the capacity to alter the scripts on which
            machines do their complex processing, they lend scholarly authority to what computing
            machines can process. What we require, and what declarative methods should afford, is
            control and validation of the grounds of knowledge, even when these are shifting.</para>
        <para>In a moment of eager excitement, confusion, and fear about the potential disruptive
            influences of generative language models, markup technologies provide reliable precision
            and control. They allow us to intervene and guide computational processes within
            declarative bounds of reason. Declarative methods can provide a foundation for a digital
            humanities lab like mine to counterbalance the anxiety-ridden speculative work of
            statistically-based <quote>distant reading</quote>, to extend what digital resources we
            can create, and to ground the authority of our research. When the calculations and
            training capacities of a large language model are subject to rapid change with the next
            month's update, and when developers of generative language models conceal their sources
            for commercial reasons and do not share their transformer architectures openly, we would
            do well to inspect our tools and research methods for brittle dependencies. Declarative
            markup proves itself a precision instrument to guide computational processing and may
            help to address the ephemerality of unstable technology stacks. What might it mean for a
            text-generative <quote>AI</quote> system to operate in a fully declarative
            way?</para>
    </section>

</article>
