<!DOCTYPE HTML><html lang="en">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>Balisage: Markup and migratory workflows in the context of AI and big data analytics</title>
      <link href="https://fonts.googleapis.com/css?family=PT+Sans+Narrow&amp;display=swap" rel="stylesheet">
      <meta name="viewport" content="width=device-width, initial-scale=1"><script type="text/JavaScript">
      var detailsElement = document.createElement("details");
      if (!("open" in detailsElement)) {
          document.write('<script src="..//js/bower_components/better-dom/dist/better-dom.js"><\/script>');
          document.write('<script src="..//js/bower_components/better-details-polyfill/dist/better-details-polyfill.js"><\/script>');
          document.write('<script src="..//js/classname.js"><\/script>');
      }
      /* Enable CSS styling of figure elements in IE:
       * https://xopus.com/devblog/2008/style-unknown-elements.html
       */
      var IEfix = document.createElement('figure');
    </script><style type="text/css" id="inverter" media="none">
      html {
        filter: invert(100%);
      }

      * {
        background-color: inherit;
      }

      /* do not invert SVG images */
      img:not([src*=".svg"]),
      [style*="url("] {
        filter: invert(100%);
      }
    </style>
      <link rel="stylesheet" href="balisage-proceedings.css" type="text/css">
      <meta name="keywords" content="artificial intelligence, AI, large language model, LLM, declarative markup, declarative methods, imperative methods, TEI, Text Encoding Initiative, tokenization, normalization, machine-assisted collation, Python, XSLT">
      <link id="favicon" rel="shortcut icon" type="image/png" href="http://balisage.net/favicon.ico">
      <!--balisage-html.xsl--></head>
   <body>
      <div class="skipnav"><a href="#main">Skip to contents.</a></div>
      <div id="balisage-header" role="banner">
         <h1><!--* balisage-html.xsl 519.38 *--><i>Balisage:</i>&nbsp;<small>The Markup Conference</small></h1>
      </div>
      <html lang="en">
         <head>
            <title>Balisage: Markup and migratory workflows in the context of AI and big data analytics</title>
            <link rel="stylesheet" href="balisage-proceedings.css" type="text/css">
            <link href="https://fonts.googleapis.com/css?family=PT+Sans+Narrow&amp;display=swap" rel="stylesheet">
            <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1"><script type="text/JavaScript">
      var detailsElement = document.createElement("details");
      if (!("open" in detailsElement)) {
          document.write('<script src="..//js/bower_components/better-dom/dist/better-dom.js"><\/script>');
          document.write('<script src="..//js/bower_components/better-details-polyfill/dist/better-details-polyfill.js"><\/script>');
          document.write('<script src="..//js/classname.js"><\/script>');
      }
      /* Enable CSS styling of figure elements in IE:
       * https://xopus.com/devblog/2008/style-unknown-elements.html
       */
      var IEfix = document.createElement('figure');
    </script><style type="text/css" id="inverter" media="none">
      html {
        filter: invert(100%);
      }

      * {
        background-color: inherit;
      }

      /* do not invert SVG images */
      img:not([src*=".svg"]),
      [style*="url("] {
        filter: invert(100%);
      }
    </style>
            <!--balisage-proceedings.xsl-->
            <meta name="generator" content="Balisage Conference Proceedings XSLT (v1.2)">
            <link id="favicon" rel="shortcut icon" type="image/png" href="http://balisage.net/favicon.ico"><script type="text/javascript">

   function hidecite(citeID) {
     cite = document.getElementById(citeID);
     cite.style.display = "none";
     return;
   }
   
   function showcite(citeID,anchorID) {
     cite = document.getElementById(citeID);

     citeLeft = cite.style.left;
     citeTop = cite.style.top;
     
     if (citeLeft != (getLeft(anchorID)+"px") ||
         citeTop != (getTop(anchorID)+"px")) {
       cite.style.display = "none";
     }
     
     if (cite.style.display != "table-cell") {
        movebox(citeID, anchorID);
        cite.style.display = "table-cell";
     }
     else {
       cite.style.display = "none";
     };
     return;
   }

   function movebox(citeID, anchorID) {

     cite = document.getElementById(citeID);
     
     // alert(cite.offsetWidth + " by " + cite.offsetHeight)
     
     horizontalOffset = getLeft(anchorID);
     // horizontalOffset = (inMain(anchorID)) ?
     // (horizontalOffset - 260) : (horizontalOffset + 20)
     // (horizontalOffset - (20 + cite.offsetWidth)) : (horizontalOffset + 20)

     verticalOffset = getTop(anchorID);
     // verticalOffset = (inMain(anchorID)) ?
     // (verticalOffset - 20) : (verticalOffset + 20)
     // (verticalOffset - (20 + cite.offsetHeight)) : (verticalOffset + 20)

     /*
     horizontalOffset = getAbsoluteLeft(anchorID) - getScrollLeft(anchorID) + 20;
     if (inMain(anchorID)) {
       horizontalOffset = horizontalOffset - 300;
     }
     verticalOffset = getAbsoluteTop(anchorID) - getScrollTop(anchorID) - 40;
     if (inMain(anchorID)) {
       verticalOffset = verticalOffset - 300;
     }
     */
     
     cite.style.left = horizontalOffset + "px";
     cite.style.top = verticalOffset + "px";
   }
   
   function getLeft(objectID) {
     var left = getAbsoluteLeft(objectID) - getScrollLeft(objectID);
     left = (inMain(objectID)) ? (left - 260) : (left + 20)    
     return left;
   }
   
   function getTop(objectID) {
     var top = getAbsoluteTop(objectID) - getScrollTop(objectID);
     top = (inMain(objectID)) ? (top - 50) : (top + 20)
     return top;     
   }
   
   function getAbsoluteLeft(objectId) {
   // Get an object left position from the upper left viewport corner
     o = document.getElementById(objectId)
     oLeft = o.offsetLeft            // Get left position from the parent object
     while(o.offsetParent!=null) {   // Parse the parent hierarchy up to the document element
       oParent = o.offsetParent    // Get parent object reference
       oLeft += oParent.offsetLeft // Add parent left position
       o = oParent
      }
    return oLeft
    }

    function getAbsoluteTop(objectId) {
    // Get an object top position from the upper left viewport corner
      o = document.getElementById(objectId)
      oTop = o.offsetTop            // Get top position from the parent object
      while(o.offsetParent!=null) { // Parse the parent hierarchy up to the document element
        oParent = o.offsetParent  // Get parent object reference
        oTop += oParent.offsetTop // Add parent top position
        o = oParent
      }
    return oTop
    }

   function getScrollLeft(objectId) {
     // Get a left scroll position
     o = document.getElementById(objectId)
     oLeft = o.scrollLeft            // Get left position from the parent object
     while(o.offsetParent!=null) {   // Parse the parent hierarchy up to the document element
       oParent = o.offsetParent    // Get parent object reference
       oLeft += oParent.scrollLeft // Add parent left position
       o = oParent
      }
    return oLeft
    }

    function getScrollTop(objectId) {
    // Get a right scroll position
      o = document.getElementById(objectId)
      oTop = o.scrollTop            // Get top position from the parent object
      while(o.offsetParent!=null) { // Parse the parent hierarchy up to the document element
        oParent = o.offsetParent  // Get parent object reference
        oTop += oParent.scrollTop // Add parent top position
        o = oParent
      }
    return oTop
    }

    function inMain(objectId) {
    // returns true if in div#main
      o = document.getElementById(objectId)
      while(o.parentNode != null) { // Parse the parent hierarchy up to div#main
        oParent = o.parentNode
        if (o.id == "main") { return true; }
        o = oParent;
      }
    return false;
    }


   /*
   function showcite(citeID) {
      cite = document.getElementById(citeID);
      if (cite.style.display != "table-cell") {
        cite.style.display = "table-cell";
      }
      else {
        cite.style.display = "none";
      };
      return;
    }
    */

      </script></head>
         <body>
            <div class="skipnav"><a href="#main">Skip to contents.</a></div>
            <div id="balisage-header" role="banner" aria-label="Logo and breadcrumb links"><a class="quiet" href="http://www.balisage.net"><img style="float:right;border:none" alt="Balisage logo" height="130" src="icons/BalisageSeries-logo.png"></a><h2 class="page-header">Balisage: The Markup Conference</h2>
               <h1 class="page-header">Proceedings preview</h1>
            </div>
            <nav id="main-menu" role="navigation">
               <details>
                  <summary tabindex="0"><svg role="img" viewBox="0 0 20 20" height="20" width="20">
                        <title>Menu</title>
                        <path d="m0-0v4h20v-4h-20zm0 8v4h20v-4h-20zm0 8v4h20v-4h-20z" fill="currentColor"></path></svg> Menu
                     </summary>
                  <div class="menu">
                     <div id="navbar"></div>
                     <div id="index-mast">
                        <div class="content">
                           <h1 class="article-title" id="d4e5">Balisage Paper: Markup and migratory workflows in the context of AI and big data analytics</h1>
                           <h2 class="subtitle">Reflections on the data modeling groundwork of the digital humanities</h2>
                           <details class="mast-box">
                              <summary class="title">Elisa E. Beshero-Bondar</summary>
                              <div class="affiliation">
                                 <p class="jobtitle">Chair</p>
                                 <p class="orgname">TEI Technical Council</p>
                              </div>
                              <div class="affiliation">
                                 <p class="jobtitle">Professor of Digital Humanities</p>
                                 <p class="jobtitle">Program Chair of Digital Media, Arts, and Technology</p>
                                 <p class="orgname">Penn State Erie, The Behrend College</p>
                              </div>
                              <h5 class="author-email"><code class="email">&lt;<a class="email" href="mailto:eeb4@psu.edu">eeb4@psu.edu</a>&gt;</code></h5>
                              <div class="personblurb">
                                 <p id="d4e19">Elisa Beshero-Bondar explores and teaches document data modeling with the XML
                                    family of languages. She serves on the TEI Technical Council and is the founder
                                    and organizer of the <a href="https://digitalmitford.org" class="link">Digital
                                       Mitford project</a> and <a href="https://digitalmitford.github.io/DigMitCS/" class="link">its usually annual coding
                                       school</a>. She experiments with visualizing data from complex document
                                    structures like epic poems and with computer-assisted collation of differently
                                    encoded editions of <a href="https://frankensteinvariorum.github.io/" class="link"><span class="ital">Frankenstein</span></a>. Her ongoing adventures with
                                    markup technologies are documented on <a href="https://newtfire.org" class="link">her
                                       development site at newtfire.org</a>. </p>
                              </div>
                           </details>
                           <details class="abstract">
                              <summary>
                                 <h2 class="inline-heading">Abstract</h2>
                              </summary>
                              <p id="d4e9">Can large language models, working with tokenized text, effectively compare strings
                                 and accurately model the comparison in structured forms like alignment tables and
                                 the TEI critical apparatus? The answer is no, or not very well, but that answer helps
                                 to illuminate a remarkable strength and versatility of declarative markup, when deliberately
                                 introduced to imperative programs. We can see how declarative methods control the
                                 imperative machinery of a complex collation process in the Frankenstein Variorum project.
                                 The key question or provocation is whether <q>artificial intelligence</q> in our time can be improved by returning to its declarative origins, to make room
                                 for the authority of domain experts to control an otherwise unwieldy stochastic process
                                 that poses as a voice of reason.</p>
                           </details>
                           <details class="toc">
                              <summary>
                                 <h2 class="inline-heading">Table of Contents</h2>
                              </summary>
                              <dl>
                                 <dt><span class="section"><a href="#d4e58" class="toc">Introduction: Text tokenization and declarative methods in digital humanities</a></span></dt>
                                 <dt><span class="section"><a href="#d4e103" class="toc">Can AI help with my document collation?</a></span></dt>
                                 <dd>
                                    <dl>
                                       <dt><span class="section"><a href="#d4e158" class="toc">What happens when we ask a large language model to compare strings?</a></span></dt>
                                       <dt><span class="section"><a href="#d4e600" class="toc">From stochastic parrot to reasoning intelligence?</a></span></dt>
                                    </dl>
                                 </dd>
                                 <dt><span class="section"><a href="#d4e730" class="toc">How meaningful is markup, anyway?</a></span></dt>
                                 <dd>
                                    <dl>
                                       <dt><span class="section"><a href="#d4e734" class="toc">Markup as declarative intervention in an imperative process</a></span></dt>
                                       <dt><span class="section"><a href="#d4e798" class="toc">There and back again: Transferring declared semantics</a></span></dt>
                                    </dl>
                                 </dd>
                                 <dt><span class="section"><a href="#d4e846" class="toc">Conclusion</a></span></dt>
                              </dl>
                           </details>
                        </div>
                     </div>
                  </div>
               </details>
            </nav>
            <nav id="index-mast" class="wide-mode" role="navigation">
               <div class="content">
                  <h1 class="article-title" id="d4e5">Balisage Paper: Markup and migratory workflows in the context of AI and big data analytics</h1>
                  <h2 class="subtitle">Reflections on the data modeling groundwork of the digital humanities</h2>
                  <details class="mast-box">
                     <summary class="title">Elisa E. Beshero-Bondar</summary>
                     <div class="affiliation">
                        <p class="jobtitle">Chair</p>
                        <p class="orgname">TEI Technical Council</p>
                     </div>
                     <div class="affiliation">
                        <p class="jobtitle">Professor of Digital Humanities</p>
                        <p class="jobtitle">Program Chair of Digital Media, Arts, and Technology</p>
                        <p class="orgname">Penn State Erie, The Behrend College</p>
                     </div>
                     <h5 class="author-email"><code class="email">&lt;<a class="email" href="mailto:eeb4@psu.edu">eeb4@psu.edu</a>&gt;</code></h5>
                     <div class="personblurb">
                        <p id="d4e19">Elisa Beshero-Bondar explores and teaches document data modeling with the XML
                           family of languages. She serves on the TEI Technical Council and is the founder
                           and organizer of the <a href="https://digitalmitford.org" class="link">Digital
                              Mitford project</a> and <a href="https://digitalmitford.github.io/DigMitCS/" class="link">its usually annual coding
                              school</a>. She experiments with visualizing data from complex document
                           structures like epic poems and with computer-assisted collation of differently
                           encoded editions of <a href="https://frankensteinvariorum.github.io/" class="link"><span class="ital">Frankenstein</span></a>. Her ongoing adventures with
                           markup technologies are documented on <a href="https://newtfire.org" class="link">her
                              development site at newtfire.org</a>. </p>
                     </div>
                  </details>
                  <details class="abstract">
                     <summary>
                        <h2 class="inline-heading">Abstract</h2>
                     </summary>
                     <p id="d4e9">Can large language models, working with tokenized text, effectively compare strings
                        and accurately model the comparison in structured forms like alignment tables and
                        the TEI critical apparatus? The answer is no, or not very well, but that answer helps
                        to illuminate a remarkable strength and versatility of declarative markup, when deliberately
                        introduced to imperative programs. We can see how declarative methods control the
                        imperative machinery of a complex collation process in the Frankenstein Variorum project.
                        The key question or provocation is whether <q>artificial intelligence</q> in our time can be improved by returning to its declarative origins, to make room
                        for the authority of domain experts to control an otherwise unwieldy stochastic process
                        that poses as a voice of reason.</p>
                  </details>
                  <details class="toc">
                     <summary>
                        <h2 class="inline-heading">Table of Contents</h2>
                     </summary>
                     <dl>
                        <dt><span class="section"><a href="#d4e58" class="toc">Introduction: Text tokenization and declarative methods in digital humanities</a></span></dt>
                        <dt><span class="section"><a href="#d4e103" class="toc">Can AI help with my document collation?</a></span></dt>
                        <dd>
                           <dl>
                              <dt><span class="section"><a href="#d4e158" class="toc">What happens when we ask a large language model to compare strings?</a></span></dt>
                              <dt><span class="section"><a href="#d4e600" class="toc">From stochastic parrot to reasoning intelligence?</a></span></dt>
                           </dl>
                        </dd>
                        <dt><span class="section"><a href="#d4e730" class="toc">How meaningful is markup, anyway?</a></span></dt>
                        <dd>
                           <dl>
                              <dt><span class="section"><a href="#d4e734" class="toc">Markup as declarative intervention in an imperative process</a></span></dt>
                              <dt><span class="section"><a href="#d4e798" class="toc">There and back again: Transferring declared semantics</a></span></dt>
                           </dl>
                        </dd>
                        <dt><span class="section"><a href="#d4e846" class="toc">Conclusion</a></span></dt>
                     </dl>
                  </details>
               </div>
            </nav>
            <main id="main" role="main" aria-label="Main Content">
               <div class="article">
                  <h1 class="article-title" id="d4e5">Balisage Paper: Markup and migratory workflows in the context of AI and big data analytics</h1>
                  <h2 class="subtitle">Reflections on the data modeling groundwork of the digital humanities</h2>
                  <div class="section" id="d4e58">
                     <h2 class="title" style="clear: both">Introduction: Text tokenization and declarative methods in digital humanities</h2>
                     <p id="d4e60">Many scholars in the digital humanities work on natural language processing projects
                        that involve tokenizing texts and applying software to study how they cluster and
                        co-occur. Studies of term/token frequency-inverse document frequency (TF-IDF) are
                        the
                        basis of experiments like topic modeling, an approximate statistical effort to survey
                        <q>topics</q> based on clustering of tokens. The practice of tokenizing
                        texts is also fundamental to stylometry, to seek evidence of what patterns and
                        clusterings make a voice distinctive. Among digital humanists who have spoken at the
                        ADHO conference from 2015 onward, my own work on digital scholarly editions involves
                        me
                        much more than usual with declarative markup through XML and TEI.<sup class="fn-label"><a href="#d4e64" class="footnoteref" id="d4e64-ref">[1]</a></sup> This apparent marginality in my field means I have a slightly unusual and
                        persistently useful <q>toolkit</q> I have been using for a decade, and that I am
                        also a resource for my colleagues when they need to learn these technologies. My work
                        with declarative methods also allows me to enter the world of natural language
                        processing and explore documents as my colleagues do where we share common areas of
                        interest. These days I regularly move data from my marked-up documents into the realm
                        of
                        natural language processing to identify and analyze patterns. Such work tends to cycle
                        from marked-up XML documents to strings for tokenization and processing, and then
                        back
                        into markup to frame the outputs for sharing and visualizing the data in SVG, XML,
                        XHTML5.</p>
                     <p id="d4e82">The cycle from declarative markup, to string-processing algorthims, and back to output
                        declarative markup is a fundamental aspect of my research and teaching. But for many
                        in
                        my field, only the string processing portion of this is relevant, as they are not
                        regularly involved as I am with designing custom interfaces. When you work with digital
                        scholarly editions, you think of interfaces and representation, and you also tend
                        to
                        work closely with lots of textual data drawn from single works or small collections,
                        instead of at a distance from thousands or millions of documents treated as
                        <q>unstructured</q> streams of tokenized data. I began my career in the
                        United States in the 1990s in a literary and cultural field called
                        <q>English</q>, and I know that many of my digital humanities colleagues
                        invested in natural language processing share that background with me, and share much
                        of
                        my own migration experience into zones delineated <q>digital
                           humanities</q> in our strange institutional adventures with computers. But I
                        think of texts quite differently than many of my digital humanist colleagues do, simply
                        because in my document modeling and research with digital scholarly editions, I am
                        processing texts in ways that seem to be out of scope in their work (at least for
                        now).
                        Some of my analytical colleagues opine that declarative markup seems unnecessary in
                        a
                        time of big text data analytics, particularly when the making of declarations about
                        the
                        document form and content seems to encumber or inhibit projects at scale. The
                        classifications and categorizations made by AI should be able to do the work of markup
                        or render it obsolete.<sup class="fn-label"><a href="#d4e90" class="footnoteref" id="d4e90-ref">[2]</a></sup> In this paper, I want to address the question of what declarative markup can
                        do for us who engage in textual scholarship in the digital humanities. More needs
                        to be
                        declared just now about what we do with declarative methods and semantics and how
                        they
                        might assist the efforts of AI in our time.</p>
                     <p id="d4e97">Because I am steeped in scholarly editing and a declarative markup
                        <q>specialization</q> in the digital humanities, my efforts to test the chat
                        interfaces of large language models reflect my distinct research interests in comparing
                        and collating texts. Over the course of this year, I have realized something about
                        the
                        authority and efficacy of declarative methods in text analysis, and I hope this
                        realization is worth sharing with declarative markup specialists and their adjacent
                        text-scholarly friends in the digital humanities. In this paper I will discuss a form
                        of
                        token-based text analysis that consistently foils large language models, and I will
                        show
                        how declarative markup, interacting with imperative programming, simply and profoundly
                        makes that analysis possible to accomplish. This is a paper intended to demonstrate
                        the
                        importance of declarative authority in our text-analytic systems and to join a call
                        for
                        a more declarative approach to what is currently an unintelligent (so-called
                        <q>AI</q>) system for modeling language.</p>
                  </div>
                  <div class="section" id="d4e103">
                     <h2 class="title" style="clear: both">Can AI help with my document collation?</h2>
                     <p id="d4e105">I have been working on a project over the past few years that has challenged me to
                        explore, test, and refine a machine-assisted method for comparing versions of a text.
                        The project involves comparing five versions of the novel
                        <span class="ital">Frankenstein</span>, and the basis for comparing these versions
                        includes the markup from editions that were coded differently. I have shared papers
                        about these adventures over the past few Balisage meetings, including the fun of
                        flattening and raising markup and the challenge of comparing strings that include
                        representations of the markup in the editions.<sup class="fn-label"><a href="#d4e109" class="footnoteref" id="d4e109-ref">[3]</a></sup> Even when machine-assisted, document collation is tiring, tedious work. It
                        is one thing to prepare an algorithm for comparison and apply it to good, adaptable
                        software for the purpose, but it is quite another have to correct the output. That
                        is
                        where the real challenge begins, the intellectual challenge, mental discipline, or
                        <q>self-psych-out</q> of <q>machine-assisted</q> collation: When do
                        you give up trying to refine the software algorithm, and when do you
                        <q>crack</q> and resort to hand-correcting problematic outputs? Sometimes
                        giving up really slows down a project, when it is still possible to refine the method.
                        Not giving up on the process requires patience and tinkering with the machinery, and
                        the patience to continue
                        testing. Would it not be wonderful for artificial intelligence to assist and accelerate
                        this painstaking effort, if there could be a reliable way to train it to process text
                        like an editor of a digital scholarly edition?</p>
                     <p id="d4e124">The sensational public launch of ChatGPT on November 30, 2022 has sparked excitment,
                        confusion, concern and a new surge of publications across academia and the public
                        sector.<sup class="fn-label"><a href="#d4e126" class="footnoteref" id="d4e126-ref">[4]</a></sup> ChatGPT has also given us much fun with prompt experiments among
                        my academic circles. We would ask for introductions of ourselves and our colleagues
                        suitable for use in conferences and laugh at how ludricously wrong they are. (In one
                        invented bio I am both a medievalist and a published poet, neither of which is true,
                        but
                        I could speculate that somehow the words associated with me in ChatGPT’s training
                        had
                        been in proximity with medievalist friends and people far more creative than me).
                        Of
                        course we also prompted it to invent supposedly serious bibliographies to see its
                        made-up citations and fake URLs, too. At universities, teaching faculty worry about
                        our
                        students abusing generative AI to compose their papers, and possibilities for new
                        approaches to the writing process. Academics who write computer programs quickly
                        discovered a supremely helpful aspect of ChatGPT for debugging code or quickly
                        introducing how to access a software library on the fly. Once we have seen such
                        benefits, we tend to recognize that our students should also cultivate skills to prompt
                        AI—responsibly—for coding assistance. ChatGPT has saved time for me and my most
                        dedicated students, time that we might otherwise have spent combing through
                        documentation and Stack Overflow posts. Even when ChatGPT was wrong and its suggested
                        code plainly did not work, it was leading us rapidly to the ad-hoc fixes we needed
                        to
                        make, and particularly with some knowledge coming in we could work with it in a dialogue
                        and improve our understanding. </p>
                     <p id="d4e137">Encouraged by such time-saving coding assistance, my colleagues, students, and I have
                        been eagerly experimenting all year with something that seems to promise the ultimate
                        <span class="ital">declarative</span> possiblity: to directly ask a machine to deliver an
                        output, without directing how it generates that output. The developers at OpenAI fondly
                        aspire for their chat model to become: <q>a very eager junior programmer</q> to
                        <q>make completely new workflows effortless and efficient</q>.<sup class="fn-label"><a href="#d4e145" class="footnoteref" id="d4e145-ref">[5]</a></sup> I wondered how well the grand new AI models might perform on the very task
                        that has taken me and my colleagues and students years to refine: the machine-assisted
                        collation of multiple versions of a work in the form of manuscripts and printed
                        documents. The processes that underlie this involve aligning chunks of text, and a
                        token-by-token processing of streams of text pulled from marked-up documents. The
                        large
                        language models supporting generative AI are themselves based on word embeddings and
                        tokenized processing text streams. could the <q>word arithmetic</q> we associate
                        with text-generative AI be applied to comparison algorithms? Would it <q>just
                           know</q> how to optimize the most reasonable alignments and outputs? </p>
                     <p id="d4e157">At various moments between January and July 2023, I began testing a hypothesis that
                        a
                        machine trained on tokenized strings and word embeddings should excel at the task
                        of
                        token-by-token comparison of strings. My informal approach to conversational prompt
                        engineering discussed in the following sections could likely be improved, but I do
                        have
                        specific requirements for an optimal collation in mind that I have been attempting
                        to
                        declare and discuss with text-generative chat interfaces, and the exercise has been
                        instructive. Over the past several months in my prompt experiments to engage ChatGPT
                        and
                        Anthropic’s Claude in various permutations of this task, they have not only been wanting,
                        but
                        remarkably and consistently so. The ways in which generative AI has bungled my series
                        of
                        string-comparison challenges may tell us something interesting about the limits of
                        current large language models to correctly observe the differences between strings,
                        and
                        to express those differences in structured forms. The errors are illuminating in a
                        way
                        that demonstrates something seriously lacking in the text-generative system in 2023,
                        and
                        that is a fully declarative method of working with input and generating output.</p>
                     <div class="section" id="d4e158">
                        <h3 class="title" style="clear: both">What happens when we ask a large language model to compare strings?</h3>
                        <p id="d4e160">To begin to estimate whether AI could assist my collation work, I needed to work
                           within the limits of ChatGPT’s input window. But just as I could ask it to proofread
                           a paragraph or two for errors, surely I could provide some input strings and ask it
                           to compare them, and show me how they differ. In no case did I ever receive
                           reliable, accurate results, the the kinds of errors I saw were interesting to try
                           to
                           diagnose the basis of error. Here I share a representative sampling of the
                           experiments.<sup class="fn-label"><a href="#d4e162" class="footnoteref" id="d4e162-ref">[6]</a></sup></p>
                        <p id="d4e167">In some of my experiments, I simply requested that ChatGPT present me a table
                           showing me how two versions of a text align. In this prompt, I indicated that two
                           editions share a version, and a manuscript presents a different version. I was
                           curious to see how the AI would handle two versions shared by three documents. 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">Elisa:</p>
                                 <p id="d4e171">Can you prepare a data structure to show where these texts are the same
                                    and where they differ?</p>
                                 <p id="d4e172">Manuscript: It was on a dreary night of November that I beheld the frame
                                    on which my man compleated. And with an anxiety that almost amounted to
                                    agony I collected instruments of life around me that I might infuse a spark
                                    of being into the lifeless thing that lay at my feet.</p>
                                 <p id="d4e173">1818 edition and 1831 edition: It was on a dreary night of November, that
                                    I beheld the accomplishment of my toils. With an anxiety that almost
                                    amounted to agony, I collected the instruments of life around me, that I
                                    might infuse a spark of being into the lifeless thing that lay at my
                                    feet.</p>
                              </blockquote>
                           </div>
                           
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">ChatGPT:</p>
                                 <p id="d4e177">To compare the texts and visualize the similarities and differences, you
                                    can use a data structure such as a table or a side-by-side comparison.
                                    Here's an example of how you can represent the texts:</p>
                                 <pre class="programlisting" id="d4e178">
+---------------------+---------------------------+-------------------------+
|       Manuscript     |      1818 edition         |     1831 edition        |
+---------------------+---------------------------+-------------------------+
| It was on a dreary  | It was on a dreary        | It was on a dreary      |
| night of November   | night of November         | night of November       |
| that I beheld the   | that I beheld the         | that I beheld the       |
| frame on which my   | accomplishment of my      | accomplishment of my    |
| man compleated.     | toils.                    | toils.                  |
| And with an anxiety | With an anxiety that      | With an anxiety that    |
| that almost amounted| almost amounted to agony, | almost amounted to agony|
| to agony I collected| I collected the           | I collected the         |
| instruments of life | instruments of life       | instruments of life     |
| around me that I    | around me,                | around me,              |
| might infuse a spark| that I might infuse a     | that I might infuse a   |
| of being into the   | spark of being into the   | spark of being into the |
| lifeless thing that | lifeless thing that lay   | lifeless thing that lay |
| lay at my feet.     | at my feet.               | at my feet.             |
+---------------------+---------------------------+-------------------------+

                    </pre>
                                 <p id="d4e179">In this representation, each row corresponds to a line of text, and the
                                    columns represent the different versions: Manuscript, 1818 edition, and 1831
                                    edition. The matching text is aligned vertically, allowing you to see where
                                    the texts are the same and where they differ.</p>
                                 <p id="d4e180"> By comparing the texts using this structure, you can easily identify the
                                    variations between the Manuscript, 1818 edition, and 1831 edition.</p>
                              </blockquote>
                           </div> Here I was pleased to see that ChatGPT understood that I wanted to
                           represent three editions, although I was surprised that it did nothing besides block
                           the text into a single row. I asked for ChatGPT to refine the table. 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">Elisa:</p>
                                 <p id="d4e184">Let's try to refine this. Where the texts are identical, just show one
                                    block of text on the screen. Then when the texts are different, use the
                                    table to put the differences side by side.</p>
                              </blockquote>
                           </div>
                           
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">ChatGPT:</p>
                                 <p id="d4e188">Sure! Let's refine the representation to show the identical text blocks
                                    once and use a table to display the differing portions side by side. Here's
                                    an updated representation:</p>
                                 <pre class="programlisting" id="d4e189">
                    Identical <span class="under">text</span>:
-------------------------
It was <span class="under">on</span> a dreary night <span class="under">of</span> November

<span class="under">Text</span> differences:
+---------------------+---------------------------+-------------------------+
|       Manuscript     |      1818 edition         |     1831 edition        |
+---------------------+---------------------------+-------------------------+
| that I beheld the   | that I beheld the         | that I beheld the       |
| accomplishment <span class="under">of</span> my| accomplishment <span class="under">of</span> my      | accomplishment <span class="under">of</span> my    |
| toils.              | toils.                    | toils.                  |
| <span class="under">With</span> an anxiety that| <span class="under">With</span> an anxiety that      | <span class="under">With</span> an anxiety that    |
| almost amounted <span class="under">to</span>  | almost amounted <span class="under">to</span> agony, | almost amounted <span class="under">to</span> agony|
| agony I collected   | I collected the           | I collected the         |
| instruments <span class="under">of</span> life | instruments <span class="under">of</span> life       | instruments <span class="under">of</span> life     |
| around <span class="under">me</span>, that I   | around <span class="under">me</span>,                | around <span class="under">me</span>,              |
| might infuse a spark| that I might infuse a     | that I might infuse a   |
| <span class="under">of</span> being <span class="under">into</span> the   | spark <span class="under">of</span> being <span class="under">into</span> the   | spark <span class="under">of</span> being <span class="under">into</span> the |
| lifeless thing that | lifeless thing that lay   | lifeless thing that lay |
| lay at my feet.     | at my feet.               | at my feet.             |
+---------------------+---------------------------+-------------------------+
  
                </pre>
                                 <p id="d4e270">In this refined representation, the identical text block "It was on a
                                    dreary night of November" is displayed once at the top, indicating that this
                                    portion is the same in all versions. The table below then shows the
                                    differing text portions side by side, highlighting the variations between
                                    the Manuscript, 1818 edition, and 1831 edition.</p>
                              </blockquote>
                           </div> Here I am applying underlined emphasis to show what ChatGPT delivered
                           in blue color-coded CSS to highlight what it calls <q>variations</q> between
                           the editions. A few strange things have happened. First the language model does
                           correctly indicate that the first portion of the string is identical. But it misses
                           the difference that there is a comma in the 1818 and 1831 versions, and simply does
                           not represent the comma, so we have dropped a small token of text. Next in the
                           table, we completely miss the variant passage from the manuscript: <q>the frame
                              on which my man compleated. And</q>. Instead ChatGPT represents the
                           manuscript text as the same block that it provides for the other two. Is it
                           forgetting the differences? Yet is seems to understand that some indication of
                           differences is expected, and it highlights words of between two and four characters
                           long that are identical in the gthree passages it blocked. This is distressingly
                           inaccurate, but enough to raise questions of how it can be determining what to
                           highlight.</p>
                        <p id="d4e277">I tried again with this experiment. I understood that ChatGPT’s memory might well
                           be too short to handle the text processing completely, but I wondered whether it
                           could improve its response, much as we can prod it to help us debug our code, and
                           whether it might help to remind it of the source texts again. 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">Elisa:</p>
                                 <p id="d4e281">Your approach is what I had in mind, good. But you've forgotten where the
                                    source texts are different. Can you redo this, taking another look at the
                                    source texts?</p>
                                 <p id="d4e282">Manuscript: It was on a dreary night of November that I beheld the frame
                                    on which my man compleated. And with an anxiety that almost amounted to
                                    agony I collected instruments of life around me that I might infuse a spark
                                    of being into the lifeless thing that lay at my feet.</p>
                                 <p id="d4e283">1818 edition and 1831 edition: It was on a dreary night of November, that
                                    I beheld the accomplishment of my toils. With an anxiety that almost
                                    amounted to agony, I collected the instruments of life around me, that I
                                    might infuse a spark of being into the lifeless thing that lay at my
                                    feet.</p>
                              </blockquote>
                           </div>
                           
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">ChatGPT:</p>
                                 <p id="d4e287">Apologies for the oversight. Let's revise the representation to include
                                    the differing portions as well. Here's the updated version:</p>
                                 <pre class="programlisting" id="d4e288">
                      Text differences:
+---------------------+---------------------------+-------------------------+
|       Manuscript     |      1818 edition         |     1831 edition        |
+---------------------+---------------------------+-------------------------+
| It was <span class="under">on</span> a dreary  | It was <span class="under">on</span> a dreary        | It was <span class="under">on</span> a dreary      |
| night <span class="under">of</span> November   | night <span class="under">of</span> November         | night <span class="under">of</span> November       |
| that I beheld the   | that I beheld the         | that I beheld the       |
| frame <span class="under">on</span> which my   | accomplishment <span class="under">of</span> my      | accomplishment <span class="under">of</span> my    |
| man compleated.     | toils.                    | toils.                  |
| <span class="ital">And</span> <span class="under">with</span> an anxiety | <span class="under">With</span> an anxiety that      | <span class="under">With</span> an anxiety that    |
| that almost amounted| almost amounted <span class="under">to</span> agony, | almost amounted <span class="under">to</span> agony|
| <span class="under">to</span> agony I collected| I collected the           | I collected the         |
| instruments <span class="under">of</span> life | instruments <span class="under">of</span> life       | instruments <span class="under">of</span> life     |
| around <span class="under">me</span> that I    | around <span class="under">me</span>,                | around <span class="under">me</span>,              |
| might infuse a spark| that I might infuse a     | that I might infuse a   |
| <span class="under">of</span> being <span class="under">into</span> the   | spark <span class="under">of</span> being <span class="under">into</span> the   | spark <span class="under">of</span> being <span class="under">into</span> the |
| lifeless thing that | lifeless thing that lay   | lifeless thing that lay |
| lay at my feet.     | at my feet.               | at my feet.             |
+---------------------+---------------------------+-------------------------+
                      
                  </pre>
                                 <p id="d4e377">In this refined representation, we have the text differences table with
                                    the Manuscript, 1818 edition, and 1831 edition side by side. The portions
                                    that are the same in all versions are omitted for brevity, and only the
                                    differing sections are displayed.</p>
                              </blockquote>
                           </div> With this response, I am baffled and simply stop the prompt experiment
                           sequence. ChatGPT seems unaware of what it is, and is not doing. There is a single
                           accentuated highlight (in yellow against the blue) of the capitalized word
                           <q>And</q> from the manuscript, but it has otherwise simply highlighted
                           short words across all the witnesses. What most surprised me was ChatGPT's assertion
                           that it <q>omitted</q> all the passages that were the same. It omitted
                           nothing. And it seemed to have no understanding of the concept of
                           differentiation.</p>
                        <p id="d4e383">I tried similar experiments this summer, wondering if differentiation of strings
                           might have improved after the news that ChatGPT had expanded its context window for
                           processing input. After June 21, developers are able to prompt ChatGPT with
                           8000-word prompts, and it will be able ot store longer passages in memory. My
                           prompts were not so long, but I suspect there is something challenging to the memory
                           processing about my requests to compare strings, and I was curious whether I might
                           see improvements. So I tried some similar experiments. Among my experiments were
                           efforts to ask ChatGPT to provide responses not in an alignment table but TEI
                           critical apparatus markup.<sup class="fn-label"><a href="#d4e385" class="footnoteref" id="d4e385-ref">[7]</a></sup></p>
                        <p id="d4e391">Here is a more recent experiment, requesting output in TEI critical apparatus
                           markup (with apologies to Samuel Taylor Coleridge for my flagrant abuse of
                           <q>The Rime of the Ancient Mariner</q>). 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">Elisa:</p>
                                 <p id="d4e397">Given these four text inputs, can you collate them and generate a TEI
                                    critical apparatus? 
                                    <div class="orderedlist" id="d4e399">
                                       <ol style="list-style-type: decimal;">
                                          <li id="d4e400">
                                             <p id="d4e401">It was an ancient Marinere eftsoons there went he.</p>
                                          </li>
                                          <li id="d4e402">
                                             <p id="d4e403">He was an old mariner, erstwhile he went there.</p>
                                          </li>
                                          <li id="d4e404">
                                             <p id="d4e405">It was an old Marinere, eftsoons there went he.</p>
                                          </li>
                                          <li id="d4e406">
                                             <p id="d4e407">He was an ancient Marinere, eftsoons he went there.</p>
                                          </li>
                                       </ol>
                                    </div>
                                    </p>
                              </blockquote>
                           </div>
                           
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">ChatGPT:</p>
                                 <p id="d4e412">Certainly! A critical apparatus in Text Encoding Initiative (TEI) format
                                    typically consists of variant readings with corresponding witnesses. In this
                                    case, the four text inputs are slightly different from each other, and we
                                    can create a simple critical apparatus for them. I will assume that each
                                    text is a separate witness (W1, W2, W3, and W4) in the critical
                                    apparatus.</p>
                                 <p id="d4e413">Here's the TEI critical apparatus:</p>
                                 <pre class="programlisting" id="d4e414">
&lt;app&gt;
  &lt;lem&gt;
    It was an ancient Marinere eftsoons there went he.
  &lt;/lem&gt;
  &lt;rdg wit="#W2"&gt;
    He was an old mariner, erstwhile he went there.
  &lt;/rdg&gt;
  &lt;rdg wit="#W3"&gt;
    It was an old Marinere, eftsoons there went he.
  &lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;
    He was an ancient Marinere, eftsoons he went there.
  &lt;/rdg&gt;
&lt;/app&gt;   
              </pre>
                                 <p id="d4e415"> In this representation: 
                                    <div class="itemizedlist" id="d4e417">
                                       <ul>
                                          <li id="d4e418">
                                             <p id="d4e419"><code class="code">&lt;lem&gt;</code> stands for the lemma (the base
                                                text).</p>
                                          </li>
                                          <li id="d4e422">
                                             <p id="d4e423"><code class="code">&lt;rdg&gt;</code> stands for a variant reading.</p>
                                          </li>
                                          <li id="d4e426">
                                             <p id="d4e427"><code class="code">wit="#W1"</code> represents the witness identifier for
                                                each variant reading.</p>
                                          </li>
                                       </ul>
                                    </div>
                                    </p>
                                 <p id="d4e431">Now, the critical apparatus shows that the lemma (base text) is "It was an
                                    ancient Marinere eftsoons there went he," and three variants (W2, W3, and
                                    W4) are provided with their corresponding readings. </p>
                              </blockquote>
                           </div> What is presented here as a distinct advantage over my other
                           experiments of being, quite simply correct. Indeed, none of these four sentences is
                           the same, and from ChatGPT this is a fair representation of TEI critical apparatus
                           encoding, representing a single moment of variation in the <code class="code">&lt;app&gt;</code>
                           element, and showing each of the four versions inside. Its explanation is clear. I
                           am not sure how it arrived at a concept of the lemma except that it seems to be
                           defaulting to the first as being somehow preferred for the base text. But this
                           markup is too simple and not especially useful if I am wanting to highlight
                           precisely where the texts align and where they differ. So I continued the
                           conversation. 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">Elisa:</p>
                                 <p id="d4e437">Can you improve this by using the <code class="code">&lt;app&gt;</code> elements only
                                    where there are forks or deltas in the text?</p>
                              </blockquote>
                           </div>
                           
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">ChatGPT:</p>
                                 <p id="d4e445">Certainly! In a critical apparatus, we can use the
                                    <code class="code">&lt;app&gt;</code> element only where there are forks or deltas
                                    (variants) in the text. This will help in presenting a more concise
                                    representation of the textual differences. Here's the improved TEI critical
                                    apparatus:</p>
                                 <pre class="programlisting" id="d4e449">
&lt;app&gt;
  &lt;lem&gt;
    It was an ancient Marinere eftsoons there went he.
  &lt;/lem&gt;
  &lt;rdg wit="#W2"&gt;
    He was an old mariner, erstwhile he went there.
  &lt;/rdg&gt;
  &lt;rdg wit="#W3"&gt;
    It was an old Marinere, eftsoons there went he.
  &lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;
    He was an ancient Marinere, eftsoons he went there.
  &lt;/rdg&gt;
&lt;/app&gt;    
                    </pre>
                                 <p id="d4e450">In this representation, the <code class="code">&lt;app&gt;</code> element encloses the
                                    entire set of variant readings (rdg elements) because there are textual
                                    differences among the witnesses at this point. Since the lemma (base text)
                                    remains the same in all cases, we don’t need separate
                                    <code class="code">&lt;app&gt;</code> elements for each witness.</p>
                              </blockquote>
                           </div> This was amusing. ChatGPT does not change its code: it is identical.
                           It explains to me that, of course, the witnesses each differ from one another. This
                           is a justification or rationalization of its response. </p>
                        <p id="d4e457">If I want it to approach the problem differently perhaps I need a better prompt.
                           So I try again. In the prompt below, I attempted to show ChatGPT what kind of output
                           I wanted to see, and gave it a start that I requested it to continue. (I
                           inadvertently left the second app element unclosed, though this omission does not
                           seem to have affected the reply.) 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">Elisa:</p>
                                 <p id="d4e461">That is not what I meant. I'd like you to apply the critical apparatus
                                    using inline parallel segmentation. This means you should show just one line
                                    of text where all witnesses are the same, and then use the
                                    <code class="code">&lt;app&gt;</code> element in the specific moments where the text
                                    differs. Here is how you could begin: 
                                    <pre class="programlisting" id="d4e465"> 
                   &lt;app&gt;
                       &lt;rdg wit="#W1 #W3"&gt;It&lt;/lem&gt;
                           &lt;rdg wit="#W2 #W4"&gt;He&lt;/rdg&gt;
                   &lt;/app&gt;
                   was an
                   &lt;app&gt;
                       &lt;rdg wit="#W1 #W4"&gt;ancient&lt;/rdg&gt;
                       &lt;rdg wit="#W2 #W3&gt;old&lt;/rdg&gt;
   
                  </pre>
                                    </p>
                                 <p id="d4e467">Can you continue based on this start?</p>
                              </blockquote>
                           </div>
                           
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">ChatGPT:</p>
                                 <p id="d4e471">Apologies for the misunderstanding. I understand now that you want to
                                    represent the critical apparatus using inline parallel segmentation. Here's
                                    the continuation based on the start you provided:</p>
                                 <pre class="programlisting" id="d4e472">                        
&lt;app&gt;
  &lt;rdg wit="#W1 #W3"&gt;It&lt;/rdg&gt;
  &lt;rdg wit="#W2 #W4"&gt;He&lt;/rdg&gt;
&lt;/app&gt;
was an
&lt;app&gt;
  &lt;rdg wit="#W1 #W4"&gt;ancient&lt;/rdg&gt;
  &lt;rdg wit="#W2 #W3"&gt;old&lt;/rdg&gt;
&lt;/app&gt;
Marinere
&lt;app&gt;
  &lt;rdg wit="#W1 #W3 #W4"&gt;eftsoons there&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;erstwhile&lt;/rdg&gt;
&lt;/app&gt;
went he.
    
                    </pre>
                                 <p id="d4e473">In this representation, the critical apparatus is represented using the
                                    <code class="code">&lt;app&gt;</code> element, and within each
                                    <code class="code">&lt;app&gt;</code> element, we use the <code class="code">&lt;rdg&gt;</code>
                                    elements to indicate the variant readings for different witnesses (W1, W2,
                                    W3, and W4).</p>
                                 <p id="d4e481">I hope this format better meets your requirements for inline parallel
                                    segmentation. Let me know if you need any further adjustments!</p>
                              </blockquote>
                           </div> At first glance this appeared to be what I wanted, but on review of
                           the strings I had asked ChatGPT to collate, we need to recognize some significant
                           errors. 
                           <div class="orderedlist" id="d4e483">
                              <ol style="list-style-type: decimal;">
                                 <li id="d4e484">
                                    <p id="d4e485">It was an ancient Marinere eftsoons there went he.</p>
                                 </li>
                                 <li id="d4e486">
                                    <p id="d4e487">He was an old mariner, erstwhile he went there.</p>
                                 </li>
                                 <li id="d4e488">
                                    <p id="d4e489">It was an old Marinere, eftsoons there went he.</p>
                                 </li>
                                 <li id="d4e490">
                                    <p id="d4e491">He was an ancient Marinere, eftsoons he went there.</p>
                                 </li>
                              </ol>
                           </div> ChatGPT's critical apparatus markup declares that all of the texts
                           share the capitalized and distinct spelling <q>Marinere</q>, missing the
                           difference of witness 2 which has <q>mariner</q>. It also misses the
                           presence or absence of the comma (omitting it entirely in the critical apparatus).
                           Finally, there is the issue with representing transposition. Versions 2 and 4 show
                           <q>he went there</q> while Versions 1 and 3 have <q>there went
                              he</q>. ChatGPT almost completely these differences in its representation of
                           the end of the passages. Its apparatus correctly represents Text 2 as the only
                           variant holding <q>erstwhile</q>, but it incorrectly identifies Text 4 as
                           showing <q>eftsoons there</q> along with Texts 1 and 3. It should have
                           stopped the alignment at <q>eftsoons</q>, and created a new
                           <code class="code">&lt;app&gt;</code> to hold the variations of <q>there went he</q>
                           vs. <q>he went there</q>. It was doing pretty well, but clearly this was
                           only an approximation and precise accuracy is not to be expected.</p>
                        <p id="d4e515">Still I wondered if I had given ChatGPT something too short and intricate with too
                           many small variations. What if I added a bit to the four strings that would give it
                           something that should be easy to align, a long stretch of identical tokens? Could
                           it
                           show improvement, continuing on? 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">Elisa:</p>
                                 <p id="d4e519"> You're on the right track, but you're dropping some of the text in your
                                    comparison. Let's try again with a longer set of texts to see if that helps. 
                                    <div class="orderedlist" id="d4e521">
                                       <ol style="list-style-type: decimal;">
                                          <li id="d4e522">
                                             <p id="d4e523">It was an ancient Marinere eftsoons there went he. He wanted
                                                to talk to the AI about collation and TEI.</p>
                                          </li>
                                          <li id="d4e524">
                                             <p id="d4e525">He was an old mariner, erstwhile he went there. He wanted to
                                                talk about TEI to the AI that day.</p>
                                          </li>
                                          <li id="d4e526">
                                             <p id="d4e527">It was an old Marinere, eftsoons there went he. He wanted to
                                                talk to the AI about TEI.</p>
                                          </li>
                                          <li id="d4e528">
                                             <p id="d4e529">He was an ancient Marinere, eftsoons he went there. He wanted
                                                to talk about TEI and AI.</p>
                                          </li>
                                       </ol>
                                    </div>
                                    </p>
                              </blockquote>
                           </div>
                           
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">ChatGPT:</p>
                                 <p id="d4e534">Apologies for the oversight. Let's try again with the longer set of texts,
                                    using the inline parallel segmentation for the TEI critical
                                    apparatus:</p>
                                 <pre class="programlisting" id="d4e535">
&lt;app&gt;
  &lt;rdg wit="#W1 #W3"&gt;It was an ancient Marinere eftsoons there went he.&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;He was an old mariner, erstwhile he went there.&lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;He was an ancient Marinere, eftsoons he went there.&lt;/rdg&gt;
&lt;/app&gt;
&lt;app&gt;
  &lt;rdg wit="#W1"&gt;He wanted to talk to the AI about collation and TEI.&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;He wanted to talk about TEI to the AI that day.&lt;/rdg&gt;
  &lt;rdg wit="#W3"&gt;He wanted to talk to the AI about TEI.&lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;He wanted to talk about TEI and AI.&lt;/rdg&gt;
&lt;/app&gt;
                    </pre>
                                 <p id="d4e536"> In this representation:</p>
                                 <p id="d4e537">The first <code class="code">&lt;app&gt;</code> element contains the variant readings
                                    for the first sentence: <q>It was an ancient Marinere eftsoons there
                                       went he.</q> (W1, W2, W3, and W4). The second
                                    <code class="code">&lt;app&gt;</code> element contains the variant readings for the
                                    second sentence: "He wanted to talk to the AI about collation and TEI."
                                    (W1), "He wanted to talk about TEI to the AI that day." (W2), "He wanted to
                                    talk to the AI about TEI." (W3), and "He wanted to talk about TEI and AI."
                                    (W4).</p>
                                 <p id="d4e545">This format shows the differences between the witnesses inline for each
                                    sentence. Let me know if this meets your requirements, or if you need any
                                    further adjustments!</p>
                              </blockquote>
                           </div> Somehow in the series of prompts and responses, something I expect
                           ChatGPT to have <q>learned</q> seems to be forgotten. ChatGPT is returning
                           to its original preference for blocking long portions of text in the
                           <code class="code">&lt;rdg&gt;</code> elements. It is nevertheless indicating, incorrectly,
                           that Texts 1 and 3 agree completely, when Text 3 contains a comma after
                           <q>Marinere</q>. Is the experiment worth continuing? Reader, I did
                           continue, but saw similar patterns of error with dropping punctuation or variant
                           tokens, and with ignoring sameness in long blocks it marked variant. The last
                           response provided by ChatGPT to this series provides a good summary representation
                           of each of these problems: 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">ChatGPT:</p>
                                 <pre class="programlisting" id="d4e556">
&lt;app&gt;
  &lt;rdg wit="#W1 #W3"&gt;It was an&lt;/rdg&gt;
  &lt;rdg wit="#W2 #W4"&gt;He was an&lt;/rdg&gt;
&lt;/app&gt;
&lt;app&gt;
  &lt;rdg wit="#W1"&gt;ancient&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;old&lt;/rdg&gt;
  &lt;rdg wit="#W3 #W4"&gt;old&lt;/rdg&gt;
&lt;/app&gt;
Marinere eftsoons there went he. He wanted to talk to the AI about collation and TEI.
&lt;app&gt;
  &lt;rdg wit="#W1"&gt;He wanted to talk to the AI about collation and TEI.&lt;/rdg&gt;
  &lt;rdg wit="#W2"&gt;He wanted to talk about TEI to the AI that day.&lt;/rdg&gt;
  &lt;rdg wit="#W3"&gt;He wanted to talk to the AI about TEI.&lt;/rdg&gt;
  &lt;rdg wit="#W4"&gt;He wanted to talk about TEI and AI.&lt;/rdg&gt;
&lt;/app&gt;   
         </pre>
                                 <p id="d4e557">Now, the revised encoding correctly shows the common phrase "He wanted to
                                    talk to the AI about collation and TEI." in the second text, which is
                                    present across all four witnesses (W1, W2, W3, and W4).</p>
                              </blockquote>
                           </div> ChatGPT replaces one kind of problem for a new kind of error. There
                           are omissions and failures to recognize precisely what is common and what is not.
                           And now text that it claims to be the same across all versions is <span class="ital">also</span> represented as variant. This is a terrible
                           misrepresentation, but the kinds of errors make me wonder how the language model is
                           attempting to process my requests. Why is it creating these errors? </p>
                        <p id="d4e562">I had learned that sometimes if you prompt the chatbot to pretend that it is an
                           expert in an area that this would help improve its response, and in some of my
                           experiments this year I attempted this sort of <q>let’s pretend</q> game to
                           ask ChatGPT to pretend they are an expert in the TEI and preparing a digital
                           scholarly edition, but at least for the tasks I was requesting they did not help to
                           improve the responses. They are predictably unreliable, and never once did I see a
                           response without errors. I also tried simplifying the task and asking it directly
                           only to <q>diff</q> some strings, but this made no difference and I have yet
                           to see an accurate response to a prompt requesting a comparison of two or more
                           strings.</p>
                        <p id="d4e568">Finally, I attempted an experiment with Anthropic’s Claude AI, which purports to
                           having a larger memory capacity and context window for prompt processing that
                           ChatGPT.<sup class="fn-label"><a href="#d4e570" class="footnoteref" id="d4e570-ref">[8]</a></sup> The results were slightly better out of the box. In this case I returned to
                           comparing two versions of the passage from <span class="ital">Frankenstein</span>: 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">Elisa:</p>
                                 <p id="d4e580">You are preparing a critical edition in TEI using critical apparatus
                                    markup. Can you prepare a sample of code for comparing two editions based on
                                    the following three versions of the same passage?</p>
                                 <p id="d4e581">Manuscript: It was on a dreary night of November that I beheld the frame
                                    on which my man compleated. And with an anxiety that almost amounted to
                                    agony I collected instruments of life around me that I might infuse a spark
                                    of being into the lifeless thing that lay at my feet.</p>
                                 <p id="d4e582">1818 edition and 1831 edition: It was on a dreary night of November, that
                                    I beheld the accomplishment of my toils. With an anxiety that almost
                                    amounted to agony, I collected the instruments of life around me, that I
                                    might infuse a spark of being into the lifeless thing that lay at my
                                    feet.</p>
                              </blockquote>
                           </div>
                           
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">Claude.ai:</p>
                                 <p id="d4e586">Here is a sample TEI encoding of the critical apparatus comparing those
                                    three versions of the passage:</p>
                                 <pre class="programlisting" id="d4e587">
&lt;p&gt;It was on a dreary night of November, that I beheld the 
&lt;app&gt;
  &lt;rdg wit="#MS"&gt;frame on which my man compleated&lt;/rdg&gt;
  &lt;rdg wit="#1818 #1831"&gt;accomplishment of my toils&lt;/rdg&gt;. 
&lt;/app&gt;
With an anxiety that almost amounted to agony, I collected the instruments of 
life around me, that I might infuse a spark of being into the lifeless thing that 
lay at my feet.&lt;/p&gt;     
                    </pre>
                              </blockquote>
                           </div> This is <span class="ital">almost</span> correct, and indeed, I
                           was surprised to find that Claude was unifying the text streams around the parallel
                           portions. It was missing the differences in punctuation, however, and even when I
                           prompted Claude to correct for omissions they might have made, Claude failed to
                           identify the problems. </p>
                        <p id="d4e592">Experimenting with text-generative language models in the previous months has
                           illuminated some interesting problems in comparing text strings in language models
                           that work with tokenized string inputs. Comparisons are fuzzy, overly broad, or
                           outright drop tokens and usually misrepresent the source texts in some way. Not only
                           were the results almost always inaccurate, but on repeated prompts and requests for
                           corrections, neither ChatGPT nor Claude could not be said to improve significantly.
                           Why are the models so problematic at a task that involves identifying sameness and
                           difference in sequences of tokenized text? I can only speculate since I lack access
                           or expertise to comprehend the working systems <q>under the hood</q> of the
                           language models, but I speculate that the problems stem from a fundamentally
                           different way of <q>reading</q> tokens. That is, the method of reading input
                           and studying word embeddings in the langauge model is based on a more complicated
                           statistical process than the simple edit-distance calculation I requested. Perhaps
                           the AI can <q>read</q> in no other way than by the (statistical)
                           books.</p>
                     </div>
                     <div class="section" id="d4e600">
                        <h3 class="title" style="clear: both">From stochastic parrot to reasoning intelligence?</h3>
                        <p id="d4e602">As a human (read: limited, inconsistent) reader of texts I am in awe that a
                           mathematically trained language model, a so-called <q>artificial
                              intelligence</q> which I expect to be more consistent and adept at pattern
                           recognition than I am, consistently struggles with what seems to be a simple
                           comparison of strings. Is it a shortness of Long-Term Short-Term Memory (LTSTM) that
                           causes the models to lose track of the details in the process of calculating a
                           response? Perhaps ChatGPT’s current inability to analyze comparisons of strings has
                           something to do with its token-by-token generative stream. ChatGPT can correctly
                           tell me what Levenshtein (or edit-distance) distance is: 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p class="title">ChatGPT:</p>
                                 <p id="d4e608">The Levenshtein distance is a measure of the minimum number of
                                    single-character edits (insertions, deletions, or substitutions) required to
                                    change one string into another.</p>
                              </blockquote>
                           </div> The AI can also separate two different versions of a text in different
                           boxes. But it cannot accurately calculate the edit-distance and it cannot seem to
                           pinpoint variations. In the task of preparing an alignment table or a TEI critical
                           apparatus, the AI supplies the illusion of structure with some persistent blind
                           spots. Perhaps it is failing to <q>see</q> what constitutes a reasonable,
                           meaningful basis for comparison of text streams. Perhaps this is due to a confusion
                           between its paradigm of understanding tokens based on
                           <span class="ital">relatedness</span> as opposed to their exact sameness or
                           difference. In other words, I suspect that something about semantics is getting in
                           the way, not literally the meaning of the text, but rather the programming to
                           associate tokens with each other based on their co-occurence, the vectorized word
                           embeddings that helps the AI predict the next token to generate. The very capacities
                           that permit ChatGPT and Claude to converse in a reasonable voice interfere with
                           their capacities to calculate or prepare an accurate programming script. We have
                           been learning these past several months simply to expect, and live with, AI being
                           fast but fuzzy, to expect error, and certainly not to ask it do to our math homework.<sup class="fn-label"><a href="#d4e614" class="footnoteref" id="d4e614-ref">[9]</a></sup></p>
                        <p id="d4e621">Perhaps we should not expect anything better. Today dialogue with generative
                           language-based AI gives us the opportunity to declare and inquire with the voice of
                           reason, but the stochastic outputs we receive sometimes contradict themselves and
                           frequently miscalculatge and misrepresent. We understand that prompt generation is
                           based on statistical predictions of what might be the best-fit, reasonable next
                           tokens of text to supply in sequence, and that this makes them not intelligent at
                           all but rather stochastic machines.<sup class="fn-label"><a href="#d4e623" class="footnoteref" id="d4e623-ref">[10]</a></sup> Further, we understand these stochastic machines can do damage, because
                           they amplify even the veiled language of racism and sexism that often goes nearly
                           unheard or unmarked in everyday discourse of Wikipedia and Reddit and social media.<sup class="fn-label"><a href="#d4e633" class="footnoteref" id="d4e633-ref">[11]</a></sup> In the year 2023, text-generative AI speaks with a language of authority
                           and confidence that amplifies normative values in its unstable predictions of the
                           best fit content completion for a prompt. We know these limitations, and their
                           consequences are dire.</p>
                        <p id="d4e644">Reasoned authority is what we expect of optimal interactions with computers, and
                           this is a foundational value of our declarative markup community. In slides from a
                           2015 digital humanities conference presentation, Michael Sperberg-McQueen claims,
                           <q>Declarative semantics make it possible to reason about representations;
                              imperative semantics impede.</q><sup class="fn-label"><a href="#d4e647" class="footnoteref" id="d4e647-ref">[12]</a></sup> Nothing in our modeling of texts escapes bias, but our capacity to
                           assert and test reasonable statements is a particular strength of declarative markup
                           and the tooling our community has developed for it. In that 2015 presentation,
                           Sperberg-McQueen also points out that hierarchical models are not neutral. The way
                           we organize document hierarchies and decide on markup representations, and create
                           schema rules to validate our models does not represent reflect absolute
                           <q>ground truth</q>, but rather attempts to describe and define based on
                           what choose to prioritize, whether that is the section headings of a legislative
                           memo or the page-by-page printing of a comic book. The models we create for
                           documents and the metadata we care about reflect the paradigms and priorities of the
                           humans who create them. Document historians of the future may come back to our XML
                           markup and find us benighted, but they could also research in our models the rules
                           of our publishing houses, the attitudes and expectations that prevailed in
                           understanding how to study language and archive our cultural heritage. The point is,
                           what we express in declarative semantics is fully visible, tractable, and usually
                           documented. Our ways of thinking about texts, however flawed, are explicitly and
                           deliberately marked. By stark contrast, the biases amplified by large language
                           models in our stochastic systems are revealed only by analyzing the outputs or
                           attempting to source the now-secret training data.</p>
                        <p id="d4e659">That seminal article from 1990 <q>What is Text, Really?</q> is striking in
                           the year 2023 for how current it remains as a critique of prevailing machine systems
                           for handling text.<sup class="fn-label"><a href="#d4e663" class="footnoteref" id="d4e663-ref">[13]</a></sup> Their proposition, that text really is an Ordered Hierarchy of Content
                           Objects, came explicitly as a response (among other things) to concepts of text as
                           a
                           stream of content objects, the gram particles and formmating instructions without
                           reference to structural context. In the year 2023 when we ask questions to large
                           language models we are given to understand that text is generated in response to a
                           limited <q>context window</q> that the language model uses for perceiving
                           the range of nearby tokens and their proximity to the current token a frame of
                           reference. Is it then the case in 2023 that context in the large language model is
                           being determined by frames of reference in a stream of text? When an approximation
                           of semantics is coded and decoded in vector space by position and token
                           co-occurrence, this generates the appearance of meaningful output, which cannot be
                           said to represent truth but might sometimes approximate it. This is the argument of
                           the famous <q>Stochastic Parrots</q> article: that large language models
                           distort, exploit, and waste resources in an effort only to produce unreliable and
                           biased approximations. <sup class="fn-label"><a href="#d4e675" class="footnoteref" id="d4e675-ref">[14]</a></sup>
                           </p>
                        <p id="d4e690">Should we expect better of so-called <q>artificial intelligence</q> in our
                           time, to attempt something more than formulaic approximations of reasoned responses?
                           Mulitple researchers suggest that large language models could attempt a wider range
                           of learning methods, to associate metadata wtih data, or to attempt solving complex
                           problems using hierarchical decision trees.<sup class="fn-label"><a href="#d4e694" class="footnoteref" id="d4e694-ref">[15]</a></sup> A group of researchers writing from the NIH, discussing the application
                           of AI in medical diagnostics, explicitly calls for declarative methods to improve
                           the learning algorithms. Because they historicize artificial intelligence to show
                           how declarative methods once were central in Lisp and Prolog, they provide a helpful
                           differentiation between AI then and now: 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p id="d4e715">The main goal of AI has been to develop programs that make intelligent
                                    decisions and solve real-world problems, possibly dealing with “messy" real
                                    world input that could make it difficult to handle using “conventional"
                                    programming. The earlier AI problem solvers were expert systems that
                                    attempted to model the way experts reason and make decisions using a set of
                                    logical rules. Programming languages like Lisp and Prolog were designed to
                                    make programming such systems easy even for non-expert users. The idea was
                                    to represent the domain knowledge using a set of logical rules, and use the
                                    rules in a logical reasoning process hidden from the programmers.</p>
                                 <p id="d4e716">From the traditional AI perspective, this is a declarative programming
                                    paradigm where we program for the what and not the how. The expert programs
                                    could go beyond an independent set of rules and turn to logical programs
                                    with a Turing-complete expressivity, supporting logical inference, for
                                    example, by unification and resolution. However, real-world problems are
                                    complex and often involve many interdependent components . . .It has become
                                    evident that formalizing complex problem solving using programming a finite
                                    set of deterministic logic-based rules is not possible, nor is it possible
                                    to write a conventional structured program, even with a Turing-complete
                                    language, for supporting intelligent decision-making based on naturally
                                    occurring data.</p>
                              </blockquote>
                           </div>The virtues of declarative methods are here expressed in familiar
                           terms: domain experts can communicate needed information and apply programming to
                           validate according to logical constraints. The authors point out how insufficient
                           these machine learning techniques are, and call for augmenting them with what they
                           call Systems AI using declarative methods. 
                           <div class="blockquote">
                              <blockquote class="blockquote">
                                 <p id="d4e719">We emphasize the need to use some fundamental declarative ideas such as
                                    first-order query languages, knowledge representation and reasoning
                                    techniques, programming languages for multi agent systems, database
                                    management systems (DBMS), and deductive databases (DDB). We need to place
                                    these ideas within and around ML formalisms including classical ML tools,
                                    deep learning libraries and automatic differentiation tools, and integrate
                                    them with innovative programming languages and software development
                                    techniques, as a way to address complex real-world problems that require
                                    both learning and reasoning models.<sup class="fn-label"><a href="#d4e721" class="footnoteref" id="d4e721-ref">[16]</a></sup></p>
                              </blockquote>
                           </div>
                           I have quoted at length to emphasize a point that should not be
                           forgotten about the origins of artificial intelligence work in declarative methods,
                           and the capacity of declarative methods to alter the grounds of what a machine
                           intelligence can reference. The language models with which we interact in 2023
                           cannot change paradigms for how they evaluate language. If they are to develop to
                           become precision instruments that do no harm, declarative methods may be the way
                           forward. </p>
                     </div>
                  </div>
                  <div class="section" id="d4e730">
                     <h2 class="title" style="clear: both">How meaningful is markup, anyway?</h2>
                     <p id="d4e732">When the text-generative AI models composed the markup shared in the previous section,
                        their declarative semantics were unclear and often inconsistently applied.Perhaps
                        its
                        purpose became diluted by other imperatives of the generative language algorithm.
                        We
                        could describe such output as expressing a middle state, a string bearing the forms
                        of
                        markup but with dubious or disreputable declarative semantics. The way declarative
                        logic
                        is incorporated in a text-processing system matters. How deliberate can we be in
                        applying it and generating the output we ask for? In their current form, large language
                        models are limited in their capacities to handle complex tasks.</p>
                     <p id="d4e733"> When handled deliberately, declarative logic can be processed in imperative programs
                        without loss of their significance in the output. Transforming text into other formats
                        shows us what is fluid and transferrable in markup. We map its structures into forms
                        that machines need to read, and when we do that they become moveable bins or containers
                        of information. The process has been vital to our collation project for the Frankenstein
                        Variorum, where a deliberate declared logic for controlling the basis for comparison
                        has
                        been key to consistent processing.</p>
                     <div class="section" id="d4e734">
                        <h3 class="title" style="clear: both">Markup as declarative intervention in an imperative process</h3>
                        <p id="d4e736">The process of refining the collation process for the Frankenstein Variorum
                           involved a serious challenge to stop the collateX software from its default
                           mechanism, always to align the smallest particles of the same text. CollateX
                           definitely tends to align the smallest irreducible units of text (tokens) that it
                           reads as <q>the same</q>, like <q>a</q>, <q>an</q>, and
                           <q>the</q>, even in passages that are not meant to be associated across
                           the texts.<sup class="fn-label"><a href="#d4e746" class="footnoteref" id="d4e746-ref">[17]</a></sup> One solution is to normalize the text stream in pre-processing prior to
                           collation, to exclude such articles or short punctuation, but this did not accord
                           with our methods of comparing the texts: the small words do matter to us when they
                           mark variations. Other solutions involve post-processing or editing the output
                           collation units by hand, which in our case was a brittle solution, prone to
                           introducing new errors. Some of the versions of Frankenstein
                           contain long inserted blocks, multi-paragraph inserted passages, and gaps in the
                           manuscript that make it tricky to prepare aligned units (or <q>chunks</q>
                           representing parallel passages across the five versions).</p>
                        <p id="d4e765">Over the last year, my student Yuying Jin and I established a reliable method for
                           bracketing off long divergent passages, a method that we call our
                           <q>longToken</q> strategy. Here we lengthen the size of the smallest
                           particle of comparable text to the size of whatever we can express inside an XML
                           element <code class="code">&lt;longToken&gt;.....&lt;/longToken&gt;</code>. We instructed our
                           Python script to isolate all tokens by newline characters, and set the entire length
                           of longToken (which could be as small as a single character and as large as two
                           paragraphs of text, including flattened markup) all in one irreducible line. By
                           controlling the tokenization algorithm, we were able to control the mechanism of the
                           collation software, prevent it from making spurious alignments on small words in a
                           passage that we would effectively bracket away from micro-comparisons.</p>
                        <p id="d4e771">Our Python script is a place of negotiation between paradigms of structured markup
                           and so-called unstructured text. We use the <a href="https://docs.python.org/3/library/xml.dom.pulldom.html" class="link">XML Pulldom
                              library</a> to process what markup from the source documents we want to
                           include in the string comparison process. That is, we mask away some elements, like
                           the page <code class="code">&lt;surface&gt;</code> and <code class="code">&lt;zone&gt;</code> elements that
                           indicate page surfaces and locations on the pages from the Shelley-Godwin Archive
                           encoding, because we have decided that page position is not relevant to comparison
                           of the semantic text structure. But we want to preserve the element nodes that mark
                           paragraphs, and chapter structures, and we want to preserve the information about
                           deletion marks in the manuscript and from the Thomas copy. The word
                           <q>mask</q> seems appropriate here: it is something like applying tape
                           to pieces of the file that we select. We continue to work with the markup, though,
                           in its meaningful form. In the Python script, we define variables containing lists
                           of element names that we will either mask away from the collation, or that we will
                           include: 
                           <pre class="programlisting" id="d4e782">
ignore = ['sourceDoc', 'xml', 'comment', 'include', 'addSpan', 'handShift', 'damage', 
                'unclear', 'restore', 'surface', 'zone', 'retrace']
blockEmpty = ['p', 'div', 'milestone', 'lg', 'l', 'cit', 'quote', 'bibl']
inlineEmpty = ['mod', 'pb', 'sga-add', 'delSpan', 'anchor', 'lb', 'gap', 
                 'hi', 'w', 'ab']
inlineContent = ['del-INNER', 'add-INNER', 'metamark', 'shi']
inlineVariationEvent = ['head', 'del', 'mdel', 'add', 'note', 'longToken']
                </pre> The <code class="code">ignore</code> variable contains
                           everything we are screening away from the stream of text comparison. The other
                           variables represent elements types we will see in the input. This input contains
                           some recognizable elements from the TEI, but <code class="code">&lt;p&gt;</code>,
                           <code class="code">&lt;lg&gt;</code>, and <code class="code">&lt;l&gt;</code> are defined in the
                           <code class="code">blockEmpty</code> list, along with <code class="code">&lt;milestone&gt;</code>, which
                           is the only element that those knowledgeable of the TEI would recognize as
                           legitimately empty.</p>
                        <p id="d4e797">What have we done to the TEI? Perhaps a sacrilege, but we are meddling with TEI
                           XML files as, after all, text files that hold meaningful declarative markup, and we
                           have converted their element nodes into a format that allows us to compare texts
                           based on their original structures by removing the structures to process the
                           comparison.</p>
                     </div>
                     <div class="section" id="d4e798">
                        <h3 class="title" style="clear: both">There and back again: Transferring declared semantics</h3>
                        <p id="d4e800">In preparing our editions for collation (as discussed in previous Balisage
                           papers), we have <q>flattened</q> the original TEI structural elements, and
                           abstracted them away from their original document models. We do this on purpose to
                           represent the element tags as Trojan-style markers and to be able to work them into
                           our a new XML file that stores a standoff critical apparatus in TEI. That file
                           represents the results of our collation pipeline, and it stores a flattened
                           representation of the tags from the source editions. The standoff critical apparatus
                           serves, also, as a basis for creating new edition files that store the collation
                           data, highlighting passages that vary with the other editions.</p>
                        <p id="d4e804">In this process, the semantics of the declarative markup from the source files are
                           preserved even while that markup has undergone a complicated series of
                           transformations. First it is transferred into strings or a stream of text in order
                           to be collated. Then that stream of text is mapped back again into new XML
                           structures to represent the meaningful data in the critical apparatus about how the
                           texts compare to one another.</p>
                        <p id="d4e805">Moving in between text-processing paradigms illuminates a transfer of semantics
                           into format. The logic of declarative markup is preserved in the Python function
                           running the pull parser via the XML Pulldom library. This function delivers us a way
                           to transfer the logic of the markup element nodes into the formatting used to
                           prepare the tokens and normalized tokens to be delivered to the collateX software.
                           
                           <pre class="programlisting" id="d4e807">
    def extract(input_xml):
    """Process entire input XML document, firing on events"""
    doc = pulldom.parse(input_xml)
    output = ''
    for event, node in doc:
        if event == pulldom.START_ELEMENT and node.localName in ignore:
            continue
        # copy comments intact
        # if event == pulldom.COMMENT:
        #     doc.expandNode(node)
        #     output += node.toxml()
        # ebb: The following handles our longToken and longToken-style elements:
        # complete element nodes surrounded by newline characters to make a long complete token:
        if event == pulldom.START_ELEMENT and node.localName in inlineVariationEvent:
            doc.expandNode(node)
            output += '\n' + node.toxml() + '\n'
        # stops the problem of forming tokens that fuse element tags to words.
        elif event == pulldom.START_ELEMENT and node.localName in blockEmpty:
            output += '\n' + node.toxml() + '\n'
        # ebb: empty inline elements that do not take surrounding white spaces:
        elif event == pulldom.START_ELEMENT and node.localName in inlineEmpty:
            output += node.toxml()
        # non-empty inline elements: mdel, shi, metamark
        elif event == pulldom.START_ELEMENT and node.localName in inlineContent:
            output += '\n' + regexEmptyTag.sub('&gt;', node.toxml())
            # output += '\n' + node.toxml()
        elif event == pulldom.END_ELEMENT and node.localName in inlineContent:
            output += '&lt;/' + node.localName + '&gt;' + '\n'
        # elif event == pulldom.START_ELEMENT and node.localName in blockElement:
        #    output += '\n&lt;' + node.localName + '&gt;\n'
        # elif event == pulldom.END_ELEMENT and node.localName in blockElement:
        #    output += '\n&lt;/' + node.localName + '&gt;'
        elif event == pulldom.CHARACTERS:
            # output += fixToken(normalizeSpace(node.data))
            output += normalizeSpace(node.data)
        else:
            continue
    return output</pre> The <q>partial DOM tree</q> constructed
                           by XML PullDom serializes something resonant with the semantics of explicit markup,
                           allowing us in our project to hold the logic and even the structure of markup as a
                           stream of text to be tokenized, chopped into the smallest fragments of meaningful
                           variation. Thanks to the advantage of declarative markup, the scholarly editor gets
                           to declare what that smallest fragment can be. A full element node marking an
                           <code class="code">inlineVariationEvent</code> surrounded by <code class="code">\n</code> newline
                           characters becomes an irreducible token in , and this includes the
                           <code class="code">&lt;longToken&gt;</code>, <code class="code">&lt;add&gt;</code>, and
                           <code class="code">&lt;del&gt;</code> elements that in our project mark irreducible units of
                           comparison. We want an entire added or deleted passage to be lined up complete as
                           one action in the text. It must be compared to a full comparable unit marked in the
                           other documents, fully undeleted. That is a decision of our scholarly edition work
                           to handle collation events, and it means that a deletion event followed by an
                           insertion event in the Thomas text (where the author crossed out a passage and
                           indicated another to add) effectively drives the collation software to generate a
                           specially shaped entry in our critical apparatus. We have programmed our work to
                           prepare this output: 
                           <pre class="programlisting" id="d4e822">
               &lt;app&gt;
		&lt;rdgGrp
			n="['&lt;del&gt;to his statement, which was delivered&lt;/del&gt;', 
			'to him with interest for he spoke']"&gt;
			&lt;rdg wit="fThomas"&gt;&lt;del rend="strikethrough"&gt;to his statement, 
			which was delivered&lt;/del&gt; &lt;add&gt;to him with interest
			for he spoke&lt;/add&gt;&lt;/rdg&gt;
		&lt;/rdgGrp&gt;
		&lt;rdgGrp n="['to his statement, which was delivered']"&gt;
			&lt;rdg wit="f1818"&gt;&lt;longToken&gt;to his statement, which was
				delivered&lt;/longToken&gt;&lt;/rdg&gt;
			&lt;rdg wit="f1823"&gt;&lt;longToken&gt;to his statement, which was
				delivered&lt;/longToken&gt;&lt;/rdg&gt;
			&lt;rdg wit="f1831"&gt;&lt;longToken&gt;to his statement, which was
				delivered&lt;/longToken&gt;&lt;/rdg&gt;
		&lt;/rdgGrp&gt;
	&lt;/app&gt;</pre> This output from collateX is formatted according to
                           the TEI XML critical apparatus to express the logic of elements storing variation
                           information across five source edition files. A moment of meaningful variation is
                           stored in an <code class="code">&lt;app&gt;</code> element, and each of uts
                           <code class="code">&lt;rdg&gt;</code> descendants stores a single token representing the text
                           of one witness, here a phrase that we purposefully blocked off to be an irreducible
                           unit of comparison using the <code class="code">&lt;longToken&gt;</code> element. You can see the
                           trace of the longToken elements in the <code class="code">&lt;rdg&gt;</code> text nodes, while
                           the <code class="code">@n</code> attribute on the <code class="code">&lt;rdgGrp</code> elements serves to
                           express how the collation software normalizes each token to show on what basis the
                           <code class="code">&lt;rdg&gt;</code> elements inside are understood to agree: the trace of
                           the longToken element is removed there because it is not itself part of the string
                           we ask the collation software to compare. </p>
                        <p id="d4e839">In the example, the collation software follows our normalizing algorithm to
                           determine that three of the witnesses share one form, and the Thomas edition holds
                           the same passage crossed out together with its complete replacement. Here,
                           declarative markup provides a precise way to delineate information on what
                           constitutes an indivisible token to the software. With the demarcation of a
                           <code class="code">&lt;longToken&gt;</code> I can bracket off passages of text and force the
                           software to deal with them on my terms. This gives us control of a process of
                           pair-wise comparisons by allowing us to alter the usual definition of the smallest
                           unit of meaningful variation. Declarative markup thus permits us to express our
                           theory of textual variation in the logic of the programming pipeline. Certainly we
                           did something unorthodox with the machinery of comparing texts and we invented our
                           own markup outside the TEI to declare what a token could be, and I want to call this
                           a deliberate, <span class="ital">declarative intervention</span> in the imperative
                           algorithms. </p>
                        <p id="d4e845">This presupposes that the imperative tools can read the declarations, and
                           accommodate the markup. For this capacity in our project, we flatten the element
                           nodes into strings and identify those as regular expression patterns for processing.
                           In our project we raise them again into elements with an XSLT pipeline, here fully
                           relying on declarative methods to communicate our desired output. But in the crucial
                           stage of collation, when texts must be handled as sequential strings and imperative
                           processes are requird for calculations of alignment and comparison, the handling of
                           markup as patterns in imperative programs offers a modicum of authority and control
                           of the output.</p>
                     </div>
                  </div>
                  <div class="section" id="d4e846">
                     <h2 class="title" style="clear: both">Conclusion</h2>
                     <p id="d4e848">In this paper we looked first at the ways in which large language models fail
                        repeatedly in the task of comparing and differentiating strings. We considered this
                        a
                        curious failing in a system that works with tokenized units of language, and also
                        a sign
                        of a limited basis for making reasonable statements. Perhaps this could be improved
                        with
                        implementing declarative methods. ChatGPT promised a kind of declarative affordance
                        and
                        declares to us its results, but its declarations are neither consistent nor reasonable.
                        Perhaps a more adaptable algorithm for AI would allow for declarative mechanisms to
                        control the logic of its operations. </p>
                     <p id="d4e849">We then turned to consider how declarative methods can be implemented in imperative
                        programming. When scholars should have the capacity to alter the scripts on which
                        machines do their complex processing, they lend scholarly authority to what computing
                        machines can process. What we require, and what declarative methods should afford,
                        is
                        control and validation of the grounds of knowledge, even when these are shifting.</p>
                     <p id="d4e850">In a moment of eager excitement, confusion, and fear about the potential disruptive
                        influences of generative language models, markup technologies provide reliable precision
                        and control. They allow us to intervene and guide computational processes within
                        declarative bounds of reason. Declarative methods can provide a foundation for a digital
                        humanities lab like mine to counterbalance the anxiety-ridden speculative work of
                        statistically-based <q>distant reading</q>, to extend what digital resources we
                        can create, and to ground the authority of our research. When the calculations and
                        training capacities of a large language model are subject to rapid change with the
                        next
                        month's update, and when developers of generative language models conceal their sources
                        for commercial reasons and do not share their transformer architectures openly, we
                        would
                        do well to inspect our tools and research methods for brittle dependencies. Declarative
                        markup proves itself a precision instrument to guide computational processing and
                        may
                        help to address the ephemerality of unstable technology stacks. What might it mean
                        for a
                        text-generative <q>AI</q> system to operate in a fully declarative
                        way?</p>
                  </div>
                  <div class="footnotes"><br><hr width="100" align="left">
                     <div id="d4e64" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e64-ref" class="footnoteref">[1]</a></sup> At least in 2017, topics connected to digital scholarly editions (and
                           connected to it, declarative markup) seems to have been on the decline. See
                           Scott Weingart, <q>What’s Under the Big Tent?: A Study of ADHO Conference
                              Abstracts</q>, Digital Studies/le Champ Numérique, 7(1), 6. DOI: <a href="http://doi.org/10.16995/dscn.284" class="link">http://doi.org/10.16995/dscn.284</a>. See also the questions raised
                           about the ADHO conference and its representation of the practice of
                           <q>digital humanities</q> in Laura Estill, Jennifer Giuliano, Élika
                           Ortega, Melissa Terras, Deb Verhoeven, and Glen Layne-Worthy, <q>The circus
                              we deserve? A front row look at the organization of the annual academic
                              conference for the Digital Humanities</q> DHQ: Digital Humanities
                           Quarterly 16:4 (2022). <a href="A front row look at the organization of the annual academic conference for the Digital Humanities" class="link">http://www.digitalhumanities.org/dhq/vol/16/4/000643/000643.html</a>
                           </p>
                     </div>
                     <div id="d4e90" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e90-ref" class="footnoteref">[2]</a></sup> Evidence of how my colleagues practicing digital humanities perceive
                           declarative markup in the time of AI can be seen in the author's January 2023
                           conversation with Ted Underwood on Mastodon:
                           <a href="https://sigmoid.social/@TedUnderwood/109730986869388754" class="link">https://sigmoid.social/@TedUnderwood/109730986869388754</a>. The informal
                           conversation was sparked by a declaration that ChatGPT’s capacity to take text
                           input with instructions and output it marked in TEI also meant that eventually
                           there will be no more need for markup at all. In some ways this paper responds
                           to the challenge of that conversation.</p>
                     </div>
                     <div id="d4e109" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e109-ref" class="footnoteref">[3]</a></sup> See among others, Elisa Beshero-Bondar, <q>Adventures in Correcting XML
                              Collation Problems with Python and XSLT</q>, Proceedings of Balisage:
                           The Markup Conference 2022. Balisage Series on Markup Technologies, vol. 27
                           (2022). <a href="https://doi.org/10.4242/BalisageVol27.Beshero-Bondar01" class="link">https://doi.org/10.4242/BalisageVol27.Beshero-Bondar01</a>.</p>
                     </div>
                     <div id="d4e126" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e126-ref" class="footnoteref">[4]</a></sup> This article documents a significant body of publications aided by, applying,
                           or investigating ChatGPT published between December 2022 and February 2023, just
                           the beginning of a scholarly surge of interest across disciplines in AI:
                           Zamfiroiu, Alin, Denisa Vasile, and Daniel Savu, <q>ChatGPT – A Systematic
                              Review of Published Research Papers.</q>
                           <span class="ital">Informatica Economica</span>, vol. 27, no. 1, 2023, pp. 5-16.
                           <a href="http://revistaie.ase.ro/content/105/01%20-%20zamfiroiu,%20vasile,%20savu.pdf" class="link">http://revistaie.ase.ro/content/105/01%20-%20zamfiroiu,%20vasile,%20savu.pdf</a>.
                           Accessed 2023-07-22.</p>
                     </div>
                     <div id="d4e145" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e145-ref" class="footnoteref">[5]</a></sup> <q><a href="https://openai.com/blog/chatgpt-plugins#code-interpreter" class="link">ChatGPT plugins: Code interpreter</a></q>, Chat GPT Blog.
                           2023.</p>
                     </div>
                     <div id="d4e162" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e162-ref" class="footnoteref">[6]</a></sup> I accessed ChatGPT from January through July 2023 from <a href="https://chat.openai.com/" class="link">https://chat.openai.com/</a></p>
                     </div>
                     <div id="d4e385" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e385-ref" class="footnoteref">[7]</a></sup> Timothy Mugayi, <a href="https://levelup.gitconnected.com/chatgpt-16k-context-window-a-step-closer-to-100k-c770f0658996" class="link"><q>ChatGPT 16K Context Window A Step Closer to 100k: A look at
                                 larger context windows and what it means for your
                                 applications</q></a> Medium: Level Up Coding. 21 June
                           2023.</p>
                     </div>
                     <div id="d4e570" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e570-ref" class="footnoteref">[8]</a></sup> I accessed Claude in July 2023 at <a href="https://claude.ai" class="link">https://claude.ai</a></p>
                     </div>
                     <div id="d4e614" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e614-ref" class="footnoteref">[9]</a></sup> Simon Frieder, Luca Pinchetti, Alexis Chevalier, Ryan-Rhys Griffiths,
                           Tommaso Salvatori, Thomas Lukasiewicz, Philipp Christian Petersen, Julius
                           Berner, <q>Mathematical Capabilities of ChatGPT</q> Arxiv: Computer
                           Science &gt; Machine Learning, 2023. <a href="https://doi.org/10.48550/arXiv.2301.13867" class="link">https://doi.org/10.48550/arXiv.2301.13867</a></p>
                     </div>
                     <div id="d4e623" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e623-ref" class="footnoteref">[10]</a></sup> For unsophisticated novices like me, these articles have been particularly
                           helpful for gaining a basic appreciation of key concepts in text generative
                           AI: Haomiao Huang, <a href="https://arstechnica.com/gadgets/2023/01/the-generative-ai-revolution-has-begun-how-did-we-get-here/" class="link"><q>The generative AI revolution has begun—how did we get
                                 here?</q></a> Ars Technica 30 January 2023; Jay Alammar,
                           <a href="https://jalammar.github.io/illustrated-word2vec/" class="link"><q>The Illustrated Word2Vec</q></a> blog post, 27 March
                           2019. </p>
                     </div>
                     <div id="d4e633" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e633-ref" class="footnoteref">[11]</a></sup> This Google Collab Notebook tutorial offers an accessible introduction to
                           gender and social class bias engrained in large language models: Shlomi Hod,
                           <q>Tutorial // Exploring Gender Bias in Word Embedding</q>
                           2018—. <a href="https://colab.research.google.com/github/ResponsiblyAI/word-embedding/blob/main/tutorial-bias-word-embedding.ipynb" class="link">https://colab.research.google.com/github/ResponsiblyAI/word-embedding/blob/main/tutorial-bias-word-embedding.ipynb</a>.
                           This article details pervasive problema of gender bias in ChatGPT’s
                           translations from English to Farsi, Malay, Tagalog, Thai, and Turkish:
                           Sourojit Ghosh and Aylin Caliskan, <q>ChatGPT Perpetuates Gender Bias in
                              Machine Translation and Ignores Non-Gendered Pronouns: Findings across
                              Bengali and Five other Low-Resource Languages</q> Upcoming
                           Publication in AAAI/ACM Conference on AI, Ethics, and Society, 2023.</p>
                     </div>
                     <div id="d4e647" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e647-ref" class="footnoteref">[12]</a></sup> Michael Sperberg-McQueen, <a href="https://blackmesatech.com/2015/10/KIaCiDH/" class="link"><q>What does
                                 descriptive markup contribute to digital humanities?</q></a>,
                           Key Ideas and Concepts of Digital Humanities conference, Technische
                           Universitat Darmstadt, 26-28 October, 2015. <a href="https://blackmesatech.com/2015/10/KIaCiDH/#(8)" class="link">Slide
                              8</a>.</p>
                     </div>
                     <div id="d4e663" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e663-ref" class="footnoteref">[13]</a></sup> Steven J. DeRose, David G. Durand, Elli Mylonas, Allen H. Renear,
                           <q>What is Text, Really?</q> Journal of Computing in Higher Education. 1. 3-26. 1990. <a href="https://doi.org/10.1007/BF02941632" class="link">https://doi.org/10.1007/BF02941632</a></p>
                     </div>
                     <div id="d4e675" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e675-ref" class="footnoteref">[14]</a></sup>  Emily Bender, Timnit Gebru et. al. <q>On the Dangers of Stochastic
                              Parrots: Can Language Models Be Too Big?</q> Proceedings of the 2021
                           ACM Conference on Fairness, Accountability, and Transparency, March 2021,
                           pp. 610–623. <a href="https://doi.org/10.1145/3442188.3445922" class="link">https://doi.org/10.1145/3442188.3445922</a>. For helpful
                           introductions to how large language models work to generate text based on
                           predictive algorithms, see On how meaning is predicted in large language
                           models, see Jay Alammar, <a href="http://jalammar.github.io/illustrated-transformer/" class="link"><q>The Illustrated Transformer</q></a> blog post. 27
                           June 2018; Molly Ruby <a href="https://towardsdatascience.com/how-chatgpt-works-the-models-behind-the-bot-1ce5fca96286" class="link"><q>How ChatGPT Works: The Model Behind The Bot</q></a>,
                           in Towards Data Science. Medium. 30 January 2023. </p>
                     </div>
                     <div id="d4e694" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e694-ref" class="footnoteref">[15]</a></sup> Here is a sampling of recent articles on how to improve problem solving
                           capacities in large language models: Cem Anil, Yuhuai Wu et. al.,
                           <q>Exploring Length Generalization in Large Language Models</q>
                           36th Conference on Neural Information Processing Systems. 2022. <a href="https://openreview.net/pdf?id=zSkYVeX7bC4" class="link">https://openreview.net/pdf?id=zSkYVeX7bC4</a>; Shunyu Yao, Dian Yu,
                           Jeffrey Zhao et. al., <q>Tree of Thoughts: Deliberate Problem Solving
                              with Large Language Models</q>, Arxiv: Computer Science &gt;
                           Computation and Language, May 2023 preprint <a href="https://arxiv.org/pdf/2305.10601.pdf" class="link">https://arxiv.org/pdf/2305.10601.pdf</a>; Roie Schwaber-Cohen,
                           <q>Vector Databases</q>, Pinecone <a href="https://www.pinecone.io/learn/vector-database/" class="link">https://www.pinecone.io/learn/vector-database/</a> n.d. </p>
                     </div>
                     <div id="d4e721" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e721-ref" class="footnoteref">[16]</a></sup> Kordjamshidi P, Roth D, Kersting K., <q>Declarative Learning-Based
                              Programming as an Interface to AI Systems</q>, Frontiers in
                           Artifical Intelligence 5:755361, 2022 Mar 14. doi:10.3389/frai.2022.755361.
                           <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8967162/" class="link">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8967162/</a>
                           </p>
                     </div>
                     <div id="d4e746" class="footnote">
                        <p><sup class="fn-label"><a href="#d4e746-ref" class="footnoteref">[17]</a></sup>  See the CollateX documentation, section 3.1 Alignment Algorithms in <a href="https://collatex.net/doc/" class="link">https://collatex.net/doc/</a>.
                           The Needleman-Wunsch algorithm appears to be a starting point that CollateX
                           has adapted and improved to the Dekker algorithm, but the author's
                           experience applying the default alignment algorithm is consistent with this
                           pronounced statement from Needleman and Wunsch when they introduced their
                           comparison algorithm for bioinformatics in 1970: <q>Comparisons are made
                              from the smallest unit of significance.</q> This means that the
                           software consistently defaults to aligning the smallest units of agreement
                           at the token level, even when the context of the passage of text surrounding
                           them (say the unit paragraph or section) is completely different. Saul B.
                           Needleman and Christian D. Wunsch, <q>A general method applicable to the
                              search for similarities in the amino acid sequence of two
                              proteins</q> Journal of Molecular Biology 48:3 (28 March 1970) pp.
                           443-453. <a href="https://doi.org/10.1016/0022-2836(70)90057-4" class="link">https://doi.org/10.1016/0022-2836(70)90057-4</a>.</p>
                     </div>
                  </div>
               </div>
               <div id="author-keywords">
                  <h5 class="keywords">Author's keywords for this paper:</h5> <span class="keyword">artificial intelligence</span>; <span class="keyword">AI</span>; <span class="keyword">large language model</span>; <span class="keyword">LLM</span>; <span class="keyword">declarative markup</span>; <span class="keyword">declarative methods</span>; <span class="keyword">imperative methods</span>; <span class="keyword">TEI</span>; <span class="keyword">Text Encoding Initiative</span>; <span class="keyword">tokenization</span>; <span class="keyword">normalization</span>; <span class="keyword">machine-assisted collation</span>; <span class="keyword">Python</span>; <span class="keyword">XSLT</span></div>
               <div id="balisage-footer">
                  <h3>Balisage Series on Markup Technologies</h3>
               </div>
            </main>
         </body>
      </html>
      <div id="balisage-footer">
         <h3><!--* balisage-html.xsl 519.38 *--><i>Balisage:</i>&nbsp;<small>The Markup Conference</small></h3>
      </div>
   </body>
</html>